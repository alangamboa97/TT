\documentclass[12pt,letterpaper]{article}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{anysize}
\usepackage{array}
\usepackage{lmodern}
\usepackage{adjustbox}
\usepackage{titlesec}
\usepackage{float}
\usepackage{tabularx}
\usepackage{multicol}

\marginsize{2cm}{2cm}{1cm}{1cm}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\footnotesize UPIITA}
%\fancyfoot[R]{\footnotesize Diseño}
\fancyfoot[R]{\thepage}
\fancyfoot[L]{\footnotesize Proyecto Terminal 1}
\renewcommand{\footrulewidth}{0.4pt}
\usepackage{graphics}
\usepackage{capt-of}
\usepackage[pdftex=false,colorlinks=true,plainpages=true,citecolor=blue,linkcolor=blue]{hyperref}
\setlength\parindent{0pt}
\usepackage[usenames]{color}
\usepackage{pdfpages}
\usepackage{float}
\usepackage{shapepar}

\begin{document}
\newcommand\tab[1][1cm]{\hspace*{#1}}
\renewcommand{\tablename}{Tabla}
\renewcommand{\listtablename}{Índice de tablas}


\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\listoftables

\newpage
\section{Glosario de Abreviaturas}
\textbf{Glosario de Abreviaturas}

\begin{itemize}

    \item \textbf{CNN} \tab[4cm] \emph{Convolutional Neural Network}
    \item \textbf{LTE-M} \tab[4cm] \emph{Long Term Evolution for Machines}
    \item \textbf{NB-IoT} \tab[4cm] \emph{Narrowband-Internet of Things}
    \item \textbf{CPU} \tab[4cm] \emph{Central Processing Unit}
    \item \textbf{GPU} \tab[4cm] \emph{Graphical Processing Unit}
    \item \textbf{SBGD} 
\end{itemize}

\newpage
\section{Resumen}

El sistema hará uso de técnicas de visión artificial, tales como las Cascadas Haar para la detección de rostro, ojos y boca del conductor a partir de la entrada de video en tiempo real, así como la propuesta del uso de una red neuronal convolucional entrenada para poder detectar el estado de los ojos. El sistema utilizará puntos de referencia faciales para marcar la posición de la boca y posteriormente se obtendrá la relación de apertura de la boca, con el fin de detectar si se trata de un bostezo. Si el sistema detecta somnolencia, se activará una alarma con intención de alertar al conductor, a su vez, se realizará un reporte de incidencia el cual será enviado a una base de datos. El sistema utilizará una Jetson Nano para su funcionamiento de manera portátil. Como parte del sistema se analizó y diseñó un sistema de administración que permitirá al usuario verificar y visualizar la información de los reportes de incidencia y la información de cada conductor. Para el cual se diseñó una aplicación web que le permita al usuario acceder a la información y adicionalmente monitorear la ubicación en tiempo real del conductor. \\

\emph{\textbf{Palabras Clave:}} Somnolencia, Visión artificial, Geolocalización, Alerta, Red Neuronal Convolucional, Aplicación web.

\section{Abstract}
The system will make use of artificial vision techniques, such as Haar Cascades for the detection of the driver's face, eyes and mouth from the video input in real time, as well as the proposal of the use of a convolutional neural network trained to to be able to detect the state of the eyes. The system will use facial reference points to mark the position of the mouth and then the mouth opening ratio will be obtained, in order to detect if it is a yawn. If the system detects drowsiness, an alarm will be activated with the intention of alerting the driver, in turn, an incident report will be made which will be sent to a database. The system will use a Jetson Nano for portable operation. As part of the system, an administration system was analyzed and designed that will allow the user to verify and view the information of the incident reports and the information of each driver. For which a web application was designed that allows the user to access the information and additionally monitor the location in real time of the driver.\\


\emph{\textbf{Keywords:}} Drowsiness, Computer Vision, Geolocation, Alert, Convolutional Neural Network.


\newpage
\section{Capítulo I: Introducción }

De acuerdo con el Informe sobre la situación mundial de la seguridad vial 2018, publicado por la Organización Mundial de la Salud (OMS), el número anual de muertes por accidentes de tránsito llego a los 1,35 millones. Sin embargo, las consecuencias de estos accidentes no solamente afectan al conductor y a los pasajeros del vehículo, sino que también involucran a los peatones, ciclistas y motociclistas, en particular aquellos que residen en países en desarrollo \cite{WHO}.
\\

La somnolencia al conducir es reconocida como un factor que puede contribuir a los percances viales. De acuerdo a datos de CONAPRA, en México cada año mueren en promedio 16,500 mexicanos por percances de este tipo. Con base en estimaciones hechas por el Secretariado Técnico del Consejo Nacional para Prevención de Accidentes (STCONAPRA), los accidentes viales le cuestan al país alrededor de 150 mil millones de pesos que representan el 1.7 \% del Producto Interno Bruto (PIB), sumando costos directos e indirectos. La somnolencia, al momento de conducir se trata de un fenómeno complejo que implica disminuciones en los niveles de alerta y conciencia por parte del conductor. Esta situación se convierte en un detonador de accidentes pues disminuye en el sujeto la capacidad de identificar situaciones de riesgo y por tanto evitar el peligro \cite{IMT}. \\

En el desarrollo logístico de empresas que se encargan de transportar a pasajeros o que se encargan de repartir paquetería, los datos pueden verse de forma más alarmante o preocupante, ya que, usualmente, las personas designadas como conductores se enfrentan a largas horas de jornada sin descanso y en muchos casos, rotan por horarios que pueden ser en el día o en la noche, aumentando el riesgo de accidentarse por el desbalance de tener un horario mixto.\\ 

Muchas de estas empresas optan por sistemas de rastreo de vehículos, que hoy es un recurso determinante para la planificación de rutas de distribución al optimizar las mismas y, lo más importante, al estar en un constante monitoreo se puede tener la certeza de que se está siguiendo la ruta marcada correctamente \cite{TastreoSatelital}.\\ 

El rastreo satelital de vehículos funge como una de las principales opciones de sistemas capaces de indicar la ubicación de los vehículos en cuestión, sin embargo, el costo es elevado y periódico. \\

Tomando en cuenta el contexto antes planteado, se analizará y diseñará en el presente documento un sistema que alerte a un conductor con somnolencia, mediante el uso de una cámara digital y algoritmos de visión artificial, además de incluir un sistema de administración que permita la geolocalización del sistema en tiempo real, así como la gestión de conductores y reportes de incidencias. 
  

\newpage
\subsection{Planteamiento del problema} \label{problema}

La somnolencia es un fenómeno complejo de analizar debido a los factores que pueden intervenir. Algunas de las características más notorias de un estado de somnolencia, se pueden apreciar principalmente en el rostro de las personas: frecuencia de parpadeo, bostezos, movimientos faciales y cabeceos, los cuales son parámetros claves para determinar si una persona está en estado de somnolencia o vigilia.  \\

Gracias a los avances tecnológicos en los últimos años, se han comenzado a desarrollar técnicas de visión artificial y aprendizaje automático que permiten detectar patrones de manera más eficiente. En el área del hardware, se han desarrollado microordenadores capaces de realizar tareas que requieran un nivel moderado de computación de una manera eficaz. Finalmente, en el área de telecomunicaciones, tecnologías como el 4G y avances en el área de \emph{Internet of Things} han permitido mayores velocidades de transmisión de datos, así como mayor cobertura dentro del territorio nacional.
\\ 
%Falta referencias: https://pure.coventry.ac.uk/ws/portalfiles/portal/40893306/Binder3.pdf %
Hoy en día, se están comenzando a utilizar tecnologías para prevenir y detectar síntomas de fatiga y somnolencia en conductores. Donde se han realizado diversos estudios y soluciones que intentan dar respuesta al problema de monitoreo de la somnolencia. \\

Uno de estos métodos está basado en el comportamiento del vehículo, el cual detecta el estado del conductor mediante el análisis de distintas métricas como son: movimientos del volante, posición del vehículo, la presión del acelerador o del freno, cambio de velocidades, con los cuales se determina la posibilidad de que el conductor se encuentre en estado de somnolencia. El principal problema de dicho método es que las características individuales del vehículo, conductor y carretera repercuten en la eficacia del sistema.  \\

Por otra parte, se encuentran los métodos que se basan en el análisis de variables fisiológicas, los cuales permiten la detección de somnolencia en sus fases tempranas con una baja tasa de falsos positivos. Se destacan los métodos basados en: electroencefalograma (EEG), electromiograma (EMG), electrocardiograma (ECG) y electrooculograma (EOG).\\  
Cabe mencionar que, entre todos los métodos, el EEG es el más común para la detección de la somnolencia, donde se analizan diferentes bandas de frecuencia. Todas estas señales brindan información adicional al momento de analizar el estado de somnolencia de una persona. Sin embargo, estos métodos requieren contacto con el conductor y el uso excesivo de canales de encefalogramas, lo cual resta comodidad, maniobrabilidad y practicidad al conductor, además de poder llegar a ser invasivos, lo cual puede llegar a entorpecer el desempeño del conductor. \cite{Sistemasdesomnolencia}  \\

Finalmente, se encuentra el análisis de características visuales que puede presentar un conductor somnoliento, como los movimientos faciales, parpadeos rápidos y constantes, cabeceos y bostezos frecuentes. Sin embargo, los bostezos se presentan generalmente antes de que el conductor entre en somnolencia, mientras que, los cabeceos normalmente ocurren cuando el conductor se duerme. Por lo que estos métodos no son capaces de detectar con exactitud cuando un conductor está empezando a entrar en un estado de somnolencia, sin embargo, son los métodos visuales más adecuados para dicho propósito. \cite{Sistemasdesomnolencia}   Por tanto, se debe tomar en cuenta las diferencias temporales entre los distintos signos visuales, por lo que realizar la combinación de varias de estas características aumentará la robustez final del sistema, logrando una mejor eficacia en el sistema. \\  

Debido a las dificultades que pueden presentarse en los sistemas a la hora de detectar la somnolencia y la eficacia de este, así como las dificultades que muchos de los sistemas anteriores presentan en cuanto al espacio y potabilidad, se hará uso del método de análisis de características visuales para brindar una mejora y complemento a los sistemas actuales, usando visión artificial, además de integrar un sistema de monitoreo que permita a un tercero seguir la ubicación del conductor y registrar las incidencias del mismo.  \\

Actualmente existen varias opciones para la geolocalización de vehículos en tiempo real, pero con costos elevados, como lo es el rastreo satelital el cual requirere un pago servicio con una suscripción anual o mensual. Entonces, surge una oportunidad para desarollar soluciones más asequibles y que sean igualmente eficaces, como es el caso de las redes móviles LTE.

Dadas las posibles soluciones y escenarios antes mencionados se plantea la siguiente pregunta: ¿Cómo desarrollar un sistema portátil que pueda detectar la somnolencia y alertar al conductor, además de monitorear la ubicación en tiempo real y gestionar las incidencias detectadas en el conductor? 


\subsection{Propuesta de solución} \label{solucion}

Como respuesta a la problemática planteada en la sección \ref{problema}, se propone el desarrollo de un sistema portátil que sea capaz de detectar somnolencia en conductores y su vez activar una alarma que permita alertar al conductor. Como parte del sistema, un subsistema que permita la administración y validación de las incidencias reportadas, así como el monitoreo GPS del conductor en tiempo real dentro de la Ciudad de México.  \\

Los problemas que resolverá el sistema se listan a continuación: \\

\begin{itemize}
\item El sistema será portátil por lo que se hará uso de un microordenador para poder ser instalado y que funcione dentro de un vehículo. 
\item Mediante una cámara digital conectada al microordenador, el sistema analizará el rostro del conductor en tiempo real, tomando en cuenta parámetros de análisis tales como; rostro, ojos y boca del conductor. 
\item El sistema hará uso de técnicas de visión artificial para poder detectar si el conductor presenta signos de somnolencia. 
\item En caso de presentarse un caso de somnolencia, el sistema activará una alarma para alertar al conductor. 
\item Al mismo tiempo, el sistema realizará y almacenará un reporte de incidencia que contendrá datos como fecha, hora, ubicación geográfica, y un pequeño video clip que muestre el momento en que el conductor presentó signos de somnolencia. 
\item Posteriormente, el sistema hará uso de redes de telecomunicaciones móviles para enviar el reporte de incidencia previamente generado hacía una estación base que funcionará mediante una aplicación web, dónde un administrador podrá verificar este reporte con el fin de confirmar que se trata de un caso de somnolencia y no un falso positivo. 
\item A su vez, el administrador podrá consultar la ubicación en tiempo real del conductor desde la misma estación base.
\item En la figura 1 se muestra la propuesta del diagrama general de diseño de la arquitectura del sistema.    

\end{itemize}


\begin{center}
  \includegraphics[scale=0.4]{imagenes/propuestasolucion}
\captionof{figure}{Diagrama general del diseño preliminar de la arquitectura del sistema. }
 \label{fig:Arquitecturapreliminar} 
\end{center} 


\subsection{Alcances}

A continuación, se describen los alcances de la propuesta de solución: 

\begin{itemize}
\item Detectar síntomas de somnolencia del conductor.
\item Alertar al conductor mediante una alarma en caso de que se detecten síntomas de somnolencia.
\item El sistema realizará un reporte de incidencia al detectar somnolencia. 
\item Solicitar el posicionamiento por medio de una tecnología de geolocalización en tiempo real. 
\item La transmisión de los datos del módulo de procesamiento se realizará mediante una red inalámbrica.
\item Se trazará la ruta en el mapa de la trayectoria ejecutada por el conductor y se mostrará en la aplicación web.
\item Las pruebas a realizar serán en la Ciudad de México donde se cuente con cobertura de redes móviles garantizada.
\item La aplicación web permitirá consultar las incidencias de los conductores, así como la fecha y hora de estas, además de la ubicación de cada conductor en tiempo real. 

\end{itemize}

 
\subsection{Escenario de pruebas}

Las pruebas se dividirán en dos fases:\\
 
\textbf{Fase 1:}

En la primera fase se probará el sistema de somnolencia y el sistema de administración de manera separada, con el propósito de analizar los resultados obtenidos. Para el sistema de detección de somnolencia será colocado dentro del vehículo, sin embargo, dicho vehículo permanecerá estacionado y con el motor apago, esto con el fin de realizar pruebas de la precisión del sistema y poder ajustar parámetros en caso de ser necesario.\\  

En un primer escenario se examinarán los siguientes signos de somnolencia sin el uso de gafas de sol:\\ 

Estado de los ojos:  

\begin{itemize}
\item Abiertos, cerrados. 
\item Duración de estos estados. 
\end{itemize}

Bostezos: 

\begin{itemize}
\item Apertura de la boca. 
\end{itemize}

En un segundo escenario se examinarán los mismos signos de somnolencia con el uso de gafas de sol.  \\

Estas pruebas se realizarán tanto de noche como de día para comprobar la efectividad del sistema. En caso de ser necesario, se realizarán los ajustes correspondientes en los parámetros de análisis para mejorar la efectividad de las pruebas. Así mismo se verificará que la alarma se active correctamente al detectar somnolencia en el conductor.  \\

Para el sistema de administración se probará la aplicación web que incluye el acceso a la geolocalización del sistema en tiempo real, así como pruebas de estrés al servidor de alojamiento, con el fin de conocer la eficacia de respuesta del sistema durante periodos de tráfico de datos elevados. \\
 
\textbf{Fase 2:}

En la segunda fase, se probará el sistema completo con el vehículo en movimiento, donde el sistema estará monitoreando el estado de somnolencia del conductor en todos sus trayectos.  \\

Para el sistema de administración se corroborará que en los casos en que el sistema de somnolencia detecte una incidencia, esta sea enviada correctamente y pueda ser visualizada desde el sistema de administración. A su vez, se constará que la información de la ubicación geográfica del sujeto de prueba esté disponible en todo momento.  

\subsection{Justificación}

Actualmente, nos encontramos en la era digital donde se han desarrollado diferentes avances tecnológicos tales como el internet de las cosas (IoT) el cual permite la comunicación con dispositivos y da pauta al desarrollo de sistemas inteligentes que resuelven problemas complejos de manera automática y eficaz en ambientes específicos, la inteligencia artificial, el machine learning, el procesamiento masivo de datos en menor tiempo, entre muchos otros. \\

El sistema propuesto será capaz de detectar la somnolencia apoyado en estudios donde se analizan los aspectos fisiológicos y donde se delimitan los datos biométricos del estado de somnolencia obtenidos en diferentes pruebas, mediante el uso de visión artificial y deep learning para tener mejores resultados y posteriormente ser enviados a una estación base con ayuda de la tecnología de las redes inalámbricas. \\

Al haber accidentes de tránsito por somnolencia en México, con este proyecto se pretende prevenirlos e integrar un sistema que permita el monitoreo del vehículo mediante la geolocalización del mismo, el uso de una alarma auditiva para que el conductor se mantenga alerta, así como un sistema interactivo con los usuarios que permita visualizar las incidencias que se puedan presentar por parte de los conductores.\\ 

Ofreciendo así un sistema que utilice las tecnologías de la nueva generación que permitan el monitoreo, la detección y la alerta del conductor. 


\subsection{Metodología}


Debido a que el presente proyecto conjunta la parte de software con hardware, se estarán implementando dos metodologías.  

\begin{itemize}

\item \textbf{Top-Down}

La metodología de diseño \emph{Top-Down} consiste en dividir un problema complejo en problemas o partes más pequeñas con mayor facilidad de resolución. A este proceso se le llama \emph{Descomposición}. Estas partes pueden ser llamadas modulos o subrutinas. Cada módulo puede ser probado individualmente \cite{TopDown}.  

\begin{center}
  \includegraphics[scale=0.56]{imagenes/Top-down}
\captionof{figure}{Descomposición en la metodología \emph{Top-Down}. \cite{TopDown}}
 \label{fig:neurona}
\end{center}

Utilizando la metodología Top-Down, se puede dividir el sistema en módulos que serán independientes de sí mismo, esto con la finalidad de ahorrar tiempo, así como recursos para su mantenimiento. Por lo tanto, en este proyecto se comenzará entendiendo el problema general para posteriormente poder realizar una subdivisión de problemas más pequeños para ser resueltos de manera invididual.


\item \textbf{UML}

UML es el estándar de la industria para modelar sistemas orientados a objetos \cite{kendall}. UML incluye un conjunto de herramientas que permite visualizar la construcción de un sistema orientado a objetos. Al trabajar por iteraciones, se aborda de manera cada vez con más detalle el diseño de sistema, hasta que se defina con claridad las relaciones de cada uno de los objetos del sistema. Uno de las principales ventajas de UML es la reutilización de objetos, esto permite reducir costo de desarrollo así como de mantenimiento de los programas. En este proyecto se hará uso de uml para el análsis y diseño de cada módulo.

\end{itemize}


\newpage
\subsection{Objetivos}

\subsubsection{Objetivo General}

Analizar y diseñar un sistema para la detección de síntomas de somnolencia y alerta del conductor. Además de ser capaz de obtener la ubicación del conductor en tiempo real para ser monitoreada desde una aplicación web que a su vez permita gestionar y visualizar los reportes de incidencias del mismo. 

\subsubsection{Objetivos Específicos}

\textbf{Para Trabajo Terminal 1:}

\begin{itemize}
\item Diseñar un sistema de visión artificial que sea capaz de detectar la somnolencia en conductores.
\item Diseñar un sistema de geolocalización en tiempo real usando redes de telecomunicaciones.
\item Diseñar un sistema de administración para la gestión de usuarios, almacenamiento de datos y consultas de las incidencias de cada conductor. 
\item Diseñar un sistema de comunicaciones que permita la interconexión entre el sistema de visión artificial y el sistema de administración.  
\end{itemize}


\textbf{Para Trabajo Terminal 2:}

\begin{itemize}
\item Implementar un sistema de visión artificial que sea capaz de detectar la somnolencia en conductores.
\item Implementar un sistema de geolocalización en tiempo real.
\item Implementar un sistema de administración para la gestión de usuarios, almacenamiento de datos y consultas de las incidencias de cada conductor. 
\item Implementar un sistema de comunicaciones que permita la interconexión entre el sistema de visión artificial y el sistema de administración.  
\end{itemize}

\newpage
\section{Capítulo II: Marco de Referencia}

\subsection{Marco Teórico}

\subsubsection{Somnolencia}

La somnolencia es la necesidad o tendencia que tiene una persona a quedarse dormido. La intensidad de somnolencia está determinada por la calidad de sueño, la cantidad, y el ritmo circadiano de la persona \cite{intensidad}.

Se han propuesto tres clases de métodos para poder medir el grado de somnolencia en una persona:

\begin{itemize}
\item \textbf{Mediciones del comportamiento} 

Se basan en la observación del comportamiento del individuo. Entre estos se encuentran: el bostezo, la actividad ocular, expresiones faciales y pestañeo.

\item \textbf{Test de funcionamiento}

Se usan para medir los efectos de somnolencia en diferentes aspectos del funcionamiento, como por ejemplo: las variaciones en el tiempo de reacción, vigilancia psicomotora y simuladores de manejo.

\item \textbf{Test Neurofisiológicos}

Son diseñados bajo la premisa de cuantificar la somnolencia de manera objetiva. 


\end{itemize}

\subsubsection{Jetson Nano}

Jetson Nano es una computadora pequeña y poderosa que permite ejecutar múltiples redes neuronales en paralelo para aplicaciones como clasificación de imágenes, detección de objetos, segmentación y procesamiento de voz. En una plataforma fácil de usar que funciona con 5 vatios \cite{JetsonNano}. 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/JetsonNano}
\captionof{figure}{Kit para Desarrolladores Jetson Nano. }
 \label{fig:JetsonNano} 
\end{center} 


\subsubsection{Visión Artificial}
Se puede definir como el conjunto de técnicas para la extracción de información de imágenes digitales. El tipo de información obtenida de una imagen puede ser de identificación, mediciones para navegación, o aplicaciones de realidad aumentada.El campo de visión artificial puede verse como una parte de la informática. La teoría de algoritmos y el aprendizaje automático son esenciales para el desarrollo de algoritmos de visión artificial.
La visión artificial está compuesta generalmente por un conjunto de procesos destinados a realizar el análsis de imágenes:captación de imágenes, memorización de la información, proceso e interpretación de los resultados \cite{vision}.


\subsubsection{Red Neuronal}

Una red neuronal es un sistema que pretende emular ciertas características propias de los seres humanos, tales como la capacidad de memorizar o y asociar hechos o características. Este sistema está se basa en el concepto de \emph{neurona}.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/neurona}
\captionof{figure}{Módelo estándar de una neurona artificial}
 \label{fig:neurona}
\end{center}

Un módelo simplificado de una neurona artificial consta de dos etapas.
En la primera etapa, las entradas provenientes de otras neuronas son combinadas tomando en cuenta los pesos de las sinapsis. Como resultado de esta etapa surge la entrada neta o \emph{excitación} de la neurona. En la segunda etapa, la entrada neta se utiliza para determinar el valor de salida de la neurona, que posteriormente será propagada a otras neuronas.

En la etapa de integración de las entradas, una neurona combina las distintas entradas $ x_i$ con sus pesos para así determinar su entrada neta $z_j$: 

\begin{equation}
zj = \sum_{i}w_{ij}x_i
\end{equation}

Dónde $w_{ij}$ representan los pesos sinápticos asociadas desde la \emph{i}-ésima neurona hasta la \emph{j}-ésima. Estos pesos tendrán valores real. Positivos para modelar conexiones excitatorias y negativos para conexiones inhibitorias.

Por otra parte, en la etapa de activación de una neurona, esta utiliza el valor asociado a su entrada neta para generar una salida $y_j$:

\begin{equation}
y_j(t)= F(y_j(t-1), z_j(t)) = F(y_j(t-1),net_j(t))
\end{equation}

\subsubsection{Redes Neuronales Convolucionales}

Las redes neuronales convolucionales, tambien conocidas como \emph{redes convolutivas}, son redes neuronales artificiales que se utilizan comunmente para resolver problemas que requieren el procesamiento de imágenes. Sus casos de uso más frecuentes van desde la detección de objetos, hasta generar una descripción textual del contenido de una imagen. Particularmente, sus entradas y salidas pueden ser estructuradas. Esto quiere decir, que en lugar de recibir un vector de entradas, se puede recibir un vector (1D), matriz (2D) o tensor($>2D$). En el caso de señales bidimensionales, las entradas pueden pertenecer a los pixeles de una imágen capturada por una cámara{Referencia0}.

Como su nombre lo indica, esta red neuronal utiliza la operación de convolución. La convolución es una operación matemática que se realiza sobre dos funciones para producir una tercera que se suele interpretar versión modificada (filtrada) de las funciones originales \cite{Referencia0}.

\

La convolución entre las funciones \emph{f} y {g} se representa de la siguiente manera:
\begin{equation}
(f\star g)(t) = \int_{-\infty}^{\infty} f(\tau )g(t-\tau )d\tau = \int_{-\infty}^{\infty} f(t-\tau)g(\tau)d\tau
\end{equation}


En el caso particular de procesamiento digital de imágenes, las variables $[n_1,n_2]$ corresponden a cordenadas $[x,y]$ de los píxeles de una imagen. Además, el signo menos que aparece en la Ecuación 8, se suele sustituir por un signo más, por lo cual la definición de convolución se expresaría como:

\begin{equation}
(x\star h)[x,y] = \sum_{k_1=0}^{K_1-1}\sum_{k_2=0}^{K_2-1} h[k_1,k_2] x[x+k_1,y +k_2]
\end{equation}


\emph{Capas convolutivas}\\
El componente clave de las redes neuronales convolucionales son las capas, que sustituyen la tradicional multiplicación de pesos por entradas. La entrada de una capa convolutiva es una señal,en el caso de imágenes, una señal bidimensional. Dicha señal es procesada realizando una convolución con una máscara o \emph{kernel}. Los pesos correspondientes al \emph{kernel} serán los parámetros de la capa convolutiva que será entrenada.
A continuación se presenta la representación más simple de las capas de una red neuronal convolucional.

\begin{center}
  \includegraphics[scale=0.45]{imagenes/cnn2} 
\captionof{figure}{Arquitectura general de una Red Neuronal Convolucional \cite{CNNpresentacion}.}
 \label{fig:boost}
\end{center}

\begin{itemize}
	\item Capa Convolucional
	
Esta capa se utiliza para extraer las diversas características de las imágenes de entrada. En esta capa se realiza la convolución entre la imagen de entrada y un \emph{kernel} de un tamaño particular $MxM$.

La salida se denomina mapa de características, que nos brinda información sobre la imagen, como las esquinas y los bordes. Posteiormente, este mapa de características se alimenta a otras capas para aprender otras características de la imagen de entrada.

La capa de convolución en CNN entrega el resultado a la siguiente capa una vez que se aplica la  en la entrada.

\item Capa de \emph{Pooling}

El objetivo principal de esta capa es disminuir el tamaño del mapa de características convolucionado para reducir los costos computacionales. Esto se realiza disminuyendo las conexiones entre capas y opera de forma independiente en cada mapa de características. Según el método utilizado, existen varios tipos de operaciones de agrupación. Básicamente resume las características generadas por una capa de convolución. El tipo de pooling más utilizado es el \emph{max-pooling}. Este devuelve el valor máximo del fragmento de la imágen filtrada por el kernel.

\begin{center}
  \includegraphics[scale=1]{imagenes/maxpool} 
\captionof{figure}{Ejemplo de Max Pooling}
 \label{fig:boost}
\end{center}

\item \emph{Fully Connected Layer}

La capa totalmente conectada  consta de los pesos y sesgos junto con las neuronas y se utiliza para conectar las neuronas entre dos capas diferentes.La imagen de entrada de las capas anteriores se aplana y se alimenta esta capa. Luego, el vector aplanado pasa por unas pocas capas  más donde normalmente tienen lugar las operaciones de las funciones matemáticas. En esta etapa comienza el proceso de clasificación.

\item \emph{Output Layer}

Esta capa se encarga de mejorar el rendimiento de un modelo de aprendizaje automático, ya que evita el sobreajuste al simplificar la red. Descarta neuronas no escenciales de la red neuronal durante el entrenamiento.

\item \emph{Funciones de activación}

Son funciones matemáticas que determinan la salida de una capa de la red neuronal, y se utilizan en capas convolucionales así cómo en las capas completamente conectadas. Estas funciones se utilizan para asignar los valores de las salidas de cada capa entre valores definidos, para así facilitar que el modelo se adapte a una gran variedad de datos. 

\item \emph{Flattening}

Flattening consiste en convertir los datos de salida de la capa convolucional a una matriz unidimensional para ser llevada a la capa siguiente.


\end{itemize}
\subsubsection{Cascadas Haar}
Existen técnicas de visión artificial que permiten el reconocimiento de objetos en una imágen o cuadros en un video. Entre los que más destacan, se encuentran las Cascadas Haar. Esta técnica fue presentada por primera vez por Viola y Jones\cite{viola}. Las Cascadas Haar implica entrenar una serie de clasificadores simples  y luego combinar su salida.\\

Posteiormente estas salidas de transforman en un \emph{clasificador h(x)} como una suma de valores de \emph{aprendices débiles}:



\begin{equation}
h(x) = sgn \left [  \sum_{j=0}^{m-1} \alpha_{j}h_j(\bold{x}) \right ]
\end{equation}


los aprendices débiles $h_j(\bold{x})$ son funciones extremadamente simples de la entrada.
En la mayoría de las variantes de Cascadas Haar, los aprendices débiles son funciones umbrales,
que también son conocidos como \emph{desicion stumps} consideradas como la forma más simple de un árbol de decisiones.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/clasificadores}
\captionof{figure}{Boosting}
 \label{fig:boost}
\end{center}

Después de que cada clasificador débil es seleccionado, los \emph{data points} que han sido clasificados de manera incorrecta aumentan su peso. El clasificador final es una combinacion lineal de los clasificadores débiles\cite{viola}.


\subsubsection{\emph{Content Delivery Network}}

Una Red de Distribución de Contenido, o CDN por sus siglas en inglés, es de una red de servidores que se encarga de mejorar el rendimiento en la carga y descarga de contenido de la red. Los componentes de una CDN se encuentran distribuidos en diferentes nodos. Estos componentes pueden ser servidores y se encuentran con contenido replicado alrededor del mundo. El trabajo de una CDN consiste en redirigir la solicitudes de los clientes a un servidor ubicado geográficamente cerca de estos. En consecuencia, los clientes obtienen los datos solicitados a una velocidad más rápida.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/cdn-diagram} 
\captionof{figure}{Arquitectura de una CDN}
 \label{fig:boost}
\end{center}

Además de esto, una CDN es capaz de detectar cambios en la información existente, así como detectar la disponibilidad de nuevo contenido en los servidores de origen.


\subsubsection{Estándares y Protocolos de Comunicación Inalámbrica}

Para transferir datos o información de un punto a otro sin la utilización de cableado o algún medio físico, existen las redes inalámbricas que utilizan ondas de radio para conectar a los 
dispositivos permitiendo así, a los dispositivos remotos, se conecten sin 
dificultad y sin importar que estos dispositivos estén a unos metros o incluso a varios 
kilómetros de distancia. Se dividen en 4 tipos dependiendo del alcance requerido y se definen por el estándar 802.11 del IEEE que es el organismo de estandarización internacional \cite{Referencian2}.

\begin{itemize}

\item \textbf{Red  inalámbrica de area amplia (WWAN)}\\

Usan ondas de radio pero transmite a uno o varios puntos de acceso inalámbrico donde un usuario inalámbrico puede conectarse a la red, al disponer de un ancho de banda más elevado ofrece una mejor cobertura. \\\\
Como ejemplo de estas redes se tienen la tecnologías 4G y 5G. 
Son conocidas como redes de largo alcance con cobertura de hasta 100km, pueden dar soporte a gran parte del territorio geográfico\cite{Referencian5}. 

En esta red se incluyen:
\begin{itemize}
\item \textbf{Celulares}\\
Es conocida como la red de telefonía móvil.
\end{itemize}
\begin{itemize}
\item \textbf{LPWAN(\emph{Low Power Wide Area Network}): Red de Área Amplia de Baja Frecuencia}\\
son redes de área amplia y de baja potencia, es un 
protocolo de transporte inalámbrico de datos que hoy en día se utiliza como uno de los 
protocolos básicos para la implementación de IoT.
Existen varias implementaciones del protocolo LPWAN, tales como Sigfox,LoRaWAN, NB-IoT y LTE. Hay muchas diferencias entre cada una de ellas en 
cuanto a los esquemas de modulación, el alcance geográfico, la cantidad de información
transmitida y a sus capacidades de encriptación y autenticación\cite{Referencian6}.
\end{itemize}

Las interfaces de comunicación inalámbrica LPWAN consideradas son:

\subsubsection{LTE-M}
LTE-M es el término simplificado de la industria para el estándar tecnológico de Área Amplia de Baja Potencia (LPWA por sus siglas en inglés). Se refiere específicamente a la tecnología LTE CatM1.

Es una tecnología de área amplia de baja potencia que admite IoT a través de dispositivos poco complejos y proporciona una cobertura extendida, al tiempo que permite la reutilización de la base instalada de LTE.\\

Las redes LTE-M coexistirán con las redes móviles 2G, 3G y 4G y se beneficiarán de todas las características de seguridad y privacidad de las redes móviles, como la confidencialidad de la identidad del usuario, la autenticación de la entidad, la privacidad, la integridad de los datos y la identificación del equipo móvil\cite{Referencian7}.

A continuación se describen las ventajas principales de LTE-M:

\begin{itemize}
\item \textbf{Ahorro de Energía}

LTE-M permite que los dispositivos IoT usen un modo de ahorro de energía, que les permite "ir a dormir" cuando no están en uso. Y tampoco tienen que despertarse para enviar solo la actualización de ubicación, sino que pueden extender los tiempos de suspensión por un período de tiempo más largo. LTE-M también permite que los dispositivos usen recepción discontinua extendida (eDRX). Cuando el dispositivo está fuera del modo suspendido, verifica periódicamente la información del enlace descendente. Con eDRX, se aumenta el tiempo de verificación de la radio, lo que reduce el consumo de energía.

\item \textbf{Cobertura}


Las redes LTE-M/Cat-M1/Cat-M2 pueden utilizar la infraestructura 4G LTE existente. Esta es una ventaja significativa, ya que más del 50 por ciento de las conexiones móviles globales se realizan en redes 4G. 

Con una pérdida de acoplamiento máxima (MCL) de 156 decibelios (dB), 14 dB más alta que LTE, las redes LTE-M también ofrecen mayor cobertura y mejor penetración en interiores. La señal puede manejar muchas interferencias de edificios y otras estructuras que obstruyen su camino.

\item \textbf{Velocidad de Transferencia}

Comparado con LTE, LTE-M no es particularmente rápido. Pero 1 megabit por segundo para transmisiones de enlace ascendente y descendente es excepcional en comparación con redes más antiguas como 2G y 3G (UMTS) y otras LPWAN. (Es varias veces más rápido que NB-IoT). Y eso es más que suficiente para la mayoría de las aplicaciones de IoT. Es factible para aplicaciones con necesidades de datos pequeñas e incluso casos de uso que involucran transmisión de video.


En el contexto de IoT, el alto rendimiento de datos significa que los dispositivos que usan LTE-M pueden recibir fácilmente actualizaciones por aire (OTA), y las transmisiones de datos consumirán menos energía, porque el dispositivo puede volver al modo de ahorro de energía más rápido.


\end{itemize}
\end{itemize}
\subsubsection{Teorema de Shannon-Hartley}

Un sistema óptimo es el que cuenta con la capacidad de minimizar la probabilidad de error de bit a la salida del sistema, esto depende de las restricciones de la energía transmitida y del ancho de banda del canal\cite{Referencian9}.

El teorema de Shannon-Hartley establece la máxima cantidad de información que puede ser transmitida sin error con un ancho de banda específico y que está expuesto a la interferencia de ruido. La ecuación para la capacidad de canal es\cite{Referencian10}:


\begin{equation}C= B\cdot log (1+\frac{S}{N}) 
\end{equation}

Donde C es la capacidad de canal, es decir, la velocidad máxima a 
la que se puede transmitir la información a lo largo del canal sin error, medida en bits por 
segundo, B es el ancho de banda en hertz, S es la potencia de la señal útil en watts y N es la potencia de ruido presente en el canal expresada en watts. Al término S/N se le conoce como relación señal a ruido\cite{Referencian11}.

\subsubsection{Geolocalización}
La Geolocalización consiste en la identificación de la posición de un dispositivo móvil en 
el espacio real. El Sistema de Posicionamiento Global GPS por sus siglas en inglés es la forma más común y 
precisa en que se realiza la localización geográfica, y es capaz de ubicar el aparato con 
una precisión de unos pocos metros.
El GPS es una red satelital que cuenta con al menos 30 satélites y que se mantienen en órbita alrededor de la tierra. Si bien el sistema en sus inicios tenía un propósito militar, en la actualidad cualquier persona puede ocuparlo\cite{Referencian12}.
Cuando se solicita el posicionamiento por medio del GPS este envía señales de radio que permiten localizar a los satélites, el centro de comando transmite la información de la órbita, el tiempo y la posición de los otros satélites en el mismo sistema GPS. Estos satélites envían simultáneamente la información de tiempo y órbita a la tierra y finaliza cuando el dispositivo GPS utiliza la información recibida para determinar su localización la cual se interpreta mayormente en dos conjuntos: la latitud y longitud\cite{Referencian13}.



\newpage
\subsection{Estado del Arte}  %Estado del arte 

\subsubsection{\emph{Driver Drowsiness Detection Using Machine Learning with Visual Behaviour}}
Este trabajo de investigación propone un sistema de detección de signos de somnolencia en conductores utilizando un modelo de Red Neuronal Convolucional para detectar la posición de los ojos, y OpenCV junto con Dlib para la detección de la boca y realizar el conteo del número de bostezos por minuto. Para alimetnar a la red Neuronal, se utilizaron el conjunto de datos de NTHU-DDD. También fue utilizado el método PERCLOS para obtener el número de parpadeos del sujeto de estudio. Este trabajo concluye que las mayores dificultades a la hora de detección de rostros fueron el uso de gafas oscuras, así como cambios en la iluminación.\cite{EstadodelAarte1}

\subsubsection{\emph{Detection Of Drowsiness And Distraction Of Drivers Using CNN}}

En este trabajo se implementó el aprendizaje automático y el paquete Keras para construir un modelo de CNN, el cual, clasifica si el conductor se encuentra somnoliento o distraído,el sistema emite un tono de alerta al detectar correctamente la somnolencia, dando al conductor una alerta temprana. Se utilizó el clasificador Open CV Haar-Cascade,un clasificador en cascada basado en características, usando sus funciones integradas, se detetó el rostro y la región de los ojos.\cite{EstadodelAarte2}


% https://www.trendytechjournals.com/files/issues/volume4/issue7-5.pdf

\subsubsection{\emph{Driver Drowsiness Detection System Using Convolutional Neural Networks}}
En este trabajo realizado en la Universidad Anurag se presenta una forma de analizar y anticipar la somnolencia del conductor mediante la aplicación de una red neuronal convolucional sobre la cara del conductor de un marco de secuencia. Se uso un conjunto de datos para dar forma y aprobar el modelo, usando redes convolucionales 3D basadas en modelos de múltiples capas de arquitectura de red neuronal repetitiva para detectar la somnolencia del conductor. Tras una sesión de entrenamiento, se obtuvo una precisión que se acerca al 92\% de aceptación.\cite{EstadodelAarte3}


\subsubsection{Rasperry Pi based System for Visual Object Detection and Tracking}
Este trabajo aborda la implementación de un sistema capaz de realizar el seguimiento de varios objetos mediante una cámara digital conectada a una Rasperry Pi. El motor de este sistema fue desarrollado utilizando C++ y se ejecuta sobre un sistema operativo basado en GNU/Linux.
Este sistema también logra transmitir las coordenadas y el tamaño de los objetos detectados a otras computadores dentro de una red de local de Internet.

%https://a-lab.ee/edu/sites/default/files/Ivask_BSc.pdf

% https://ijarsct.co.in/Paper3399.pdf

\subsubsection{Diseño e implementación de sistema de visión artificial para alerta y detección de somnolencia mediante aprendizaje profundo aplicable en conductores de vehículos}
En este trabajo realizado en la facultad de Ingeniería de la Universidad Nacional de Trujillo, se desarrolló un sistema de extracción de características faciales tales como pestañeo, cabeceo y bostezos. Para la extracción de regiones de interés se utilizaron cascadas Haar, y la clasificación de estas características se realizó utilizando un modelo de red LeNet. Además el trabajo incluye la creación de una base de datos de las regiones de interés de la cara utilizando imágenes propias y también utilizando conjunto de datos externos. Para el desarrollo de este trabajo se utilizó el lenguaje de programación Python, junto con las librerías de OpenCV, Tensorflow y Keras.\cite{EstadodelAarte4}

\subsubsection{Aplicación de visión por computador y \emph{machine learning} al guiado de un robot móvil basado en Rasperry Pi}

Esta investigación realizada en la Universidad de Sevilla, detalla el desarrollo de un vehículo con guiado autónomo basado en visión artificial. Se utilizó una red neuronal convolucional para realizar el seguimiento de objetos. El sistema desarrollado consta de una integración de una computadora remota a la par de una Rasperry Pi.

\subsubsection{Evaluación de la plataforma Nvidia Jetson Nano para aplicaciones de visión artificial}

Este trabajo de investigación aborda distintos proyectos tales como: Estimación de pose humana en tiempo real y Reconocimiento de matrícula en tiempo real sobre una Nvidia Jetson Nano. Se realizaron pruebas de rendimiento para conocer las limitaciones de la Jetson Nano. Los resultados presentados muestran que la Jetson Nano permite trabajar tanto como imágenes como con vídeos de forma fluida, aunque con ciertas limitaciones en el uso de redes neuronales profundas. Sin embargo, al utilizar la aceleración de hardware ofrecida por Nvdia, se redujo considerablemente los tiempos de ejecución de los procesos.
%https://repositorio.uam.es/bitstream/handle/10486/698381/jimenez_varela_natalia_tfg.pdf?sequence=1

\subsubsection{\emph{Comparative Study of Computer Vision Based Line Followers using Rasperry Pi and Jetson Nano}}
Esta investigación realiza una comparación del rendimiento entre la Rasperry Pi y la Jetson Nano aplicado a un sistema de guía utilizando líneas rectas en el suelo. Los resultados de este trabajo muestran que ambas ofrecen un buen rendimiento. Sin embargo, la Jetson Nano demostró ser 20 segundos más rápida en cuanto al procesamiento de imágnes, y obtuvo un porcentaje del 100\% de efectividad al recorrer el trayecto trazado por el circuito de líneas. Por otro lado, la Rasperry Pi, obtuvo un porcentaje de 98\% de efectividad en cuanto al seguimiento del circuito. Por lo anterior, el estudio concluyó que la Jetson Nano ofrece un mejor rendimiento y efectividad en tareas de visión artificial.

%https://jurnal.unsyiah.ac.id/JRE/article/view/21324/17_4_7_239_246

\subsubsection{Sistema de detección de somnolencia mediante inteligencia artificial en conductores de vehículos para alertar la ocurrencia de accidentes de tránsito}

Este proyecto fue realizado por estudiantes de la Escuela Profesional de Ingeniería de Perú y consistió en llevar a cabo un sistema para la detección de la somnolencia y la distracción del conductor. El sistema se desarrolló utilizando C\# con EmguCV para detectar la distracción y orientación de los ojos utilizando técnicas de visión artificial. Además, cuenta con un sistema de alarma compuesto por un zumbador de 12v, que se activa a recibir la orden el microcontrolador al procesar el sistema de visión artificial junto a una red neuronal.\cite{EstadodelAarte5}

\subsubsection{Diseño de un sistema electrónico para detectar la somnolencia en automovilistas por medio de la actividad ocular}
Este trabajo realizado por alumnos de la ESIME Culhuacán en el año 2019 detalla el diseño y la implementación de un sistema que se basa en la fusión de dos señales. Una de ellas proviene de la detección del estado de los ojos utilizando información proveniente de una cámara digital. Para lo anterior, se realiza una segmentación de las regiones de la piel y posteriormente se obtiene la ubicación y el rastero de los ojos. La segunda señal se obtiene a partir de los datos proveniente de un acelerómetro colocado sobre la cabeza del conductor, cuya función es detectar los cabeceos asociados con somnolencia. El procesamiento de dicha señal del acelerómetro se lleva a cabo con la ayuda de la Transformada Wavelet Discreta. Estas dos señales son correlacionadas para tener como salida dos alarmas secuenciales que son percibidas por el conductor. La primera le alerta sobre un primer estado de posible somnolencia y la segunda acciona un control difuso para el control momentáneo del auto y la corrección del volante para el seguimiento del carril. Los resultados obtenidos por este trabajo demuestran una eficacia para la detección de ojos cerrados del 86\% y para la detección de cabeceo superior al 90\%.\cite{EstadodelAarte6}


\subsubsection{Sistema para la detección del estado de somnolencia en seres humanos, con reconocimiento de patrones }

En este artículo se muestra la implementación de un sistema de detección del estado de somnolencia en
seres humanos, a través de la identificación de patrones faciales y la frecuencia de parpadeo de los ojos. Utilizando técnicas de inteligencia artificial, visión por computadora y un sistema embebido con cámara integrada para la adquisición de imágenes.El cual permite detectar en tiempo real el estado de fatiga de un conductor automovilístico y su grado de somnolencia, todo con el objetivo de disminuir la tasa de accidentes viales causados precisamente por la somnolencia en México. Se hizo uso del lenguaje de programación Python, bibliotecas como OpenCV, Dlib y Scipy, las cuales, fueron requeridas debido a los modelos predefinidos que
establecen una mayor precisión en la detección de puntos faciales específicos, utilizando como referencia el método de predicción de 68 puntos específicos del rostro. El sistema propuesto tiene la característica de funcionar con luz de día en una primera etapa, y la idea es poder implementarlo en cualquier tipo de vehículo automotriz a un costo accesible a la mayoría de los propietarios de vehículos automotrices.\cite{EstadodelAarte7}


%https://uptexcoco.edomex.gob.mx/sites/uptexcoco.edomex.gob.mx/files/files/2020/articulos-Tesis/sistema_somnolencia.pdf

\subsubsection{Sistema de Detección de Somnolencia}
En este trabajo de fin de grado, realizado por un alumno de la Universidad de La Laguna en el año 2022 se estudió el uso de los modelos de Redes Neuronales para la clasificación de imágenes. Enfocado en la resolución del problema de la somnolencia en los conductores. En el cual se utilizó el lenguaje de programación Python, junto con diversas librerías que facilitan la integración del modelo, y otras que ayudan en la captura de las imágenes.\cite{EstadodelAarte8}

%https://riull.ull.es/xmlui/bitstream/handle/915/30312/Sistema%20de%20deteccion%20de%20somnolencia.pdf?sequence=1&isAllowed=y


\subsubsection{Desarrollar un prototipo de reconocimiento facial basado en Machine Learning para detectar estado de Somnolencia en conductores de una cooperativa de transporte. }

En este trabajo, realizado por alumnos de la Universidad de GUAYAQUIL en el año 2020-2021 se plantea el desarrollo un prototipo para la detección de la somnolencia del conductor de una cooperativa de transporte el cual dicho conductor se había sobrepasado el límite de horas de trabajo, usando la técnica de reconocimiento facial, basándose específicamente en el estado de los ojos. Para ello se realizó una investigación bibliográfica relacionada con patrones biométricos, inteligencia artificial y programación mediante Machine Learning, así como, las principales variables que permiten identificar un estado de somnolencia. Dentro de esta investigación también se determinan cuáles son los algoritmos a utilizar (CV2, Imutils, etc.) siendo la herramienta Python y su librería principal Visión por Computadora las seleccionadas para el estudio.\cite{EstadodelAarte9}


\subsubsection{Sistema basado en la detección y notificación de somnolencia en conductores de autos }
En este trabajo, realizado por alumnos de la Universidad de Córdoba en el año 2015 se plantea el desarrollo que permite alertar a los conductores en estado de somnolencia leve, utilizando la tecnología de reconocimiento de objetos de Kinect y la librería OpenCV con el lenguaje C\# para el reconocimiento de imágenes. Además, se diseña una aplicación móvil del sistema operativo Android para la notificación de somnolencia utilizando una conexión socket tipo TCP. Para el procesamiento de imágenes, se utilizó el algoritmo Viola-Jones, el cual se basa en una nueva forma de representación de imágenes llamada Integral Image, permitiendo que las características del detector se conmuten rápidamente.\cite{EstadodelAarte10}



\subsubsection{Detección de somnolencia para conducción sin accidentes}
En este trabajo de fin de grado, realizado por un alumno de la Universidad de Alicante en el año 2022 se propuso crear una aplicación real para detectar la somnolencia al volante haciendo énfasis a un bajo coste económico. Donde se realizó una comparativa entre una solución mediante Machine Learning (ML) y Principal Component Analysis (PCA).\cite{EstadodelAarte11}


%http://hdl.handle.net/10045/124695


\subsubsection{Implementación de un sistema web con geolocalización para medir la transaccionalidad del portal ABC de la democracia para el consejo nacional electoral (CNE)}
En este proyecto de titulación de la Universidad de Guayaquil del año 2016, se 
implementa un sistema de geolocalización para poder tener una mejor visión a través 
de mapas virtuales de las personas y de las zonas geográficas de los productos o 
servicios que se quieran introducir, apoyado en un cien por ciento de las 
herramientas que Google Maps ofrece, se utilizó una aplicación popular y gratuita 
para poder analizar los datos obtenidos con la localización, Google Analytics. En este 
proyecto, sólo se pretendía visualizar mapas en la web, por lo que sólo fue necesario 
usar los servicios que ofrece Google Maps por ser una aplicación gratuita con la 
ayuda del api Javascript de Google Maps, se tuvieron en cuenta las limitaciones con 
respecto al código libre, pero estás no afectaron el desempeño del sistema; los datos 
obtenidos se recopilaban en una base de datos en MySQL.\cite{EstadodelAarte12}

\subsubsection{Diseño e implementación de un sistema de geolocalización en interiores para plataforma Android vía la red enterprise WLAN de la PUCP}
En este proyecto de titulación de la Pontifica Universidad Católica Del 
Perú del 2016 se desarrolló una aplicación móvil capaz de geolocalizar a un usuario 
dentro de las instalaciones de la universidad usando la técnica de Huellas de Señal 
(fingerprinting), que minimiza el error debido a reflexiones y obstáculos, basada en 
el estimador de máxima verosimilitud (ML por sus siglas en inglés Maximum 
Likehood) junto a las mediciones de señal de los Access Points cercanos usando la 
red Wi-Fi. La tecnología de radiofrecuencia que se usó fue la de redes inalámbricas 
de área local, Wi-Fi. Que ofrece conectividad por radiofrecuencia, con alcance local a 
un dispositivo que envíe datos Ethernet desde la ubicación del mismo hasta una 
conexión a la red fija, que en este caso la universidad contaba con 32 access points 
que recibirían la señal de datos a través de cobre o fibra. La técnica del fingerprinting, 
que está dirigida a geolocalización en interiores, consiste en un mapeo de datos que 
se encuentran en un escenario para luego asociarlos a una localización y 
almacenarlos en una base de datos, para estimar la localización más probable se 
utilizó el algoritmo de ML basado en el teorema de Bayes de probabilidad. En las 
conclusiones señalan que este sistema obtuvo una precisión del 100\% en la 
estimación del ambiente con un error menor de 2.4m en las pruebas realizadas.\cite{EstadodelAarte13}

\subsubsection{Geolocalización con LoRa mediante multilateración}
En esta tesis de la Universidad de la República de Uruguay del 2018 se desarrolló 
un prototipo para la geolocalización animal en estudios de comportamiento. Para la 
geolocalización se usó una tecnología nueva emergente llamada LoRa, tecnología de 
radiofrecuencia de bajo consumo energético y largo alcance; usando un método de 
multilateración para la geolocalización, técnica de navegación basada en la medición 
de la diferencia de distancia a dos estaciones en posiciones conocidas, el proyecto se 
conformó por tres puntos fijos o access points y nodos, que son los dispositivos 
llevados por los animales de radio frecuencia. Los nodos envían señales de radio 
frecuencia cada cierto tiempo, la señal emitida se recibe por los puntos fijos que, a 
su vez, esa señal genera metadatos que se almacenan en una base de datos para 
posteriormente realizar los cálculos en Geolocator , sistema de geolocalización 
desarrollado en Python, y así, obtener la posición geográfica del nodo. Se concluyó 
que el uso de LoRa para la geolocalización tiene gran potencial y que el alcance de 
las señales fue eficiente, de igual manera se trata de una tecnología de bajo consumo 
y que mantuvo los dispositivos con energía por meses.\cite{EstadodelAarte14}
\subsubsection{Propuesta de un sistema de geolocalización y monitoreo vía GPS/GSM/GPRS aplicado a un pulsómetro para personas con enfermedades cardiovasculares}
Tesis del Instituto Politécnico Nacional de la Escuela Superior de Ingeniería Mecánica 
y Eléctrica Unidad Zacatenco del año 2018, donde se empleó un sensor de pulso 
cardiaco el cual proporciona información en tiempo real de los latidos del corazón
mientras que un microcontrolador procesa los datos y, en caso de que se obtengan 
los datos de que se está presentando una taquicardia, el microcontrolador solicita la 
ubicación al módulo GPS y envía un mensaje de texto a través de GSM/GPRS a la 
persona designada.\cite{EstadodelAarte15}

\subsubsection{Influencia de un sistema de geolocalización en el control y monitoreo de vehículos con dispositivos GPS en una empresa logística}
Tesis del año 2015 de la Universidad César Vallejo de Perú donde se investiga de manera profunda las características y detalles de la tecnología GPS para determinar la influencia de un sistema de geolocalización en el control y monitoreo de vehículos con esta tecnología en una empresa logística. \cite{EstadodelAarte16}

\subsubsection{Diseño de la red de acceso LTE en el distrito de Jesús María}
Tesis del año 2017 de la Pontifica Universidad Católica del Perú que tiene por objetivo analizar y diseñar una red usando la tecnología LTE, al desarrollar el proyecto se conocen las ventajas y desventajas de usar esta red así como la posibilidad de implementarla, también se realizan los cálculos de las coberturas y se dan a conocer las velocidades de enlace y el uso de diversos anchos de banda para su despliegue.\cite{EstadodelAarte17}

\newpage
\section{Capítulo III: Análisis}

Partiendo de la propuesta de solución y la metodología \emph{Top-down}, que nos permite dividir un sistema en módulos para un análisis por partes, el sistema se dividirá en tres principales módulos: el Módulo de Comunicaciones, el Módulo Central de Procesamiento y el Módulo de la Estación Base, figura \ref{fig:topdown}.  

\begin{center}
  \includegraphics[scale=0.55]{imagenes/topdowngeneral}
\captionof{figure}{Diagrama del sistema basado en la metodología Top-Down}
 \label{fig:topdown}
\end{center} 

A continuación, se desglosan cada uno de los módulos: \\

\textbf{Módulo Central de Procesamiento:}\\

El módulo Central de procesamiento estará compuesto por un microordenador que será colocado dentro de un automóvil. Este microordenador será alimentado por el corriente proporcionado por dicho automóvil. Además, contará con una cámara digital que analizará el rostro del conductor después de que este encienda el automóvil. A este microordenador también le será acoplado un dispositivo que sea capaz de utilizar redes de telecomunicaciones móviles, esto para que sea posible la conexión con la Estación Base. Finalmente, también contará con una alarma para alertar al conductor si este presenta un estado de somnolencia. \\


\textbf{Módulo de Comunicaciones}\\

Una vez que se tengan los datos recibidos por el módulo de procesamiento, este módulo se encargará de la transmisión de los datos hacia el módulo de estación base por medio de la tecnología  4G/LTE. Donde la información recibida por el módulo de procesamiento se enviará en forma de paquetes hacia las antenas 4G y serán subidas a la nube para después ser descargadas o consultadas por el módulo de Estación Base. La tasa de datos con la que el transceptor funcionará se especifica en la sección \ref{sec:ASD} y se cumplirán los parámetros establecidos en el teorema de Shannon-Hartley para garantizar la probabilidad de error en la transmisión. En caso de no contar con cobertura, quedarán almacenados las incidencias en una unidad externa para que puedan seguir los mismos pasos antes mencionados teniendo en cuenta el retraso de estos una vez que esta se restablezca. \\

 
\textbf{Módulo de Estación Base}\\

Este módulo estará compuesto por una aplicación web y una base de datos que se encargará de almacenar las incidencias de los conductores para ser corroborados por un administrador posteriormente, esto con la intención de descartar un falso positivo y realizar los ajustes necesarios al sistema. 



\subsection{Análisis y delimitación de la zona geográfica  }
El sistema está dirigido principalmente para empresas cuya actividad esté enfocada al transporte de material o personas. Debido a que una parte fundamental del proyecto es la portabilidad, el sistema requiere de un servicio de acceso al internet. Por tanto, se decidió utilizar redes móviles celulares para cumplir con dicho requerimiento.  

\begin{center}
  \includegraphics[scale=0.5]{imagenes/MapaCoberturaMexico}
\captionof{figure}{Mapa de cobertura 3G/4G/5G en México.\cite{CoberturaNacional}}  
 \label{fig:mapacoberturaN}
\end{center} 

Tomando en cuenta la información del Mapa de cobertura 3G/4G/5G, de redes móviles en México, mostrado en la figura \ref{fig:mapacoberturaN}, se observa que las zonas con mayor cobertura son principalmente las que cuentan con mayor densidad de población, por tanto, se plantea que su funcionamiento sea principalmente en la Ciudad de México, debido a que cuenta con mayor infraestructura en dichas redes.

\begin{center}
  \includegraphics[scale=0.9]{imagenes/CoberturaCDMX}
\captionof{figure}{Mapa de cobertura 3G/4G/5G en la Ciudad de México.\cite{CoberturaNacional}}
 \label{fig:mapacoberturaCDMX}
\end{center}

\clearpage


\subsection{Análisis del Módulo Central de Procesamiento}

\textbf{Análisis de Requerimientos Funcionales}
\begin{table}[H]
\centering
\caption{RF01- Verificar estado funcional de periféricos}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Verificar estado funcional de periféricos}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema verificará el estado funcional de los distintos periféricos utilizados en el Módulo Central de Procesamiento\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microodenador\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Zumbador\\
\quad $\bullet$ Antena
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Utilizando métodos de comprobación ofrecidos por cada uno de las libererías de los periféricos, se comprobará que funcionen de manera correcta, en caso contrario se enviará una alerta al módulo de Estación Base.
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{RF02- Establecer conexión con la base de datos }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Establecer conexión con la base de datos}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:} Se realizará conexión con la Base de Datos.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microodenador\\
\quad $\bullet$ Base de Datos

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Se podrá acceder a la información almacenada y registrar nuevos datos en la base de datos.
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{RF03- Activar Alarma}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Activar Alarma}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema activará el zumbador en caso de que el Submódulo de Visión Artificial detecte somnolencia en el conductor. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microodenador\\
\quad $\bullet$ Zumbador Pasivo

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Utilizando métodos de comprobación ofrecidos por cada uno de las libererías de los periféricos, se comprobará que funcionen de manera correcta, en caso contrario se enviará una alerta al módulo de Estación Base.
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{RF04- Enviar Video de Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF04}}                                              & \emph{Enviar Video de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  Se enviará el video de la incidencia hacia un servicio de almacenamiento en la nube.  \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Video\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El video será almacenado y se obtendrá un ID del video. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}



\begin{table}[H]
\centering
\caption{RF05- Realizar Reporte de Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Realizar Reporte de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:} Se realizará una consulta previa a la Base de Datos para obtener el nombre y apellidos del conductor de acuerdo al id del conductor. Se registrará la fecha, hora y ubicación geográfica del momento en que se detectó la somnolencia. Los datos recabados serán usados en la creación de un documento que contenga los datos de la incidencia. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Id del Conductor  \\
\quad $\bullet$ Nombre de Conductor\\
\quad $\bullet$ Apellidos de Conductor \\
\quad $\bullet$ Fecha\\
\quad $\bullet$ Hora\\
\quad $\bullet$ Ubicación\\
\quad $\bullet$ Id Video\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El documento de la incidencia contendrá los campos necesarios para registrar la incidencia en la base d datos. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{RF06- Enviar Reporte de Incidencia a la Base de Datos }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF06}}                                              & \emph{Enviar Reporte de Incidencia a la Base de Datos}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se enviará el reporte de incidencia hacia la Base de Datos. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Reporte de Incidencia  \\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Reporte de Incidencia será almacenado en la Base de Datos. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}



\begin{table}[H]
\centering
\caption{RF07- Eliminar Video de Incidencia  }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF07}}                                              & \emph{Eliminar Video de Incidencia }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se eliminará el video de Incidencia del almacenamiento externo después de ser almacenado en la nube.   \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Reporte de Incidencia  \\
\quad $\bullet$ URL del Video  \\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El video de la incidencia será eliminado.  
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\clearpage
\subsubsection{Análisis y Elección del microordenador}\label{sec:microordenador}

Como ya se mencionó en la sección \ref{solucion}, se hará uso de un microordenador para permitir que el sistema sea portátil y pueda funcionar dentro de un automóvil.Por tanto, se realizó una investigación de los modelos disponibles y de mayor aceptación en el mercado, figura \ref{tab:microordenador}.

\begin{table}[h]
\centering
\caption{\label{tab:microordenador} Comparación de microordenadores}
\begin{tabular}{{|m{0.12\linewidth}|m{0.2\linewidth}|m{0.15\linewidth}|m{0.15\linewidth}|m{0.15\linewidth}|m{0.08\linewidth}|}}
\hline
\textbf{Nombre}& \textbf{CPU} & \textbf{RAM}  & \textbf{GPU} & \textbf{Alimentación}                                                 & \textbf{Precio} \\ \hline
Google Coral Dev Board & NXPiMX 8M SoC Dual Core 1.2 GHz & 2GB DDR3                                                &  Hexa Core A-72 2GHz & 5V DC & \$4289 \\ \hline
Rasperry Pi 4B & 1.5 GHZ 64 bit QuadCore Cortex A-72 & 1GB, 2GB, 4GB, 8GB DDR4 & No cuenta con GPU & 5V vía USB-C o puerto GPIO& \$3956\\ \hline
Asus TinkerBoard 2S & Mali-G52 MP6  con 6 núcleos & 2GB/4GB dual- channel LPDDR4 & Integrated GC7000 Lite Graphics  & 12V-19V   & \$7169  \\ \hline
NVIDIA Jetson Nano & ARM A57 2.1 GHz de cuatro núcleos & 4 GB de LPDDR4 de 64 bits & NVIDIA Maxwell de 128 núcleos CUDA & 5V/4A & \$3,799 \\ \hline
\end{tabular}
\end{table}

Los parámetros que se tomaron en cuenta para la elección de que microordenador utilizar fueron los siguientes:
\begin{itemize}
\item Precio
\item Voltaje necesario
\item RAM
\item Módulos compatibles
\end{itemize}

Si bien la Rasperry Pi es uno de los microordenadores con más aceptación por parte de la comunidad, esta no cuenta con una GPU, lo cual reduce significativamente su rendimiento en tareas relacionadas con IA que requieren de mayor procesamiento. Por lo que al buscar alternativas de microordenadores que contaran una GPU, y basándose en él estudio \cite{nanovspi} se concluyó , que la Nvidia Jetson Nano, ofrece una mayor ventaja en comparación a la rasperry Pi en cuanto a procesamiento y eficacia en tareas que involucran visión artificial. A pesar de que Asus y Google Coral Dev Board  cuenta con una GPU, su potencia no supera a la ofrecida por Jetson Nano \cite{deepedgebench}  y su precio es considerablemente mayor como se puede apreciar en la tabla \ref{tab:microordenador}, por lo cual se descartaron como opción viable. 
Debido a lo anterior, se concluyó que la Jetson Nano representa la mejor opción para el desarrollo del presente proyecto debido a su bajo costo, bajo consumo de energía y mejor rendimiento en comparación a sus alternativas. 






\clearpage
\subsubsection{Análisis y Elección de la alarma }\label{sec:alarma}

Dentro de la búsqueda de modelos de alarma se encontraron dos tipos de zumbadores, el zumbador activo y zumbador pasivo, donde el primero produce un tono audible fijo, al aplicar una tensión de corriente directa. Mientras que el segundo requiere de una señal oscilante, generalmente de tipo PWM, que indique la frecuencia y la duración de la señal.  \\

Para la elección de la alarma se obtuvieron dos de los principales modelos comerciales de cada tipo de zumbador mencionado: 

\textbf{Buzzer Pasivo KY-006}

\begin{itemize}
\item Voltaje: 1.5 V - 5 V 
\item Rango de frecuencia: 1.5 Hz - 2.5kHz 
\item Decibeles: 72 DB
\item Precio: \$50 
\end{itemize}

\textbf{Buzzer Activo KY-012  }

\begin{itemize}
\item Voltaje: 3.5 V - 5.5 V 
\item Rango de frecuencia: 300 Hz - 2.5kHz
\item Decibeles: 85 DB
\item Precio: \$71 
\end{itemize}

Debido a la posibilidad que ofrece el zumbador pasivo para controlar el tono y la duración del mismo, además de su bajo coste en comparación con el zumbador activo KY-012, se optó por el zumbador de tipo pasivo, específicamente el modelo KY-006, en cual se pueden configurar los tonos desde la Nvidia Jetson Nano por medio del lenguaje Python. 
\clearpage  



\subsubsection{Análisis y Elección de la unidad de almacenamiento externa}\label{sec:almacenamientoexterno}

Para utilizar una NVIDIA Jetson Nano, se requiere una tarjeta SD que contenga el sistema operativo y las aplicaciones. La tarjeta SD debe tener una capacidad de almacenamiento de al menos 8 GB. 

\begin{table}[h]
\caption{Cuadro Comparativo de módelos de MicroSD}
\begin{tabular}{{|m{0.12\linewidth}|m{0.15\linewidth}|m{0.1\linewidth}|m{0.1\linewidth}|m{0.13\linewidth}|m{0.13\linewidth}|m{0.1\linewidth}|}}
\hline
Micro SD  & Almacenamiento  & Speed class  & Video class  & Velocidad de escritura  & Velocidad de Lectura  & Precio \\ \hline
SanDisk Extreme A2 & 32-256 (MAX 1T)GB  & Clase 30/U3  & V30 & 90 MB/s  & 160 MB/s  & \$1041  \\ \hline
Kingston ENDURANCE  & 32-256 (MAX 1T)GB  & Clase 10/U1   & - & 45 MB/s  & 95 MB/s  & \$628  \\ \hline
Samsung PRO Plus  & 128-512 GB  & Clase 10/U3   & V30  & 120 MB/s  & 160 MB/s  & 160 MB/s \$883 (128) \\ \hline
Kingston Canvas React Plus V90 Card  & 64-256 GB  & Clase 10/U3  & V90  & 90 MB/s  & 180 MB/s  & \$3596 \\ \hline

\end{tabular}
\end{table}

Tomando en cuenta la capacidad mínima de almacenamiento y el costo de la misma se decidió usar una unidad de almacenamiento \emph{Kingston ENDURANCE} de 32 GB para el almacenamiento externo.   

\clearpage
\subsubsection{Análisis y Elección de lenguajes de programación para el microordenador}

Lo que se debe de considerar para la elección de un lenguaje de programación, es que la programación orientada a la inteligencia artificial es diferente al paradigma de la programación convencional. En esta última, el usuario le indica a la máquina exactamente lo que tiene que hacer, mientras que en Machine learning, se le enseña a programarse sola. Lo cúal se ejemplifica en el siguiente gráfico:
\\
\begin{center}
  \includegraphics[scale=0.3]{imagenes/programaclasico}
\captionof{figure}{Programa clásico vs Machine Learning}
 \label{fig:pcvsml}
\end{center}


El proceso de trabajo para aprendizaje automático es muy diferente a la construcción de una aplicación convencional. Por este motivo, la manera de utilizar los lenguajes de programación es diferente. Se deben de tomar en cuenta las características que estos utilizan, así como sus enfoques y paradigmas.\\

Uno de los factores importantes a considerar al momento de elegir un lenguaje de programación orientado a machine learning, es la popularidad el mismo, ya que esta es una señal de la aceptación por parte de la comunidad. A su vez, su el soporte es tanto o mas importante, ya que podemos darnos una idea si dicho lenguaje posee las herramientas adecuadas que se acoplan a nuestras necesidades. La velocidad de ejecución es otro factor importante, sobre todo cuando se requiere una minusiocidad en la ejecución de procesos y el cuidado de la memoria .Finalmente, la versatilidad del lenguaje es otro factor relevante, ya que, si el lenguaje fue diseñado con una determinada tarea o propósito en mente, este será mucho más eficiente y productivo.\\

A continuación, se listan algunos de los lenguajes de programación más populares en el campo de Machine Learning:\\

\begin{itemize}

\item Python
Es uno de los lenguajes más populares en la comunidad de aprendizaje automático y visión artificial debido a su facilidad de uso, gran cantidad de bibliotecas y frameworks disponibles y gran comunidad de desarrolladores.

\item C++: Es un lenguaje de programación de alto rendimiento, es muy adecuado para proyectos de visión artificial que requieren de un gran rendimiento.

\item Matlab: Es un lenguaje de programación y entorno de desarrollo específicamente diseñado para matemáticas y cálculo científico, es muy utilizado en el campo de la visión artificial y procesamiento de imágenes.

\item Java: Es un lenguaje de programación multiplataforma, es muy popular en el desarrollo de aplicaciones y se utiliza en proyectos de visión artificial.

\item R: Es un lenguaje de programación especializado en estadística y análisis de datos. Es ampliamente utilizado en investigación académica, ciencia de datos y análisis estadístico en ciencias sociales, económicas, financieras y biotecnología entre otros.

\end{itemize}

A continuación se presenta una tabla comparativa de las características que se tomaron en cuenta para la elección sobre que lenguaje utilizar.

\begin{table}[h]
\centering
\caption{\label{tab:lenguajes} Tabla Comparativa Lenguajes de Programación}
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Lenguaje} & \textbf{Popularidad} & \textbf{Versatilidad} & \textbf{Velocidad} & \textbf{Soporte} \\ \hline
Python            & Alta                 & Alta                  & Moderada           & Alta             \\ \hline
C++               & Baja                 & Alta                  & Alta               & Moderado         \\ \hline
R                 & Alta                 & Moderada                  & Moderado           & Bajo             \\ \hline
Matlab            & Baja                 & Moderada              & Moderada           & Bajo             \\ \hline
Java        & Moderada             & Moderada              & Baja               & Moderado         \\ \hline
\end{tabular}

\end{table}


Debido a que en el presente proyecto se realizará la integración de sistemas enfocados a Machine Learning y a su vez a la programación orientada a objetos, Python representa la mejor opción para ser implementado, ya que este lenguaje permite desarrollar ambos ámbitos de una manera integral\cite{python}.Por lo cual será utilizado a lo largo del proyecto.
\clearpage
\subsubsection{Análisis y Elección de herramientas de programación}

\begin{itemize}

\item \textbf{Tensorflow}

Es una plataforma de código abierto para el aprendizaje automático y el procesamiento de datos. Permite  definir, optimizar y ejecutar operaciones matemáticas, especialmente aquellas que involucran tensores, que son arrays multidimensionales de datos.Una de las principales ventajas de esta herramienta es su capacidad para ejecutarse en diferentes plataformas, desde dispositivos móviles hasta servidores de alta capacidad y sistemas en la nube.

\item \textbf{Keras}

Es una biblioteca de software de código abierto para el desarrollo de redes neuronales escrita en Python.Permite la construcción de modelos mediante la definición de capas y la conexión de estas capas para crear una red neuronal completa. También proporciona una serie de funciones de alto nivel para la configuración de optimizadores, pérdidas y métricas, lo que facilita el proceso de entrenamiento y evaluación de un modelo.


\item  \textbf{OpenCV}

Es una biblioteca de procesamiento de imágenes de código abierto, ampliamente utilizada en la investigación académica y la industria. Permite el análisis de imágenes, la detección de objetos, el reconocimiento de patrones y la segmentación de imágenes.




\end{itemize}





\clearpage
\subsubsection{Análisis del Submódulo Visión Artificial}


\textbf{Submódulo de Visión Artificial:}\\

El submódulo de visión artificial tiene como objetivo realizar la detección de somnolencia del conductor, analizando el rostro con distintas técnicas y algoritmos de visión artificial. 

Si el conductor presenta un estado de somnolencia, se activará una alarma para alertar al conductor. A su vez el sistema tomará un videoclip dónde se apreciará el momento en que el conductor presentó un estado de somnolencia. \\ 

Se tomarán en cuenta los siguientes parámetros para determinar si el conductor presenta o no signos de somnolencia:  

Estado de los ojos (cerrados, abiertos). \\ 

Estado de la boca (cerrada o abierta). \\  

Bostezo. 



\begin{itemize}

\item \textbf{Requerimientos Funcionales}
\begin{table}[h]
\centering
\caption{RF01- Capturar Video en Tiempo Real}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Capturar video en tiempo real}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema capturará video en todo momento\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Cámara Digital\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Con el uso de una cámara digital, se capturará video en tiempo real.
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{RF02- Ingresar al Campo Visual}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Ingresar al campo visual}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El conductor ingresará al campo visual de la cámara digital, posicionándose en el asiento del conductor\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Cámara Digital
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Utilizando el software de procesamiento de imágenes el sistema podrá detectar el rostro del conductor.
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{RF03- Reconocer Características Faciales}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Reconocer Características Faciales}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:} El sistema detectará la posición de los ojos y la boca del conductor a partir de la detección del rostro.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Método de Detección de Rostro\\
\quad $\bullet$ Cámara Digital
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Utilizando un método de detección de rostro el sistema podrá detectar el rostro del conductor.
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{RF04- Detectar signos de somnolencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Detectar signos de somnolencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema detectará el estado de los ojos y la boca, y analizará si estos corresponden a los signos de somnolencia del conductor.\\ \\ \textbf{Elementos:}
\\

\quad $\bullet$ Red Neuronal Convolucional
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema obtendrá el estado de somnolencia del conductor utilizando una red neuronal convolucional. 
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{RF05- Enviar señal de Alerta}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Enviar señal de alerta}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se enviará una señal de alerta al módulo central de procesamiento cuando se detecten signos de somnolencia en el conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microordenador\\
\quad $\bullet$ Zumbador

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El módulo Central de procesamiento activará la alarma al recibir la señal de alerta. 
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{RF06- Almacenar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Almacenar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Enviar señal de alerta}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se almacenará un fragmento del video en la memoria externa en caso de detectar somnolencia en el conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microordenador\\
\quad $\bullet$ Memoria Externa\\
\quad $\bullet$ Video
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Se guardará el video de incidencia en la memoria externa en caso de no contar con conexión inalámbrica, para ser enviada posteriormente a un almacenamiento en la nube. 
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\end{itemize}
\clearpage

\begin{center}

  \includegraphics[scale=.4]{imagenes/casosuso_vision}
\captionof{figure}{Diagrama de Casos de Uso - Submódulo de Visión Artificial}
 \label{fig:actividades}
 \end{center}
 
\textbf{Especificación de Casos de Uso}


\begin{table}[h]
\centering
\caption{Caso de Uso 01 - Ingresar al campo visual de la Cámara}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Ingresar al campo visual de la Cámara}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Conductor}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El conductor ingresesará al campo visual de la cámara al entrar al auto \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El conductor deberá encender el auto
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Automóvil
 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 02 - Capturar Video en Tiempo real}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Capturar Video en Tiempo real}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial capturara un video en tiempo real utilizando una cámara digital \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El conductor deberá encender el auto
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Automóvil\\
\quad $\bullet$ Cámara Digital

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 03 - Detectar Rostro}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Detectar Rostro}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial detectará el rostro del conductor. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El conductor deberá permanecer en el campo visual de la cámara
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Automóvil\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[h]
\centering
\caption{Caso de Uso 04 - Reconocer características faciales}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Reconocer características faciales}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial reconocerá características faciales tales cómo: ojos, boca \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber detectado previamente el rostro del conductor
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 05 - Detectar Signos de Somnolencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Detectar Signos de Somnolencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial detectará signos de somnolencia utilizando métricas de tiempo para los ojos y tomará en cuenta la apertura de la boca \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber extraído previamente la información de los ojos y boca
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}
 
\begin{table}[h]
\centering
\caption{Caso de Uso 06 - Enviar Señal de Alerta}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Enviar Señal de Alerta}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial,Módulo Central de Procesamiento}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial enviará una alerta al Módulo Central de Procesamiento para activar la alarma  
 \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber detectado signos de somnolencia en el conductor
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Alerta

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table} 


\begin{table}[h]
\centering
\caption{Caso de Uso 07 - Identificar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Identificar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo realizará un reporte de incidencia que contenga la fecha hora y lugar de la incidencia \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber extraído previamente la información de los ojos y boca
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

 
\clearpage 
\subsubsection{Análisis y Elección de la cámara digital}\label{sec:camara}

Para la búsqueda de modelos de cámaras digitales, se buscaron modelos que tuvieran compatibilidad con la Nvidia Jetson Nano debido a que el sistema será alojado en este micrordenador.  

Se optó por utilizar la cámara IMX219-160, ya que cuenta con hasta 8 Megapixeles de resolución, además de tener distintos los formatos de salida jpg, RAW, DNG O MP4. También cuenta con diferentes resoluciones de video que van desde 1080p hasta 480p a 30 cuadros por segundo. 

\begin{center}
  \includegraphics[scale=0.5]{imagenes/imx}
\captionof{figure}{Modulo de Cámara IMX219-160}
 \label{fig:CameraModuleV2}
\end{center}



\subsubsection{Análisis y Elección de algoritmos de visión artificial}

Existen varios métodos utilizados para detectar rostros en imágenes y videos, algunos de los más comunes son:

\begin{itemize}

\item \textbf{Detección de cascada de Haar:} Este método utiliza una cascada de clasificadores basados en características Haar para detectar rostros. El método es rápido y eficiente en términos de recursos, pero puede ser menos preciso que otros métodos.


\item \textbf{Métodos basados en aprendizaje automático:} Se utilizan algoritmos de aprendizaje automático para detectar rostros en imágenes y videos. Estos métodos suelen ser más precisos que los métodos basados en cascadas de Haar, pero requieren un gran conjunto de datos para el entrenamiento.

\item \textbf{Métodos basados en deep learning}: utilizan redes neuronales profundas para detectar rostros en imágenes y videos. Estos métodos suelen ser más precisos que los métodos anteriores, pero requieren un gran conjunto de datos para el entrenamiento y un gran poder de procesamiento.


\end{itemize}

Debido a que el presente proyecto busca conseguir un ahorro en procesamiento, se decidió a utilizar cascadas Haar para la detección de rostro, ya que estas tienen un tiempo de respuesta mayor y requieren menos procesamiento que los demás métodos mencionados \cite{facedetection}


\begin{table}[H]
\caption{Cuadro Comparativo - Algoritmos de Aprendizaje}
\begin{tabular}{{|m{0.1\linewidth}|m{0.25\linewidth}|m{0.25\linewidth}|m{0.25\linewidth}|}}
\hline
  & \emph{Aplicaciones} & \emph{Ventajas}  & \emph{Desventajas} \\ \hline
\emph{Neural Networks (CNNs)} & Se utiliza principalmente en las tareas de reconocimiento de imágenes y detección de objetos. Además de sistemas de recomendación y tareas de procesamiento de lenguaje.   & los resultados son más precisos, especialmente para los casos de uso de reconocimiento de imágenes/objetos, en comparación con otros algoritmos  & ara entrenarla se requiere una potencia de cálculo muy alta. Por lo tanto, no es muy rentable. \\ \hline
\emph{Long Short-Term Memory Networks} & Ideal para tareas como autocompletado de oraciones, generación de subtítulos y análisis de cuadros de video.  & Puede manejar la información en la memoria durante un largo período de tiempo en comparación con RNN.  & Se requiere una gran cantidad de computación y recursos para entrenar el modelo. \\ \hline
\emph{General Adversarial Networks (GANs)} & Utilizado en la industria creativa para la generación de objetos 3D. 

Útil en la edición de imágenes (Deepfake), generación de personajes de dibujos animados, ilustraciones para novelas, artículos, etc.  & Capaz de aprender la representación interna (distribuciones desordenadas y complejas) en cualquier dato.  & Cuando genera nuevos datos a partir de datos originales, no hay métrica de evaluación para juzgar la precisión de la salida. 

Se requiere mucho cómputo y tiempo para el entrenamiento del modelo  \\ \hline
\emph{Recurrent Neural Networks (RNNs) } & Se utiliza principalmente en los campos del procesamiento del lenguaje natural y el reconocimiento de voz. También es ideal para tareas como autocompletado de palabras, reconocimiento de texto y análisis de cuadros de video.  & Capacidad de recordar información a lo largo del período de entrenamiento. Posibilidad de procesar entradas de cualquier longitud   & Los cálculos requieren mucho tiempo debido a su naturaleza recurrente. 

Dificultad de acceder a la información desde hace mucho tiempo.  \\ \hline
\emph{Multilayer Perceptron?s (MLP?s)} & Problemas de clasificación.  

Voz, reconocimiento de imágenes y compresión de datos.  & Puede distinguir datos que no son linealmente separables. 

No hace ninguna suposición con respecto a las funciones de densidad de probabilidad  & Al actualizar los pesos en capas, la red puede atascarse en un mínimo local que puede dificultar la precisión.  \\ \hline

\end{tabular}
\end{table}

Debido a que el presente proyecto se basará en el reconocimiento de imágenes y de clasificación de información, se tomó la de decisión de utilizar una CNN o Red Neuronal Convolucional para el reconocimiento de ojos abiertos o cerrados dentro de la imagen, esta aprende directamente de los datos, sin necesidad de extraer características manualmente.  Estas redes son particularmente útiles para encontrar patrones en imágenes para reconocer objetos, caras y escenas, además de permitir su implementación en video en tiempo real, lo cual es indispensable para el presente proyecto.  

\subsubsection{Análisis y Elección del modelo de Red Neuronal}

Debido a que el presente proyecto se plantea resolver un problema de clasificación, a continuación se analizará que tipos de modelos de redes neuronales son los más aptos para la resolución de los mismos.

\begin{itemize}
\item Redes Neuronales Unicapa
En el caso mas simple de una red neuronal, las neuronas de la capa de entrada se limitan a recibir las señales de entrada. Estas se encargan de redistribuir estas señales a las neuronas de la capa de salida. A esto se le llama una red neuronal unicapa.


\begin{center}
  \includegraphics[scale=0.4]{imagenes/unicapa}
\captionof{figure}{Redes Unicapa}
 \label{fig:boost}
\end{center}


Utilizando la herramienta de \emph{PlayGround Tensorflow} podemos observar la eficacia de este tipo de redes al resolver problemas de clasifiación.
Si se le pide a esta Red Neuronal que sombree el área del color de los puntos mostrados dentro de la gráfica, se puede observar que es incapaz de realizarlo de manera correcta.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/unicapa2}
\captionof{figure}{Red Neuronal Unicapa}
 \label{fig:boost}
\end{center}


\item Redes Neuronales Multicapa


Existe otro tipo de módelo de red neuronal que utiliza capas intermedias entre la capa de salida y la capa de entrada, a estas redes se les conoce como redes profundas o redes multicapa.

\begin{center}
  \includegraphics[scale=0.7]{imagenes/multicapa}
\captionof{figure}{Redes Neuronales Multicapa}
 \label{fig:boost}
\end{center}

En la siguiente figura se puede apreciar que las redes neuronales multicapa tienen una eficiencia mayor a la hora de realizar el mismo problema de clasificación de puntos.Sin embargo, aún no puede resolver este problema correctamente. 


\begin{center}
  \includegraphics[scale=0.4]{imagenes/capasocultas}
\captionof{figure}{Redes Neuronal con 2 Capas Ocultas de 4 Neuronas cada una}
 \label{fig:boost}
\end{center}

\item \textbf{Funciones de Activación}

Una función de activación es un filtro o umbral que modifica o impone límites en los valores resultantes de una capa en una red neuronal. A continucación se muestran los resultados al resolver el mismo problema de clasificación de puntos de colores utilizando distintas funciones de activación.

\begin{itemize}
\item \textbf{ReLU}
Esta función de activación consiste en anular los valores de entrada negativos y conservar los valores positivos con sus valores originales.

\begin{center}
  \includegraphics[scale=0.4]{imagenes/funrelu}
\captionof{figure}{Representación Gráfica de la Función ReLu}
 \label{fig:boost}
\end{center}


\begin{center}
  \includegraphics[scale=0.4]{imagenes/relu}
\captionof{figure}{Redes Neuronal con 2 Capas Ocultas de 4 Neuronas cada una utilizando la función de Activación ReLu}
 \label{fig:boost}
\end{center}

\item \textbf{Tanh}
La función de la tangente hiperbólica toma cualquier valor real como valores de entrada y de salida en el rango de -1 a 1. Cuanto mayor sea la entrada, más cerca estará del valor de salida de 1.0. Por otro lado, mientras sea menor sea la entrada, el valor de salida se aproximará mas a -1.0


\begin{center}
  \includegraphics[scale=0.2]{imagenes/funtanh}
\captionof{figure}{Representación gráfica de la función Tangente Hiperbólica}
 \label{fig:boost}
\end{center}




\begin{center}
  \includegraphics[scale=0.4]{imagenes/tanh}
\captionof{figure}{Redes Neuronal con 2 Capas Ocultas de 4 Neuronas cada una utilizando la función de Activación Tanh}
 \label{fig:boost}
\end{center}

\end{itemize}
Existe un tipo de Red Neuronal que integra los puntos anteriormente vistos: capas ocultas y funciones de activación. Este tipo de red se le conoce como Red Neuronal Convolucional. Cómo su nombre lo indica, estas redes se basan en el uso de la operación de convolución, además de hacer uso de las capas de ocultas y funciones de activación. Estas redes son de las mas eficientes en el campo de visión artificial. \cite{Referencia0}. Por lo tanto, se decidió hacer uso de una red convolucional para cumplir los requisitos previamente planteados.

\end{itemize}

\newpage

\subsection{Análisis del Módulo de Comunicaciones}
Los sistemas automatizados de comunicación, mayormente inalámbricos, se encargan de recopilar datos remotos y transmitir la información.
La tecnología previamente elegida para la implementación de este módulo es la red 4G/LTE, su estándar es establecido por el 3GPP (Proyecto de asociación de tercera generación) donde establece sus especificaciones en la versión 8 de sus estándares, el cual clasifica hasta 13 categorías LTE\cite{Referencian14}. En estas categorías se especifica la velocidad máxima de carga y descarga, siendo la categoría 0 la velocidad más baja.
En la Tabla \ref{tab:CLTE} se observan las categorías LTE que existen junto con su velocidad máxima de bajada y subida,de la categoría 0 a la 5 se definen para equipos de usuarios, es decir, telefonía celular. 
Las antenas de la red 4G pueden conectarse a la red LTE-M que forma parte de la tecnología LPWAN sin necesidad de una puerta de enlace y con una velocidad de hasta 5Mbps. 

\begin{table}[H]
	\begin{center}
	\caption{\label{tab:CLTE} Categorías LTE}
\begin{tabular}{| c | c | c |}
\hline

Categoría & Velocidad Máxima de Bajada(Mbps)& Velocidad Máxima de Subida (Mpbs \\ \hline
0 &  1 &  1   \\ \hline
1 &  10 &  5  \\ \hline
2 &  50 &  25   \\ \hline
3 & 100 &  50  \\ \hline
4 & 150 &  50  \\ \hline
5 & 300 &  75   \\ \hline
6 &  300 &  50  \\ \hline
7 &  300 &  150 \\ \hline
8 & 1200 & 600   \\ \hline
9 &  450 &  50  \\ \hline
10 &  450 &  100  \\ \hline
11 &  600 &  50 \\ \hline
12 &  600 &  100  \\ \hline
13 & 390 &  150  \\ \hline

\end{tabular}

\end{center}
\end{table}

Para este sistema, el análisis debe cumplir con los parámetros que dicta el teorema de Shannon-Hartley establece que, dado un canal con ruido con una capacidad $C$ e información transmitida en una tasa $R$ entonces si $R<C$ existe una técnica de codificación que permite que la probabilidad de error en el $Rx$ se reduzca. Se debe cumplir que la tasa de bits debe ser siempre menor a la capacidad del canal.

Este análisis se divide en:
\begin{itemize}
\item Telemetría:\\ El módulo de telemetría es el encargado de recopilar, procesar y transmitir las coordenadas de la ubicación geográfica del conductor a la estación base que se encarga de monitorear los datos obtenidos.

\item Datos:\\ El encargado de recopilar, procesar y transmitir los fotogramas que el sistema identifica como somnolencia en el conductor, así como un mensaje informativo.

\item Telemetría:\\ Encargado de revisar la cobertura de la zona o regiones presentes en el alcance del sistema.
\end{itemize}

\subsubsection{Análisis del Submódulo de Telemetría }
El objetivo que tiene el módulo de telemetría es mandar el posicionamiento mediante coordenadas (latitud y longitud) del vehículo en movimiento en tiempo real. Las coordenadas serán mandadas en forma de cadena de texto, teniendo un aproximado de hasta 300 bits, otro punto a considerar es el periodo de tiempo entre el envío de cada posición, al tratarse de un vehículo en movimiento y la velocidad máxima siendo regida por Semovi (Secretaría de movilidad de la ciudad de México) que dicta una velocidad promedio de entre 50-80 km/h\cite{Referencian15}.

Se propone una velocidad de 60 km/h:

\begin{equation*}
60 \frac{km}{h} \cdot \frac{1000m}{1km}\cdot \frac{1h}{60min} \cdot \frac{1min}{60s}= 16.6 \frac{m}{s}\approx1 7\frac{m}{s}
\end{equation*}


El automóvil se desplaza aproximadamente 17 metros en 1 segundo por lo que al realizar el envío en periodos de 10 segundos, se  garantiza el trazado de la ruta en el mapa. Teniendo 170 metros recorridos cada 10 segundos del viaje.
Verificando que se cumpla el Teorema de Shannon-Hartley  tenemos:
\begin{equation*}
300 bits \cdot 10 s=3kbps
\end{equation*} 
y la máxima tasa de datos que el transceptor tiene es de 5 Mbps.

Cumpliéndose la relación establecida de $R<C$.
\begin{equation*}
3kbps<5 Mbps
\end{equation*}

\subsubsection{Análisis y Elección de Protocolos de comunicación inalámbrica  }
Debido a que el presente proyecto tiene como parte fundamental la portabilidad y la transferencia de contenido multimedia, y habiendo definido que para su desarollo se utilizará un microordenador, se requiere una interfaz de comunicación inálmbrica con amplia cobertura. A continuación se muestra una comparación de los estándares de comunicación inalámbrica más utilizados enfocados a sistemas portátiles.

\begin{table}[h]
\caption{\label{tab:redes} Comparación entre Redes Inalámbricas}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
        & Espectro                                                                 & \begin{tabular}[c]{@{}l@{}}Ancho de\\ Banda\end{tabular} & Costo    & \emph{BitRate} & Escalabilidad & \begin{tabular}[c]{@{}l@{}}Inmunidad a \\ la Interferencia\end{tabular} \\ \hline
LTE-M   & \begin{tabular}[c]{@{}l@{}}Sin licencia\\ 869 MHz\\ 915 MHz\end{tabular} & 100kHz                                                   & Moderado & 1Mbps   & Alta          & Moderada                                                                \\ \hline
NB-IoT  & \begin{tabular}[c]{@{}l@{}}Sin licencia\\ 433 MHz\end{tabular}           & \textless{}500kHz                                        & Moderado & 200kbps & Alta          & Baja                                                                    \\ \hline
SigFox  & \begin{tabular}[c]{@{}l@{}}Con licencia\\ 700-900 MHz\end{tabular}       & 200kHz                                                   & Bajo     & 100bps & Baja          & Baja                                                                    \\ \hline
LoraWan & \begin{tabular}[c]{@{}l@{}}Con licencia\\ 700-900 MHz\end{tabular}       & 1.4MHz                                                   & Bajo     & 10kbps  & Moderada      & Muy Alta                                                                \\ \hline
\end{tabular}

\end{table}

De la Tabla 1\ref{tab:redes} las interfaces de comunicación que mas destacan por su cobertura y su tasa de transferencia de datos son LTE-M y NB-IoT. A continuación se realiza una comparación entre estas interfaces para poder definir cual será utilizada a lo largo del proyecto.


\textbf{LTE-M}

Es una tecnología de área amplia de baja potencia que admite IoT a través de dispositivos poco complejos y proporciona una cobertura extendida, al tiempo que permite la reutilización de la base instalada de LTE\\

Las redes LTE-M coexisten con las redes móviles 2G, 3G y 4G y se beneficiaan de todas las características de seguridad y privacidad de las redes móviles, como la confidencialidad de la identidad del usuario, la autenticación de la entidad, la privacidad, la integridad de los datos y la identificación del equipo móvil.

A continuación se describen las ventajas principales de LTE-M

\begin{itemize}
\item \textbf{Ahorro de Energía}

LTE-M permite que los dispositivos en los que operan utilicen un modo de ahorro de energía. Consumiendo energía sólo cuando los dispositivos requiren su uso.

\item \textbf{Cobertura}


Las redes LTE-M/Cat-M1/Cat-M2 pueden utilizar la infraestructura 4G LTE existente. Esta es una ventaja significativa, ya que más del 50 por ciento de las conexiones móviles globales se realizan en redes 4G. 

Con una pérdida de acoplamiento máxima (MCL) de 156 decibelios (dB), 14 dB más alta que LTE, las redes LTE-M también ofrecen mayor cobertura y mejor penetración en interiores. La señal puede manejar muchas interferencias de edificios y otras estructuras que obstruyen su camino.

\item \textbf{Velocidad de Transferencia}

LTE-M cuenta con un estándar base de 1 megabit por segundo para transmisiones de enlace subida y descarga. Su uso es factible para aplicaciones con necesidades de  transmisión datos menores a los 50MBps e incluso casos de uso que involucran transmisión de contenido multimedia.


En el contexto de IoT, el alto rendimiento de datos significa que los dispositivos que usan LTE-M pueden recibir fácilmente actualizaciones por aire (OTA), y las transmisiones de datos consumirán menos energía, porque el dispositivo puede volver al modo de ahorro de energía más rápido.


\item \textbf{Costo}

Las redes 4G se construyeron principalmente para teléfonos inteligentes. Las redes LTE-M se construyeron principalmente para dispositivos IoT. Como tal, los componentes necesarios para los dispositivos LTE-M son menos complejos y más asequibles que los componentes que necesitaría para un dispositivo 4G tradicional, aunque ambos utilizan la infraestructura 4G LTE.




\end{itemize}

\textbf{NB-IoT}

Es un protocolo inalámbrico de Internet de las cosas (IoT) que también utiliza tecnología de red de área amplia de baja potencia (LPWAN). Fue desarrollado por 3GPP para comunicación inalámbrica celular que permite una amplia gama de nuevos dispositivos y servicios NB-IoT. NB-IoT es uno de los tres principales estándares 3GPP LPWAN.\\

El estándar de comunicación NB-IoT tiene como objetivo permitir que los dispositivos IoT funcionen a través de redes de operador, ya sea dentro de una onda portadora de comunicación del Sistema Global para Móviles (GSM) existente, en una "banda de protección" no utilizada entre canales LTE o de forma independiente.\\

Uno de los objetivos de NB-IoT es impulsar la extensión de la cobertura más allá de lo que ofrecen las tecnologías celulares existentes. Para ello, NB-IoT ofrece repeticiones de transmisión y diferentes configuraciones de asignación de ancho de banda en la transmisión de enlace ascendente.\\

La tecnología NB-IoT utiliza señales de bajo ancho de banda para comunicarse dentro de las tecnologías GSM y LTE existentes.

Los dispositivos y sensores especialmente diseñados son los componentes básicos de los sistemas NB-IoT. Estos dispositivos recopilan información de su entorno y la transmiten a estaciones base NB-IoT o nodos de transmisión.

Las estaciones base individuales están conectadas a una puerta de enlace de IoT y servidores de aplicaciones en la nube de IoT para el monitoreo centralizado y el análisis de datos.

NB-IoT emplea una nueva capa física con señales y canales para cumplir con los requisitos de cobertura extendida en áreas rurales e interiores profundos, al tiempo que permite una complejidad de dispositivo muy baja. La tecnología subyacente es mucho menos compleja que la de los módulos GSM/GPRS.\\

A continuación se describen las ventajas más importantes de NB-IoT:
\begin{itemize}

\item \textbf{ Ahorro de Energía}

NB-IoT no necesita ejecutar un sistema operativo pesado, y no require procesamiento de señales, lo que lo hace más eficiente en términos de energía en comparación con LTE-M.

\item \textbf{Cobertura}


NB-IoT puede ayudar a admitir una gran cantidad de dispositivos mediante el establecimiento de redes NB-IoT que pueden conectarse a miles de millones de nodos. Diseñado para cobertura extendida en interiores, la menor complejidad de los dispositivos proporciona conectividad y comunicación de largo alcance.

\item \textbf{Costo}

Debido a que es más fácil crear dispositivos con menor complejidad, el costo de los dispositivos es significativamente bajo, alrededor de 5 dolares por módulo.

\item \textbf{Seguridad}


NB-IoT está protegido de manera muy similar a 4G, incluidas todas las funciones de autenticación basadas en cifrado y SIM.

Comparado a NB-IoT las velocidades de transferencia de datos de LTE-M son más de 10 veces más rápidas, su latencia es de 10 a 100 veces menor y cuenta con una cobertura mucho mayor, ya que utiliza la infraestructura 4G LTE existente. Sin embargo, aunque ambas LPWAN funcionan bien en interiores, NB-IoT tiene una pérdida máxima de acoplamiento (MCL) ligeramente más alta, lo que significa que puede manejar un poco más de interferencia.

LTE-M también puede usar una gama más amplia de frecuencias, aunque, como su nombre lo indica, Narrowband-IoT usa bandas de frecuencia más estrechas, lo que permite que esta tecnología use el espectro de radiofrecuencia (RF) de manera más eficiente.

\begin{table}[h]
\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
       & \begin{tabular}[c]{@{}l@{}}Velocidad \\ Máxima de Subida\end{tabular} & \begin{tabular}[c]{@{}l@{}}Velocidad Máxima \\ de Descarga\end{tabular} & Latencia & \begin{tabular}[c]{@{}l@{}}Perdida Máxima\\ de Acoplamiento(dBs)\end{tabular} & Ancho de Banda \\ \hline
LTE-M  & 1Mbps                                                                 & 1Mps                                                                    & 10-15 ms & 156                                                                           & 1.4MHz a 5MHz  \\ \hline
NB-IoT & 127 kbit                                                              & 159 kbit                                                                & 1.6-10s  & 164                                                                           & 180KHz         \\ \hline
\end{tabular}
\end{adjustbox}
\caption{\label{tab:interfaces} Comparación entre LTE-M y NB-IoT}
\end{table}

Pocos operadores han establecido acuerdos de roaming para sus redes NB-IoT, por lo que LTE-M ofrece una mejor cobertura y tiene menos circunstancias en las que necesita cambiar de SIM.
Actualemente, la compañia Telcel cuenta con la mayor cobertura de tecnología LTE en México.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/lte-mcobertura}
\captionof{figure}{Mapa de Cobertura LTE-Telcel}
 \label{fig:prot}
\end{center}
\newpage
\item\textbf{NB-IoT consume más energía en algunos casos}

Cuando los dispositivos necesitan transmitir grandes volúmenes de datos, las velocidades de datos más bajas de NB-IoT requieren estos permanezcan en línea por más tiempo, lo que resulta en un mayor consumo de energía. En casos de uso móvil, NB-IoT también usa más energía


\end{itemize}

Por lo anterior, se decidió a utilizar el estándar LTE-M para nuestro proyecto. 

\subsubsection{Análisis del Submódulo de Datos }\label{sec:ASD}
El objetivo que tiene el análisis de los datos es mandar fotogramas a la estación base para su futura gestión y validación, así como el almacenamiento de estos; de igual manera se pretende el envío de mensajes informativos para la estación base.
Anteriormente se establecen las especificaciones que debe tener el material multimedia a utilizar, las características que debe tener el clip grabado es una profundidad de bits de mínimo 8  y una resolución de mínimo 960 x 540 píxeles comúnmente conocido como QHD o \emph{Quarter of High Definition} por sus siglas en inglés, que es lo mínimo necesario que requiere el sistema, todo esto en una secuencia de 30fps.
Tenemos que:

\begin{equation*}
960 \; x \; 540 \; x \; 8=4,147,200 \; bits
\end{equation*}

Cada imagen tiene 4,147,200 bits entonces en 1 segundo se transmiten:
\begin{equation*}
4,147,200 \; x \; 30 fps=124.41 \; Mbps
\end{equation*}
Que rebasa la capacidad de canal de red establecida, por lo que se implementa el uso de un compresor de video MP4 que tiene una relación de compresión de 16:1 \cite{Referencian16} para así modificar la resolución en la que se almacena el video en la estación base, por otro lado, se envían al menos 2 fotogramas por segundo para no sobrepasar la capacidad de canal.   
Tenemos que:

\begin{equation*}
640 \; x \; 480 \; x \; 8=2,457,600 \; bits
\end{equation*}
Cada imagen tiene 2,457,600 bits entonces en 1 segundo se transmiten:
\begin{equation*}
2,457,600 \; x \; 2 fps=4.91 \; Mbps
\end{equation*}
Cumpliéndose nuevamente la relación establecida $R < C$.
\begin{equation*}
4.91 Mbps<5 Mbps
\end{equation*}
Más 3 kbps de la tasa de bits a utilizar del texto informativo.

\subsubsection{Análisis del Submódulo de Cobertura}

La red de telefonía celular funciona mediante celdas (véase la Figura \ref{fig:handover}), estas celdas tienen el objetivo de mantener conectados a los dispositivos en las diferentes áreas de cobertura y cada una de ellas contiene una estación base o antena. El \emph{handover}  o \emph{handoff} es el proceso de transferir el servicio de una celda a otra\cite{Referencian17} y se tiene la siguiente métrica:
\begin{itemize}
\item Se considera un \emph{handoff} fuerte cuando al ir cambiando de celdas  se presente algún problema en la velocidad de la red logrando así la pérdida de la misma.
\item Se considera un \emph{handoff} suave cuando al ir cambiando de celdas no se presente algún problema de la red o este sea mínimo.
\end{itemize}
Ya sea cuando se pierde la calidad en una de ellas o cuando el dispositivo se va trasladando.Este mecanismo tiene por objetivo el garantizar la correcta realización del servicio en las condiciones mencionadas anteriormente. 
Para el análisis de cobertura de la red LTE se tiene en cuenta el sistema \emph{handoff} porque el dispositivo se va trasladando entre distintas celdas.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/handover}
\captionof{figure}{Esquema \emph{handover} entre dos celdas }
 \label{fig:handover}
\end{center}

La cobertura de LTE por Telcel es la más amplia del país \cite{Referencian18}, su mayor cobertura está concentrada en la Ciudad de México, por lo que existe una buena recepción, aunque en ocasiones debido a la saturación de la red o al transferir el servicio de la antena de una estación base a otra se puede encontrar alguna intermitencia o retraso, en estos casos el módulo va a pasar a modo de espera para enviar la información una vez se restablezca la red.

\begin{center}
  \includegraphics[scale=1.3]{imagenes/mapaLTE}
\captionof{figure}{Mapa de cobertura de la red LTE }
 \label{fig:mapaLTE}
\end{center}

En el mapa de cobertura la zona verde hace referencia a zonas con cobertura garantizada y la zona amarilla cobertura no garantizada, en caso de realizar pruebas en las zonas amarillas del mapa se va a notar un cambio en la velocidad del dispositivo móvil ya sea para la transferencia de archivos o la conectividad a la red
ocasionando un \emph{handoff fuerte}; por el otro lado, al estar realizando pruebas en la zona verde del mapa su \emph{handoff} será más suave.

\textbf{Alcances:}
\begin{itemize}
\item Envío de las coordenadas y mensaje informativo del posicionamiento del vehículo a la estación base.
\item Envío del fotograma y mensaje informativo del vehículo a la estación base.
\item Compresión a MP4 para la transmisión y almacenamiento del fotograma.
\item Recepción del estatus del envío de la información transmitida.
\end{itemize}

\textbf{Restricciones:}
\begin{itemize}
\item La velocidad de transmisión es de hasta 5Mbps.
\item El envío de las coordenadas en periodos de 10 segundos.
\item El envío de fotogramas a la estación base se mantiene limitado a 2 fps.
\item El envío de la cadena de texto se mantiene limitada a 300 bits.
\item El sistema de comunicación transmite la información solamente en zonas que cuenten con cobertura garantizada.
\end{itemize}
 


\clearpage
\subsection{Análisis del Módulo de Estación Base}
El módulo de la estación base tiene como objetivo que el usuario administrador, visualice y confirme el estado de los reportes de incidencia que se hayan presentado por parte del conductor, por tal motivo, se realizará una aplicación web, la cual se conectará a una base de datos NoSQL. En ella se guardarán los reportes de incidencias y se podrán visualizar por medio de la aplicación web. Cabe aclarar que el video de la incidencia se almacenará en la nube, ya que al ser contenido multimedia no se puede guardar en la base de datos, únicamente se guardará el URL para acceder al video. Las credenciales del usuario serán almacenadas en Amazon Cognito, con la cuales podrán iniciar sesión dentro de la Aplicación Web, la cual estará alojada en un servidor web.  




El sistema contará con los siguientes requerimientos:   \\

\textbf{Requerimientos Funcionales del Módulo de Estación Base}

\begin{table}[h]
\centering
\caption{RF01- Guardar Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Guardar Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La base de datos almacenará la información de cada reporte de incidencia que se envié desde el Módulo Central de Procesamiento. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Id del Conductor \\
\quad $\bullet$ Nombre de Conductor\\
\quad $\bullet$ Apellidos de Conductor  \\
\quad $\bullet$ Número de Incidencias\\
\quad $\bullet$ Fecha\\
\quad $\bullet$ Hora\\
\quad $\bullet$ Estado de la Incidencia \\
\quad $\bullet$ Ubicación  \\
\quad $\bullet$ URL del video 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Módulo de Procesamiento Central puede insertar datos en la base datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{RF02- Guardar Video }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Guardar Video }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La base de datos almacenará la información de cada reporte de incidencia que se envié desde el Módulo Central de Procesamiento. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Video de incidencia 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Módulo de Procesamiento Central puede insertar el video en el almacenamiento de objetos, mientras que la base de datos obtiene la URL del video guardado. \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{RF03- Conectar Aplicación Web }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Conectar Aplicación Web }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La base de datos almacenará la información de cada reporte de incidencia que se envié desde el Módulo Central de Procesamiento. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Node.js  \\
\quad $\bullet$ React   \\
\quad $\bullet$ Express   \\
\quad $\bullet$ MongoDB 

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador puede realizar la inserción, modificación, eliminación y consulta de datos desde la aplicación web.  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}





\begin{table}[h]
\centering
\caption{RF04- Desplegar Aplicación Web}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF04}}                                              & \emph{Desplegar Aplicación Web  }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La aplicación web se alojará en una red de entrega de contenido (CDN), disponible con una URL.  \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ \emph{Content Delivery Network}  \\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador puede acceder a la interfaz de la aplicación web, haciendo uso de la URL en el navegador web.  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[h]
\centering
\caption{RF05- Guardar Credenciales de Usuario Administrador }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Guardar Credenciales de Usuario Administrador }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se guardarán únicamente las credenciales de los usuarios administradores que podrán acceder a la aplicación web. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Servicio de Administración de Acceso e Identidad 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador podrá iniciar sesión en la aplicación web utilizando un servicio de Administración de Acceso e Identidad  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\clearpage
\textbf{Requerimientos No Funcionales del Módulo de Estación Base}



\begin{table}[H]
\caption{Requerimientos No Funcionales del Módulo de Estación Base}
\begin{tabular}{{|m{0.12\linewidth}|m{0.25\linewidth}|m{0.50\linewidth}|}}
\hline
\textbf{ID} & \textbf{Nombre del requerimiento} & \textbf{Descripción } \\ \hline
\emph{RNF01 } & Disponibilidad & La disponibilidad del sistema será continua, el usuario podrá acceder a la información las 24 horas del día.  \\ \hline
\emph{RNF02 } & Interoperabilidad  & El sistema será capaz de intercambiar información con el Módulo Central de Procesamiento a través del Módulo de Telemetría.  \\ \hline
\emph{RNF03 } & Seguridad  & El sistema hará uso de encriptación AES-256 para garantizar la seguridad de las credenciales de los usuarios. \\ \hline
\emph{RNF04 } & Usabilidad  & El sistema estará enfocado a la visualización de reportes, por lo que este tendrá una interfaz intuitiva y amigable para el usuario. El sistema proporcionará mensajes de advertencia orientados al usuario, en caso de ocurrir un error en el Módulo Central de Procesamiento. \\ \hline

\end{tabular}

\end{table}


\textbf{Análisis de Casos de Uso}

Con base en los requerimientos se realizó el siguiente diagrama de casos de uso, el cual muestra las actividades y la interacción con el Módulo de Estación base y el Módulo Central de Procesamiento. 

\begin{center}
  \includegraphics[scale=.55]{imagenes/CasosdeusosMEB}
\captionof{figure}{Diagrama de Casos de Usos del Módulo de Estación Base}
 \label{fig:CasosdeusosMEB}
\end{center}


\begin{table}[h]
\centering
\caption{Caso de Uso 01 - Guardar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Guardar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento, Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema almacenará las incidencias recibidas por el módulo de Comunicaciones. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con una conexión al Módulo de Comunicaciones\\
\quad $\bullet$ Contar con una conexión a la Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Reporte de Incidencia\\
\quad $\bullet$ Módulo de Comunicaciones\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[h]
\centering
\caption{Caso de Uso 02 - Guardar Video }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Guardar Video}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se almacenará el video recibido por el Módulo de Comunicaciones \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con una conexión al Módulo de Comunicaciones\\
\quad $\bullet$ Contar con una conexión a la Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Video\\
\quad $\bullet$ Módulo de Comunicaciones\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 03 - Conectar Aplicación Web }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Conectar Aplicación Web}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se realizará la conexión de la aplicación web y la base de datos \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con el servicio de Hosting Disponible
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Aplicación Web\\
\quad $\bullet$ Base de Datos\\ 
\quad $\bullet$ Servicio de Hosting\\   \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 04 - Desplegar Aplicación Web}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Desplegar Aplicación Web}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento, Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:} Utilizando el servicio de Hosting ofrecido por Amazon Amplify se desplegará la aplicación web\\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con una cuenta registrada en Amazon Amplify
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Aplicación Web\\
\quad $\bullet$ Base de Datos\\
\quad $\bullet$ Servicio de Hosting \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 05 - Guardar Credenciales de Usuario Administrador }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Guardar Credenciales de Usuario Administrador}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Utilizando Amazon Congito, el sistema permitirá almacenar nuevos usuarios administradores \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con el servicio de la aplicación web Desplegado
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Amazon Cognito
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\clearpage
\subsubsection{Análisis de la Aplicación Web}




A continuación se listan los requerimientos Funcionales obtenidos

\begin{itemize}






\item \textbf{Análisis de Requerimientos Funcionales}
\begin{table}[H]
\centering
\caption{RF01- Iniciar Sesión}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Iniciar Sesión}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{@{}l@{}}\textbf{Descripción:}  El sistema permitirá iniciar sesión en la aplicación web\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Servicio de Administración de Acceso e Identidad\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Credenciales\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema, con la ayuda un servicio de administración de acceso e identidad del cliente, comprobará que las credenciales ingresadas por parte del usuario administrador se encuentren en la base de datos. En caso contrario, la aplicación web indicará que ese usuario no se encuentra registrado en la base de datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}




\begin{table}[H]
\centering
\caption{RF02- Mostrar el Historial de Reportes de Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Mostrar el Historial de Reportes de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema desplegará en forma de lista todas las incidencias que se tengan registradas en la base de datos\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Incidencias\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema recuperará de la base de datos todas las incidencias que se tengan registradas.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}




\begin{table}[H]
\centering
\caption{RF03- Visualizar Reporte de Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Visualizar Reporte de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema desplegará los detalles específicos de cada incidencia registrada.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Incidencia\\
\quad $\bullet$ Administrdor\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador podrá visualizar los reportes individuales de incidencias de cada conductor al hacer click en cualquiera de las incidencias mostrada en la lista principal. Los reportes contendrán información sobre la fecha, hora, ubicación y un video corto del momento en que fueron detectados síntomas de somnolencia.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF04- Confirmar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF04}}                                              & \emph{Confirmar Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema permitirá al administrador confirmar la incidencia, esto para descartar que se trate de un falso positivo.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Incidencia\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador podrá confirmar la incidencia después de haber revisado el videoclip del momento de somnolencia con la intención de descartar falsos positivos. Esto será posible ingresando a una incidencia específica mostrando sus detalles.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF05 - Recuperar Contraseña}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Recuperar Contraseña}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema contará con una opción para recuperar la contraseña del administrador en caso de que sea olvidada la contraseña.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Servicio de Administración de Acceso e Identidad\\
\quad $\bullet$ Email\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema requerirá que el usuario administrador ingrese el correo con el que fue registrado. Posteriormente se le enviará un código de recuperación de contraseña a ese correo. El administrador ingresará se código en el apartado de recuperar contraseña y así podrá ingresar una nueva contraseña.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF06- Mostrar perfil del Conductor}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF06}}                                              & \emph{Mostrar Perfil Conductor}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema permitirá al usuario administrador visualizar los datos de cada conductor registrado en la base de datos.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Perfil\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Gestor de Base de Datos

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El administrador podrá consultar cada uno de los perfiles de los conductores registrados en la base de datos dando click en el nombre del mismo. En dicho perfil se mostrarán datos como nombre, apellido, así como el número de incidencias de dicho conductor, con sus respectivos detalles.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF07- Mostrar ubicación Geográfica}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF07}}                                              & \emph{Mostrar Ubicación Geográfica}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La aplicación web, con ayuda de los datos proporcionados por el módulo de telemetría, mostrará la ubicación en tiempo real de un conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Ubicación en Tiempo Real\\
\quad $\bullet$ Módulo de Telemetría\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema permitirá al administrador consultar la ubicación de los conductores en tiempo real. Para esto el administrador deberá de ingresar previamente al perfil del conductor del cual desea consultar dicha ubicación.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[H]
\centering
\caption{RF08- Descartar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF08}}                                              & \emph{Descartar Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema permitirá catalogar una incidencia como Falsa si fuera el caso.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Incidencia\\
\quad $\bullet$ Administrador\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
En caso de presentarse una incidencia falsa, después de haber sido revisada por el administrador, esta podrá ser catalogada como falsa incidencia y será eliminada automáticamente de la base de datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF09- Registrar Usuario}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF09}}                                              & \emph{Registrar Usuario}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema le permitirá al administrador registrar nuevos conductores.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ ID\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Administrador podrá registrar a nuevos conductores en el sistema. El sistema generará de manera automática el ID del nuevo conductor\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF10- Mostrar el Historial de Reportes de Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF10}}                                              & \emph{Modificar Usuario}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema le permitirá al administrador modificar los datos del conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Administrador

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El administrador podrá editar los datos de los conductores como nombre o apellido.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\caption{RF11- Mostrar el Historial de Reportes de Incidencia}
\centering
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF11}}                                              & \emph{Elimininar Usuario}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema le permitirá al administrador eliminar los datos del conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Administrador


\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema le permitirá al eliminar los datos de conductores de la base de datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF12}}                                              & \emph{Generar Mensaje de Alerta}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema alertará con un mensaje en caso de que algún componente en alguna Unidad Contenedora no funcione correctamente.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Módulo Central de Procesamiento\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Alerta


\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema enviará un mensaje de alerta al administrador indicando que Unidad presenta algún desperfecto, esto con la intención de sea reparada posteriormente.\end{tabular}}                                                    \\ \hline
\end{tabular}
\caption{RF12- Generar Mensaje de Alerta}
\end{table}


	        
\item \textbf{Análisis de Requerimientos no Funcionales}

A continuación se mencionan los requerimientos no funcionales de la aplicación web.

\begin{table}[H]
\caption{Requerimientos No funcionales - Aplicación Web}
\begin{tabular}{|l|l|l}
\cline{1-2}
\textbf{Requerimiento No Funcional} & \textbf{Descripción}                                                                                                                                                                   &  \\ \cline{1-2}
Disponibilidad                      & \begin{tabular}[c]{@{}l@{}}La aplicación web deberá estar \\ disponible las 24 horas del día\end{tabular}                                                                              &  \\ \cline{1-2}
Interoperabilidad                   & \begin{tabular}[c]{@{}l@{}}La aplicación deberá ser accesible desde \\ cualquier sistema operativo \\ mientras se cuenta con un \\ navegador web en su versión más actual\end{tabular} &  \\ \cline{1-2}
Eficiencia                          & \begin{tabular}[c]{@{}l@{}}La aplicación tendrá tiempos de respuesta\\ menores a 100ms.\end{tabular}                                                                                   &  \\ \cline{1-2}
Escalabilidad                       & \begin{tabular}[c]{@{}l@{}}La aplicación web deberá ofrecer la oportunidad de \\ agregar nuevas funcionalidades y \\ soportar un mayor número de usuarios a \\ futuro\end{tabular}     &  \\ \cline{1-2}
Estabilidad                         & \begin{tabular}[c]{@{}l@{}}La aplicación deberá ofrecer un buen \\ funcionamiento mientras se tenga \\ una conexión a internet mínima de 1Mbps\end{tabular}                                      &  \\ \cline{1-2}
\end{tabular}

\end{table}

\item \textbf{Análsis de Casos de Uso}


\begin{center}
  \includegraphics[scale=.6]{imagenes/casosdeusoweb}
\captionof{figure}{Diagrama de Casos de Uso - Aplicación Web }
 \label{fig:scaraindust}
\end{center}

\textbf{Especificación de Casos de Uso}

\begin{table}[h]
\centering
\caption{Caso de Uso 01 - Iniciar Sesión }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Iniciar Sesión}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD, Amazon Cognito}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador ingresará los datos correspondientes para iniciar sesión en la aplicación web. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El administrador deberá contar sus credenciales registradas en Amazon Cognito
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Email\\
\quad $\bullet$ Contraseña
 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 02 - Registrar Usuario }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Registrar Usuario}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Solo los usuarios administradores podrán registrar a nuevos conductores en el sistema. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de acceso como administrador 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ Edad
 
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 03 - Modificar Usuario }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Modificar Usuario}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El usuario Administrador podrá modificar los datos de los conductores previamente registrados. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador \\
\quad $\bullet$ Que exista una entrada del conductor a modificar
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ Edad
 
  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 04 - Eliminar Usuario}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Eliminar Usuario}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El usuario administrador podrá dar de baja a un conductor \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador \\
\quad $\bullet$ Que exista una entrada del conductor a eliminar
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ ID del conductor\\

\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[h]
\centering
\caption{Caso de Uso 05 - Confirmar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Confirmar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá confirmar las incidencias \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador \\
\quad $\bullet$ Haber inciado sesión previamente \\
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Correo \\
\quad $\bullet$ Contraseña\\\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 06 - Visualizar Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Visualizar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá reproducir un video dónde se muestre el momento en que ocurrió la incidencia \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de administrador
\quad $\bullet$ Haber seleccionado una incidencia
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas}\\
\quad $\bullet$ ID incidencia\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 07 - Recuperar Contraseña}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Recuperar Contraseña}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá recuperar contraseña en caso de olvidarla \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de administrador

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas}\\
\quad $\bullet$ Email\\
\quad $\bullet$ Nueva Contraseña

\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 08 - Visualizar Ubicación en Tiempo Real }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Visualizar Ubicación en Tiempo Real}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, Módulo de Comunicaciones}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá visualizar la ubicación en tiempo real de los conductores registrados \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador\\
\quad $\bullet$ Haber iniciado sesión previamente
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ ID del conductor
  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\end{itemize}
\clearpage

\subsubsection{Análisis y Elección del manejador de bases de datos  }
Debido a la escalabilidad horizontal, facilidad de implementación, bajo coste y flexibilidad que ofrece los gestores de bases de datos NoSQL para adaptarse a las necesidades del proyecto, se optó por la elección de un gestor de este tipo. Además, se contemplaron las posibles modificaciones dentro del modelado de la base de datos, las cuales tendrán como motivo, cumplir los requisitos del sistema y presentar la información necesaria en la aplicación web. Estas modificaciones (en caso de ser necesarias) podrán ser fácilmente aplicadas usando un SGBD NoSQL ya que ofrecen una mayor facilidad de realizar cambios dentro del esquema a diferencia de un SGBD SQL.  \\


\begin{table}[h]
\caption{Cuadro Comparativo de los Sistemas de Gestión de Bases de Datos No Relacionales}
\begin{tabular}{{|m{0.16\linewidth}|m{0.18\linewidth}|m{0.18\linewidth}|m{0.18\linewidth}|m{0.18\linewidth}|}}
\hline
 & \textbf{Cassandra } & \textbf{MongoDB } & \textbf{Redis } & \textbf{Amazon DynamoDB } \\ \hline
 \textbf{Tipo de base de datos }& NoSQL \emph{wide-column}  & NoSQL Orientado a documentos  & NoSQL clave-valor  & NoSQL clave-valor  \\ \hline
 \textbf{Licencia }& Codigo abierto  & Codigo abierto SSPL & Codigo abierto BSD 3-clause  & Vendor \\ \hline
 \textbf{Cumplimiento ACID }& No & Si  &  Si &  Si \\ \hline
 \textbf{Lenguaje de consulta principal }& CQL  & JavaScript  & Permite el uso de varios lenguajes  & DQL  \\ \hline
 \textbf{Principales casos de uso }& Análisis social, análisis en tiempo real, venta al por menor y mensajería & Gestión de IOT, análisis en tiempo real, desarrollo de aplicaciones, inventario y personalización & Almacenamiento en caché, colas, filtrado y estadísticas  & Juegos, comercio minorista, servicios financieros, publicidad y transmisión de medios  \\ \hline
 \textbf{Seguridad  }& Seguridad integrada para la autorización, el cifrado y la autenticación, pero la seguridad está desactivada de forma predeterminada para facilitar su uso dentro de los clústeres  & Seguridad incorporada para autorización, autenticación y encriptación  & Se inicia automáticamente en modo de protección y ofrece sugerencias de seguridad  & Seguridad integrada para datos y aplicaciones; software, hardware, instalaciones y red seguros del proveedor  \\ \hline
 \textbf{Escalabilidad }& Horizontal  & Horizontal  & Horizontal  & Horizontal  \\ \hline
\end{tabular}

\end{table}


Dentro de los SGBD NoSQL se eligió MongoDB, ya que la aplicación  como base el lenguaje JavaScript y  Node.js para realizar el \emph{backend} de la aplicación, por lo cual MongoDB complementa y facilita el desarrollo del proyecto en herramientas basados en JavaScript. Además, MongoDB es de código abierto, y es una herramienta gratuita hasta cierto punto, por lo cual no se requerirá una licencia para la implementación. Otra característica importante es que es una base de datos multiplataforma, esto para que se realice información desde el sistema operativo Linux, que será utilizado en la Rasperry Pi.

\clearpage
\subsubsection{Análisis y Elección de lenguajes de programación web}

Con respecto al desarrollo web, se requiere un lenguaje de programación que pueda ofrecer felixbilidad e interoperabilidad para su futura implementación. El lenguaje de programación que cumple en estas características, es Javascript \cite{js}.


JavaScript (JS) es un lenguaje de programación ligero, interpretado, o compilado justo-a-tiempo (just-in-time) con funciones de primera clase. Si bien es más conocido como un lenguaje de scripting (secuencias de comandos) para páginas web, también es un lenguaje de programación basada en prototipos, multiparadigma, de un solo hilo, dinámico, con soporte para programación orientada a objetos, imperativa y declarativa

A continuación se describen sus características más importantes:

\begin{itemize}
\item \textbf{Veloz}

Como lenguaje de programación interpretado, no tiene que compilarse cada vez que se ejecuta, lo que hace que el desarrollo y la depuración sean más rápidos para comenzar. Además, JavaScript encuentra más velocidad al ejecutarse como un script del lado del cliente, ejecutándose en el navegador sin conectarse al servidor y ahorrando recursos valiosos para cada usuario adicional.

\item \textbf{Procesamiento asíncrono}

El procesamiento asíncrono es una de las características más útiles del lenguaje JavaScript. Usando JavaScript, un bloque del script no podrá detenerse o dejar que el otro bloque de código espere a que comience la respuesta. Si se está procesando una solicitud, otras también trabajarán en paralelo con la solicitud anterior en lugar de esperar la respuesta de la solicitud anterior. Ahorra mucho tiempo al ejecutar scripts en paralelo.

\item \textbf{Poca carga de Procesamiento del servidor}

JavaScript permite realizar funcionalidades básicas en el lado del cliente. Esto significa que el servidor no tendrá que procesar las funcionalidades básicas que mejoran el rendimiento del servidor.

\end{itemize}




\clearpage

\subsubsection{Análisis y Elección del servidor de alojamiento  }
Para el presente proyecto se requiere una capacidad de almacenamiento que nos permita el uso de archivos multimedia, concretamente archivos de video.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Tipo de Multimedia} & \textbf{Ejemplos}             \\ \hline
Imágenes                    & JPEG, GIF, PNG, Archivos TIFF \\ \hline
Audio                       & MP3, WAV, ACC                 \\ \hline
Video                       & QuickTime, MP4, Youtube       \\ \hline
\end{tabular}
\caption{Tipos de Archivo Multimedia}
\end{table}

Si se requiere alojar una aplicación web cuyo contenido predominante sea multimedia, se deberá de tomar en cuenta los siguientes factores:


\begin{itemize}
\item  Ancho de banda

El ancho de banda y el almacenamiento son una función de su plan de alojamiento. Generalmente un plan de alojamiento en la nube  permite pagar por un uso menor durante las horas de menor actividad y explotar cuando recibe mucho tráfico. No se paga por ancho de banda o espacio de almacenamiento que en realidad no se utiliza.

\item Almacenamiento

Si se tiene una gran cantidad de archivos multimedia, entonces se requiere gran capacidad de almacenamiento. Lo ideal sería contar con almacenamiento ilimitado, pero esto significaría un aumento considerable al costo de alojamiento. Se debe de analizar un aproximado de almacenamiento necesario y en base a eso se deberá elegir el plan de almacenamiento que mejor cubra esas necesidades.

\item CDN (\emph{Content Delivery Network})

Lo último que debe considerar con el alojamiento de medios es una red de entrega de contenido o CDN. Una CDN intenta mejorar el rendimiento de la transmisión de medios mediante la ubicación de servidores que están geográficamente cerca del usuario mediante sofisticados algoritmos de ubicación y de ruteo.

\end{itemize}

Sabiendo lo anterior, se procede a realizar el análisis de distintos proveedores de alojamiento con la propósito de seleccionar saber aquel que ofrezca la capadidad de alojar y almacenar contenido multimedia.

\begin{itemize}
\item AWS Amplify Hosting
AWS Amplify Hosting es un servicio de alojamiento e Integración Continua/Entrega Continua completamente administrado para aplicaciones estáticas, rápidas, seguras, fiables, renderizadas del lado del servidor y que escalan a la par. Algunas de sus principales ventajas son:

\begin{itemize}
\item \textbf{Implementación de contenido web con rapidez}

AWS permite la implementación continua de una aplicación web estática o renderizada del lado del servidor, una página de inicio de la aplicación móvil o una aplicación progresiva en cada confirmación de código.


\item \textbf{CDN}

Cuenta con la red de entrega de contenido (CDN) de Amazon CloudFront con cientos de puntos de presencia en todo el mundo. Lo que permite un tiempo de respuesta de hasta menos de 10ms.

\item \textbf{Monitoreo}

AWS cuenta con un sistema de monitoreo de tráfico en tiempo real. También permite crear alarmas personalizadas para enviar notificaciones cuando la métrica haya superado el límite establecido. 

\item \textbf{Precio}

AWS cuenta con dos planes, uno gratuito y otro de paga, a continuación, se detallan las características de cada uno.

\begin{center}
  \includegraphics[scale=.5]{imagenes/amplify}
\captionof{figure}{Planes de Alojamiento AWS Amplify}
 \label{fig:DiagramadeactividadMEB}
\end{center}

\item \textbf{A2Hosting}

\begin{itemize}
\item \textbf{Alojamiento Compartido}

A2 Hosting cuenta con dos tipos de planes de alojamiento, el primero con costo de renovación que  va desde \$10.99 dls . Si se llegara a necesitar un servidor dedicado, el plan que nos ofrece está característica tiene un precio de  \$25.99 por mes.

\item \textbf{VPS}

VPS significa servidor privado virtual por sus siglas en inglés. Es una forma de dividir un servidor en (sub)servidores individuales más pequeños. Esto significa que se puede configurar de acuerdo a las necesidades del cliente y no tener que compartir recursos con otros clientes. Un VPS en A2 Hosting cuesta desde tan solo \$7.65 al mes hasta alrededor de \$200 dependiendo del número de subdivisiones necesarias.

\item \textbf{CDN}
A2 Hosting no ofrece servicio de CDN, sin embargo, cualquiera de sus planes ofrecen la posibilidad de contratar un servicio de CDN proveedores externos pagando un precio extra del precio base dependiendo del plan contratado.

\end{itemize}


\item \textbf{HosGator}
\begin{itemize}

\item \textbf{Tiempo de Respuesta}

De acuerdo con el sitio Bitcatcha, que se dedica a evaluar los tiempos de respuestas de los servidores de páginas web, HostGator poseé tiempos de respuestas mínimos para el territorio de Estados Unidos. A continuación se muestra los tiempos de respuesta de distintos territorios:


\begin{center}
  \includegraphics[scale=.5]{imagenes/respuesta}
\captionof{figure}{Tiempos de Respuesta de servidores de HostGator}
 \label{fig:DiagramadeactividadMEB}
\end{center}

HostGator posee solo 2 datacenters, uno localizado en el área oeste, y otro en el este. Esto puede ocasionar que los tiempos de respuesta no sean los mejores en áreas que estén alejadas de las antes mencionadas


\item \textbf{Disponibilidad}
HosGator ofrece una disponibilidad del 99.9\%, esto quiere decir que los sitios que se decida alojar en los servidores de HostGator deberían ser accesibles la mayoría del tiempo.


\end{itemize}


\end{itemize}



\end{itemize}


Después de haber analizado los distintos proveedores de alojamiento así como sus características, se llegó a la conclusión de utilizar AWS Amplify. Ya que este contiene una suite de herramientas que facilitan la implementación de una aplicación web, como por ejemplo S3, que es un servicio de alojamiento en la nube utilizado para archivos multimedia de gran tamaño, además de contar con su propia CDN que facilitará el acceso a los datos almacenados.

\clearpage
\section{Capítulo IV: Diseño}
Con base a los requerimientos definidos previande
\subsection{Diseño del Módulo Central de Procesamiento}
El sistema principal comenzará por verificar el estado del Submódulo de Visón Artificial, así como el de Comunicaciones y el estado de los periféricos. En caso de que cualquiera de estos presente alguna falla, se enviará un aviso a la Estación Base de que el sistema no podrá funcionar correctamente, y se etiquetará como "mantenimiento requerido". Si todos los sistemas funcionan correctamente, el Módulo de Procesamiento Central entrará en modo de espera por los datos proporcionados por el Submódulo de Procesamiento de Imáganes. En caso de que este último envíe una señal de alerta de Somnolencia, el Módulo Central activará la alarma en forma de buzzer. 
Posteriormente, se obtendrá la ubicación geográfica con la ayuda del Módulo de Comunicaciones se realizará un reporte de Incidencia que contendrá la fecha, hora, ubicación, y un pequeño videoclip del momento en que se detectó la somnolencia. Este será enviado a la Estación Base que se encargará de almacenarlo en su respectiva base de datos. Para evitar que el almacenamiento Interno del Módulo Central de Procesamiento se llene, se eliminará el reporte de incidencia siempre y cuando la Estación Base confirme que ha recibido dicho reporte.
Como se indicó inicialmente el sistema estará disponible mientras el sistema se encuentre conectado a una fuente de alimentación, esto significa que el estado del sistema se encuentra conectado. \\\\

\begin{center}
  \includegraphics[scale=.5]{imagenes/diagrama_secuenciamc}
\captionof{figure}{Diagrama de Secuencia - Módulo Central de Procesamiento}
 \label{fig:secuenciamc}
\end{center}

Siguiendo los procesos de la Figura 4, se procede a dar un análisis superficial en la concurrencia de los mismos. También se detallan las peticiones y respuestas de los distintos submódulos y sistemas.

\subsubsection{Elección de la Unidad Contenedora de Procesamiento}

Para el diseño de la unidad contenedora del módulo de procesamiento, se tomaron en cuenta los elementos físicos que estarán dentro de la unidad y sus respectivas medias. Cabe mencionar que los elementos que respectan al modelo del ordenador, el modelo de la cámara, el modelo del zumbador y el modelo de la microSD fueron previamente seleccionados en la secciones \ref{sec:microordenador}, \ref{sec:camara}, \ref{sec:alarma} y \ref{sec:almacenamientoexterno}. 
\\
Elementos físicos que contendrá la unidad:

\begin{itemize}

\item \textbf{Nvidia Jetson Nano}\\
De acuerdo con las especificaciones físicas de la Jetson Nano se tiene las siguientes medidas en milímetros:\\



\begin{center}
  \includegraphics[scale=.6]{imagenes/nanodim}
\captionof{figure}{Dimensiones Nvidia Jetson Nano}
 \label{fig:scaraindust}
\end{center}


\begin{center}
  \includegraphics[scale=.4]{imagenes/nano}
\captionof{figure}{Nvidia Jetson Nano}
 \label{fig:scaraindust}
\end{center}



\item Zumbador Pasivo KY-006\\
Dimensiones 18 x 15mm. 
\begin{center}
  \includegraphics[scale=.2]{imagenes/KY-006}
\captionof{figure}{Zumbador Pasivo KY-006}
 \label{fig:scaraindust}
\end{center}

\item Modulo de Cámara IMX219-160\\
Dimensiones de la placa: 11 x 5.11 x 2.39 cm.

\begin{center}
  \includegraphics[scale=.4]{imagenes/imx}
\captionof{figure}{Modulo de Cámara IMX219-160}
 \label{fig:scaraindust}
\end{center}
 

\item Cable macho-hembra\\

\begin{center}
  \includegraphics[scale=.4]{imagenes/Jumpers}
\captionof{figure}{Jumpers}
 \label{fig:scaraindust}
\end{center}

Se utilizarán 2 cables macho-hembra para la conexión del zumbador pasivo hacia los pines GND y Vcc del Raspberry Pi 4. 
Largo 10 cm. 

\item Micro SD\\  
Dimensiones: 15 x 11 x 1 mm. 

\begin{center}
  \includegraphics[scale=.5]{imagenes/MicroSD}
\captionof{figure}{Micro SD}
 \label{fig:scaraindust}
\end{center}
\newpage
\item \textbf{RasperryPi 3G/4G/ LTE Base HAT}

\begin{center}
  \includegraphics[scale=.4]{imagenes/sixfabhat}
\captionof{figure}{RasperryPi 3G/4G/ LTE Base HAT}
 \label{fig:scaraindust}
\end{center}

Este HAT celular proporciona una conexión de datos simplificada para proyectos de IoT remotos, en el campo, en todo el mundo, en todas partes. Comience a usar una conexión LTE de alta velocidad con bajo consumo de energía, además de contar con todo el software necesario para desarrollar en una  Raspberry Pi.

\item \textbf{LE 910Cx Mini PCIe Series Linux}

\begin{center}
  \includegraphics[scale=.7]{imagenes/LE910}
\captionof{figure}{LE 910Cx Mini PCIe Series Linux}
 \label{fig:scaraindust}
\end{center}


Los módulos Mini PCIe (mPCIe) de la serie LE910Cx son
optimizadas para redes LTE de baja categoría y están disponibles
en modo único de LTE o con opciones de respaldo 3G/2G.

\newpage
\item \textbf{LTE Main Diversity GNSS Triple Port u.FL Antenna de 100mm}

\begin{center}
  \includegraphics[scale=.4]{imagenes/lteantena}
\captionof{figure}{LTE Main Diversity GNSS Triple Port u.FL Antenna de 100mm}
 \label{fig:scaraindust}
\end{center}


Antenas LTE principal y Diversity combinadas con una antena GNSS en una sola antena formada. Ajuste directo para el módulo Mini PCIe LTE de Quectel EC25, Telit LE910C1 y Telit LE910C4.

\end{itemize}

\newpage

En un principio se tenía propuesto diseñar la unidad contenedora de procesamiento. Sin embargo, al buscar alternativas, se encontró una carcase especificamente diseñada para la Nvidia Jetson Nano, que cuenta con una plataforma para colocar una cámara digital además de orificios para antenas 4G, por lo que se decidió a utilizar esta carcasa para proteger los componentes.

\begin{center}
  \includegraphics[scale=.6]{imagenes/waveshare}
\captionof{figure}{Carcasa Waveshare}
 \label{fig:scaraindust}
\end{center}

Esta carcasa está hecha de metal y además incluye un ventilador para disipar el calor.

\begin{center}
  \includegraphics[scale=.8]{imagenes/wavecompo}
\captionof{figure}{Componentes de la Unidad Contenedora de Procesamiento}
 \label{fig:scaraindust}
\end{center}
 


\newpage
\subsubsection{Diseño del Submódulo de Visión Artificial}
Con base a los requerimientos definidos en la sección de Análsis, se procedió a realizar distintos diagramas que muestren las interacciónes y el funcionamiento de los distintos módulos.


En el siguiente Diagrama de Actividades se describen las actividades y sus interacciones con el Submódulo de Visión Artificial y la Estación Base. Para que el sistema principal pueda iniciar, se necesita que el conductor encienda el auto, ya que este sistema funcionará utilzando la alimentación electrica.
\\\\ 

\begin{center}

  \includegraphics[scale=.45]{imagenes/actividades_vision}
\captionof{figure}{Diagrama de Actividades - Submódulo de Visión Artificial}
 \label{fig:actividades}

\end{center}

\begin{center}
  \includegraphics[scale=.5]{imagenes/flujo_vision}
\captionof{figure}{Diagrama de Flujo - Submódulo de Visión Artificial}
 \label{fig:landmark}
\end{center}



La cámara digital capturará la imagen en tiempo real a una resolución de 640x480 pixeles a 30 cuadros por segundo. Esto debido a que dicha es la resolución mínima que la cámara digital seleccionada permite realizar el streaming de video. Dado que se busca un ahorro de recursos de procesamiento, utilizar una mayor resolución o tasa de cuadros por segundo podría resultar en el funcionamiento ineficaz en los procesos de los distintos módulos.
Para la detección de rostro, se utilizarán la librería de Cascadas Haar \emph{haarcascade\_frontalface\_alt.xml} ofrecida por OpenCV. Para la detección de ojos, se utilizará la librería \emph{haarcascade\_eye\_tree\_eyeglasses.xml},  que ofrece datasets para poder detectar ojos incluso con el uso de anteojos. Posteriormente se utilizará un modelo de red neuronal convolucional previamente entrenado con el datasets EyesClosed/CNN  que cuenta con un directorio de prueba y otro de entrenamiento. La red neuronal convolucional determinará si el conductor se encuentra con los ojos abiertos o cerrados. En caso de encontrarse con los ojos cerrados se inciará un contador. Si este contador llega a los 4 segundos de detectar ojos cerrados el sistema determinará que el conductor presenta un caso de somnolencia y se activará la alama para alertar al conductor. Posteriormente se realizará un reporte de incidencia que incluirá datos del conducto y de la incidencia cómo: fecha, hora y ubicación, así como un videoclip menor a 1 minuto que muestre el momento en que se detectó la incidencia. El sistema continuará activando la alerta hasta que se detecte un cambio en el estado de los ojos (de cerrados a abiertos). Finalmente, el reporte de incidencia será enviado a la Estación Base para su posterior revisión. 



\begin{itemize}


\item \textbf{Puntos de Referencia}

\begin{center}
  \includegraphics[scale=.42]{imagenes/landmark}
\captionof{figure}{Puntos de referencia}
 \label{fig:landmark}
\end{center}



A su vez, se utilizarán puntos de referencia con la ayuda de el software OpenCV y el modelo iBUG 300-W para delimitar la región de interés de la boca.

En la siguiente tabla se muestra la delimitación y agrupación de los puntos de interés, tales como: ojo derecho, ojo izquierdo y boca. De este modelo de detección de rostro, solo serán utilizados el grupo de 48 a 67, que delimitarán la región de la boca.
\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{|l|c|}
\hline
Partes        & \multicolumn{1}{l|}{Puntos de Referencia} \\ \hline
Boca          & {[}48-67{]}                               \\ \hline
Ojo Derecho   & {[}36-41{]}                               \\ \hline
Ojo Izquierdo & {[}42-46{]}                               \\ \hline
\end{tabular}
\caption{\label{tab:landmakrs} Agrupación de Puntos de Referencia}
\end{table}
\end{center}


\item \textbf{Mouth Opening Ratio}


Debido a que bostezar es un signo de cansancio, se propone medir el tamaño y la forma de la boca es necesario para identificar un bostezo. Para esto, se utilizara el \emph{Mouth Opening Ratio} que es un método que utiliza puntos de referencia para medir la apertura de la boca. Entre más grande sea este valor, más es la aperatura de la boca, por lo tanto cumple con las características de un bostezo.

\begin{center}
  \includegraphics[scale=.5]{imagenes/MOR}
\captionof{figure}{\emph{Mouth Opening Ratio}}
 \label{fig:landmark}
\end{center}

La formula general para calular el \emph{MOR} es la siguiente:
\begin{equation}
MOR = \frac{\left \|p_{2}-p_{8}  \right \| +\left \|p_{3}-p_{7}  \right \|+\left \| p_{4}-p_{6} \right \|}{2\left \| p_{1}-p_{5}\right \|}
\end{equation}

Utilizando nuestros puntos de referencia, se podrá calcular el MOR de la siguiente manera:

\begin{equation}
MOR = \frac{\left \|P49-P59  \right \| +\left \|P51-P57  \right \|+\left \| P53-P55 \right \|}{2\left \| P48-P54\right \|}
\end{equation}


\end{itemize}


\newpage

\subsection{Diseño del Módulo de Comunicaciones}
Para el diseño de este módulo se tiene contemplado ejecutar dos procesos asíncronos, es decir, que se ejecutan al mismo tiempo o de manera paralela.

A continuación se muestra el diagrama de Flujo del Módulo de Comunicaciones
\begin{center}
  \includegraphics[scale=0.6]{imagenes/DF-modCom}
\captionof{figure}{Diagrama de Flujo del Módulo de Comunicaciones}
 \label{fig:DF-modCom}
\end{center}
\newpage
La ubicación del conductor será obtenida por el Módulo de Telemetría cada 10 segundos, esto con la intención de no consumir demasiados recursos de procesamiento y energía. Posteriormente será enviada a la Estación Base utilizando la interfaz SixFab-LTE. En caso de no contar con cobertura que permita la conexión a la estación base, la ubicación del  conductor será guardada en el almacenamiento interno de la Unidad de Procesamiento Central. Se realizaran handhshakes a la espera de respuesta de la Estación Base hasta que se obtenga una respuesta de enlace, posteriormente enviarán la o las ubicaciones almacenadas temporalmente hacia  a la Estación Base.



\begin{figure}
  \includegraphics[scale=0.5]{imagenes/DG-modCom}
\captionof{figure}{Diagrama Actividades del Módulo de Comunicaciones}
 \label{fig:DG-modCom}
\end{figure}



\newpage
\subsection{Diseño de la Estación Base}

Con base en los requerimientos, se plantea realizar el diseño de la arquitectura del Módulo de Estación Base, integrando el Módulo de Procesamiento Central. El cual hará énfasis en la organización y comunicación de los elementos que lo conforman.  \\

La Figura \ref{fig:DisenoMEB} a muestra la arquitectura del sistema de Estación base, el cual se compone de las interacciones de los elementos que permitirán al usuario acceder e interactuar con la aplicación web. El diagrama también muestra la participación del Módulo de Procesamiento Central ya que el registro de incidencias y el envío del video de incidencia serán realizados por dicho módulo. La información de los reportes de incidencias y el registro de los conductores serán almacenados en Mongo DB, mientras que los videos de incidencia se almacenarán en Amazon S3. Las credenciales de los Usuarios Administradores que tendrán permitido acceder a la aplicación se almacenarán en Amazon Cognito. Para la aplicación web, el \emph{backend} será desarrollado en node.js mientras que el \emph{frontend} será desarrollado en React, posteriormente los archivos se almacenarán en un repositorio dentro de Github. La aplicación web será alojada y desplegada desde AWS Amplify, lo cual le permitirá al cliente acceder a la aplicación desde una URL.   


\begin{center} 
  \includegraphics[scale=.5]{imagenes/DisenoMEB} 
\captionof{figure}{Diagrama de Diseño - Módulo de Estación Base} 
\label{fig:DisenoMEB} 
\end{center} 


El diagrama de comunicación muestra las interacciones entre elementos que se involucran en cada requerimiento funcional.  Así mismo, dan profundidad al diagrama de Arquitectura del Módulo de Estación Base. La aplicación web hará uso de la Base de Datos (MongoDB) y el \emph{backend} de la aplicación web, que se realizará con Node.js. Mientras que para el despliegue de la aplicación web se requiere del servidor AWS Amplify para permitirle al usuario entrar a la aplicación web. El sistema almacenará el video de incidencia en Amazon S3, enviado desde el Módulo Central de Procesamiento, al cual se podrá acceder por medio de una URL prefirmada. El envío de incidencia requiere la interacción del Módulo Central de Procesamiento el cual se encargará de realizar y enviar el Reporte de Incidencia, posteriormente será almacenado en la Base de Datos (MongoDB).

\begin{center} 
  \includegraphics[scale=.7]{imagenes/diagramaMEB} 
\captionof{figure}{Diagrama de Comunicación - Módulo de Estación Base} 
\label{fig:DisenoMEB2} 
\end{center} 

\clearpage
\subsubsection{Diseño de la Aplicación Web}

Para el diseño y desarrollo de la Aplicación web, se  decidió utilizar el lenguaje Javascript, ya que este cuenta con las herramientas y/o frameworks que mejor se adaptan a los requisitos previamente definidos.
A su vez, se decidió utilizar el NodeJs para el sistema backend.

Node.js, es un entorno en tiempo de ejecución multiplataforma basado en JavaScript. Este es controlado por eventos, permitiendo establecer y gestionar múltiples conexiones al mismo tiempo. Gracias a esta característica, el bloqueo de procesos no existe. NodeJs trabaja fundamentalmente bajo dos características: \emph{asincronía}, que permite la ejecucción de varios procesos al mismo tiempo, y \emph{Entrada/salida sin bloqueo}, que significa poder trabajar con múltiples solicitudes sin bloquear un hilo para una sola solicitud. \cite{NodeJs}

NodeJs es capaz de manejar distintas peticiones sin que tener que esperar a que una petición sea respondida para continuar con la siguiente petición. De ahí la elección de este entorno de Javascript para el desarrollo de la aplicación web.\\

A continuación se muestran diversos diagramas de secuencias que describen los procesos de los requerimientos definidos en la sección de Análisis.


\begin{center}
  \includegraphics[scale=.6]{imagenes/diagramaclasesaw}
\captionof{figure}{Diagrama de Clases - Aplicación Web}
 \label{fig:clasesaw}
\end{center}

En la Figura \ref{fig:clasesaw} se pueden observar las clases que estarán dentro de la aplicación web, así como sus atributos y las interacciones entre estas.


\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_reporte_incidencia}
\captionof{figure}{Diagrama de Secuencia Detalle Reporte Incidencia }
 \label{fig:scaraindust}
\end{center}

El Administrador podrá consultar el reporte de incidencia de cada uno de los conductores. Accediendo a la base de de datos de MongoDB
 

\begin{center}
  \includegraphics[scale=.7]{imagenes/sec_ubicacion}
\captionof{figure}{Diagrama de Secuencia Consultar Ubicación}
 \label{fig:scaraindust}
\end{center}

De igual manera, el Administrador podrá consultar la ubicación en tiempo real del conductor.
 
\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_rcontrasena}
\captionof{figure}{Diagrama de Secuencia Recuperar Contraseña }
 \label{fig:scaraindust}
\end{center}

También podrá recuperar su contraseña en caso de que esta sea olvidada.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_confirmar}
\captionof{figure}{Diagrama de Secuencia Confirmar Incidencia}
 \label{fig:scaraindust}
\end{center}

Para evitar falsos positivos, el Administrador podrá confirmar una incidencia una vez mirando el videoclip del incidente.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_perfil}
\captionof{figure}{Diagrama de Secuencia Consultar Perfil}
 \label{fig:scaraindust}
\end{center}
El Administrador podrá consultar el perfil de cada conductor. 

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_registrar}
\captionof{figure}{Diagrama de Secuencia Registrar Conductor }
 \label{fig:scaraindust}
\end{center}

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_modificar}
\captionof{figure}{Diagrama de Secuencia Modificar Conductor}
 \label{fig:scaraindust}
\end{center}

En caso de que los datos del conductor sean incorrectos, el administrador podrá modificarlos.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_eliminar}
\captionof{figure}{Diagrama de Secuencia Eliminar Conductor }
 \label{fig:scaraindust}
\end{center}

El Administrador también tendrá la opción de dar de baja a un conductor.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_estado}
\captionof{figure}{Diagrama de Secuencia Estado de los Periféricos }
 \label{fig:scaraindust}
\end{center}

La aplicación web indicará si alguno de los periféricos no se encuentra en correcto funcionamiento, lanzando una alerta indicando el número de Unidad y a qué conductor pertenece.

A continuación se muestra el diseño propuesto de cada una de las vistas que tendrá la aplicación web.

\begin{center}
  \includegraphics[scale=.3]{imagenes/login}
\captionof{figure}{Página Inicio de Sesión }
 \label{fig:login}
\end{center}
En la Figura \ref{fig:login} se observa la página dónde el Administrador podrá iniciar sesión ingresando su correo y su contraseña.
 
\begin{center}
  \includegraphics[scale=.3]{imagenes/homescreen}
\captionof{figure}{Página Principal}
 \label{fig:homescreen}
\end{center}

En la Figura \ref{fig:homescreen} se muestra la página principal, dónde se muestran la lista de las incidencias, dónde cada una tendrá un estado de confirmada, rechazada, o pendiente de revisión. También se mostrarán una lista de todos los conductores para poder acceder al perfil de cada uno.

\begin{center}
  \includegraphics[scale=.3]{imagenes/profile}
\captionof{figure}{Página Perfil del Conductor }
 \label{fig:profile}
\end{center}

En la Figura \ref{fig:profile} se aprecia la página de perfil del conductor, que mostrará sus datos personales, así como una lista de todas las incidencias acumuladas.

\begin{center}
  \includegraphics[scale=.3]{imagenes/incident}
\captionof{figure}{Página Detalle de Incidencia }
 \label{fig:incident}
\end{center}

En al Figura \ref{fig:incident}, se puede observar la página desde dónde el administrador podrá revisar el videoclip de las incidencias de cada conductor. También cuenta con las opciones de confirmar o rechazar la incidencia dependiendo de cuál sea el caso.

\begin{center}
  \includegraphics[scale=.3]{imagenes/location}
\captionof{figure}{Página Ubicación en Tiempo Real }
 \label{fig:location}
\end{center}
 
 
En la Figura \ref{fig:location} se muestra la página web dónde el Administrador podrá consultar la ubicación de un conductor en tiempo real.

\clearpage
\subsubsection{Diseño de la Base de Datos}


Basado en la estructura NOSQL de MongoDB, se propone el siguiente modelo para la base de datos, la cual contará con dos colecciones: Conductores e Incidencias. Cabe mencionar que en dicho modelo no se contempla a los administradores, debido a que se utilizará el sistema de Amazon Cognito, que ofrece herramientas de autenticación, registro, verificación e inicio de sesión para el usuario. 

\begin{center}
  \includegraphics[scale=.3]{imagenes/ModeladoBD}
\captionof{figure}{Modelo propuesto para la base de datos en MongoDB}
 \label{fig:ModeloBD}
\end{center}

El modelo de documento para la colección Conductores, se usará para registrar el nombre y apellido de cada conductor, así mismo se contabilizará el número de incidencias que presenté cada uno de ellos, el contador del conductor en marcha aumentará cada vez que el Módulo Central de Procesamiento envié un reporte de incidencia a la base de datos. Si el Usuario Administrador del Módulo de la Estación Base revisa el video de la incidencia y lo cataloga como Descartar entonces se restará la incidencia, si esta es catalogada como Confirmar, el contador permanecerá igual.  Es importante mencionar que el registro de cada conductor se realizará desde la Aplicación Web. A continuación, se muestran los campos y un ejemplo de los valores que pueden ser ingresados dentro del documento de registro de conductores. 

\begin{center}
  \includegraphics[scale=.9]{imagenes/ModeloConductores}
\captionof{figure}{Documento de Registro de Conductores}
 \label{fig:DocumentoConductores}
\end{center}

El modelo de documento para la colección Incidencias, se usará para registrar el Reporte de Incidencia que presente un conductor, el cual será enviado desde el Módulo Central de Procesamiento, por tanto, se realizará una consulta previa a la colección Conductores para obtener el id, nombre y apellido del conductor en marcha. Posteriormente se realizará el reporte de la incidencia, el cual contendrá el Id del conductor, la fecha y hora de la incidencia, el nombre y apellido del conductor, y el estado de incidencia, este último muestra si la incidencia fue catalogada como descartada o confirmada por parte del Usuario Administrador después de revisar el video de la incidencia. Como se mencionó anteriormente, MongoDB permite anidar documentos, por lo que, dentro de este documento se encontrará anidado un segundo documento llamado Detalles, el cual registrará la Ubicación donde sé detectó la incidencia y la URL donde se encontrará almacenado el video.  


\begin{center}
  \includegraphics[scale=.9]{imagenes/ModeloIncidencias}
\captionof{figure}{Documento de registro de Incidencias}
 \label{fig:DocumentoIncidencias}
\end{center}

Cabe señalar que los anteriores modelos muestran el campo Id, sin embargo, MongoDB asigna automáticamente un Id, si el id no es especificado, esto lo realiza cada vez que se crea un nuevo documento dentro de una colección, el cual es un valor hexadecimal de 12 bytes representado en 24 caracteres. Por tanto, se utilizará el id que proporcione Mongo DB en los documentos. \\


\textbf{Amazon Cognito}

Es una suite de herramientas que ofrece autenticación, autorización y administración de usuarios para aplicaciones móviles o web. Amazon Cognito utiliza dos componentes principales: los grupos de usuarios y grupos de identidades. Los grupos de usuarios se tratan de directorios que proporcionan a los usuarios de las aplicaciones opciones para inscribirse e iniciar sesión. Por otro lado, los grupos de indentidades conceden a los usuarios acceso a otros servicios de \emph{Amazon Web Services}

A continuación se muestra el funcionamiento de Amazon Cognito

\begin{center}
  \includegraphics[scale=.5]{imagenes/cognito}
\captionof{figure}{Arquitectura Amazon Cognito}
 \label{fig:DocumentoIncidencias}
\end{center}

\begin{enumerate}
\item En primer lugar, el usuario inicia sesión a través de su respectivo grupo de usuarios y recibe \emph{tokens} de grupos de usuario despuées de una autenticación correcta.
\item Después, la aplicación intercambia dichos tokens del grupo de usuarios por las credenciales de AWS mediante un grupo de identidades.
\item Finalmente, el usuario puede utilizar estas credenciales de AWS para obtener acceso a otros servicios como Amazon S3.
\end{enumerate}

Amazon Cognito se encuentra disponible en varias regiones alrededor del mundo. 

\textbf{Amazon S3 (\emph{Simple Storage Service})}

Amazon S3, es un servicio de almacenamiento de objetos en la nube. Es utilizado para almacenar datos en la nube de una forma segura, eficienta y escalable. Este servicio utiliza elementos llamados \emph{buckets}, que se encargan de almacenar objetos. Un objeto es un archivo o cualquier metadato que describa dicho archivo. Para almacenar datos en S3, primero se debe especificar el nombre de un bucket y la región dónde se planea que opere la aplicación. Esto con la intención de que el acceso a los datos se realice de manera eficiente.








\newpage
\section{Conclusiones}
Con base en los objetivos planteados, se realizó el diseño y análisis del sistema, gracias a la metodología top-dow se dividió en módulos y submódulos que nos permitieron profundizar en cada uno de ellos, delimitando los elementos a utilizar y los algoritmos o herramientas que se utilizarán en la implementación del sistema para trabajo terminal ll, en el presente trabajo se obtuvieron los resultados de las investigaciones realizadas para la elección de cada uno de los elementos principales que conforman el sistema y posteriormente el resultado del diseño de cada módulo planteado.
En el caso del Submódulo de Visión artificial, se decidió desarrollar de manera conjunta la detección de rostro s Haar y extracción de características una Red Neuronal Convolucional.En un principio estas se plantearon de manera separada, este cambio significó la simplificación del modelo para el análisis y diseño. Para el reconocimiento del rostro, ojos y boca dentro de la imagen se decidió utilizar las funciones Haar que se implementarán a través de las librarías de Open CV mientras que para el reconocimiento de signos de somnolencia se utilizarán las redes neuronales convolucionales en el caso de los ojos y para la boca se hará uso de la relación MOR y puntos de referencia faciales.
En un principio, se tenía contemplado utilizar la red LoRaWan para la comunicación y transferencia de archivos. Sin embargo, después de las actividades de investigación, se llegó a la conclusión de que esta opción no es viable, ya que el \emph{bitrate} soportado por LoRaWan es insuficiente para la transferencia de archivos multimedia, que es una parte fundamental de nuestro sistema. Por tanto, se optó por utilizar la interfaz de LTE-M, una opción más costosa, pero que cumple los requisitos de una alta tasa de transferencia, buena cobertura, así como una buena integración con la Rasperry Pi 4. De igual manera, al realizar los cálculos para el envío de fotogramas a la estación base sobrepasaba la máxima tasa de datos propuesta con anterioridad así que optamos por el uso de un compresor de video MP4 que tiene una relación de hasta 16:1 pero que no baja la calidad cómo para no poder cumplir con lo requerido en el funcionamiento del sistema y que varias fuentes mencionan que es el mejor formato para la compresión de videos. Para el envío del posicionamiento del GPS, se llegó a un intervalo de tiempo de 10 segundos que garantiza el correcto trazo de la ruta en el mapa de la página web al consultar las velocidades permitidas en la ciudad de México.
Para el desarrollo de la Estación base, se decidió utilizar la suite de herramientas de Amazon Amplify la cual hace uso de Amplify Hosting y tiene integración directa con Github, esto quiere decir, que los cambios que se realicen en el repositorio se reflejarán de manera automática en la aplicación web. Además AWS Amplify ofrece su servicio de almacenamiento en la nube S3, que será utilizado para el almacenamiento del contenido multimedia mientras que el manejo de credenciales, se eligió Amazon Cognito, que se encargará de administrar las credenciales de acceso a la aplicación. Por otra parte, el gestor de base de datos a implementar será MongoDB el cual nos permite una modelar la base de datos de una manera sencilla y flexible. Para la aplicación web se utilizará Node.js y React los cuales nos permitirán realizar el frontend y backend de dicha aplicación. 
El sistema de manera conjunta fue diseñado para ser capaz de detectar síntomas de somnolencia y alertar al conductor, además de poder obtener la ubicación del conductor en tiempo real la cual será monitoreada desde la aplicación web, que a su vez gestionará la información de los conductores y los reportes de incidencias enviados desde el módulo central de procesamiento. 




\newpage
\section{Referencias}

%\bibliographystyle{apacite}

\begin{thebibliography}{100} %10 significa el número máximo de items
%Aquí ponga la bibliografía y referencias usadas

%Artículo:

\bibitem{WHO} World Health Organization. "Global status report on road safety 2018". World Health Organization (WHO). http://www.who.int/publications/i/item/9789241565684 (accedido el 26 de enero de 2022). 

\bibitem{IMT} Paez Mario, Abarca Emilio. \emph{Herramientas para la seguridad en la movilidad, modelos predictivos de somnolencia en conductores}, Instituto Mexicano del Transporte, Septiembre 2017

\bibitem{TastreoSatelital} Rastreo satelital de vehículos: ¿qué es mejor que el GPS tradicional? (s/f). Beetrack.com. Recuperado de https://www.beetrack.com/es/blog/rastreo-satelital-de-vehiculos 

\bibitem{iot} Jim Chase, \emph{The Evolution of Internet of Things}, 

\bibitem{Sistemasdesomnolencia}  "Sistemas de detección de somnolencia en conductores:Inicio, desarrollo y futuro", Revista Ingeniería y Región., vol. 13, n.º 1, pp. 159?168, 2015. Disponible: https://journalusco.edu.co/index.php/iregion/article/view/717/1372 


\bibitem{TopDown} Metodología top-down. (s.f.) \url{http://163.10.22.82/OAS/modularizacion/metodologa_topdown.html}


\bibitem{kendall} Kenneth E. Kendall, Julie E. Kendall, \emph{Análisis y Diseño de Sistemas}, Octava Edición , Pearson Educación de México, 2011


\bibitem{intensidad} Roehrs T, Carskadon MA, Dement WC, Roth \emph{T. Daytime 
Sleepiness and alertness}. Publicado en: Kryger MH, Roth T, Dement WC, 
eds. \emph{Principles and Practice of Sleep Medicine}, 4th ed: Saunders; 
2005:39-49.

\bibitem{JetsonNano} nvidia. (s.f.). NVIDIA jetson nano. https://www.nvidia.com/es-la/autonomous-machines/embedded-systems/jetson-nano/

\bibitem {vision} David A. Forsyth, Jean Ponce, \emph{Computer Vision a Modern Approach}, Second Edition, Pearson, 2012


\bibitem{Referencia0} Fernando Berzal, \emph{ Redes Neuronales y Deep Learning}, Granada, 2018


\bibitem {CNNpresentacion} Todt, E., Krinski, B. A. (2019, 30 de noviembre). Convolutional neural network - CNN. \url{https://www.inf.ufpr.br/todt/IAaplicada/CNN_Presentation.pdf}


\bibitem{viola}Viola P.; Jones M, \emph{Rapid Object Detection
using a Boosted Cascade of Simple Features}. IEEE International Conference on Computer Vision and Pattern Recognition,2001

\bibitem{sixfab} Sixfab. "Raspberry Pi IP54 Outdoor Project Enclosure - Sixfab". Sixfab. https://sixfab.com/product/raspberry-pi-ip54-outdoor-iot-project-enclosure/ (accedido el 2 de enero de 2023).

\bibitem{Referencian4} J. A. Castillo. \emph{WLAN: Qué es, definición, estándar 802.11 y diferencias con LAN.}
https://www.profesionalreview.com/2020/03/07/wlan-que-es/ (accedido el 2 de noviembre de
2022).



\bibitem{Referencian5}Tarify.Win!\emph {Red WWAN ¿Qué es, para qué sirve y cómo
funcionan?}https://tarify.win/definiciones/red-wwan/


\bibitem{Referencian6}La Rosa, A. (2021, 13 julio). \emph{LPWAN como base de comunicaciones para IoT} Pandora 
FMS-The Monitoring Blog. Recuperado 8 de mayo de 2022, de https://pandorafms.com/blog/es/que-eslpwan/?msclkid=08006fc5cf4611ecbc00aa3b275ed2b5

\bibitem{Referencian7}\emph{LTE-M, el despegue esperado para IoT. Hablemos de empresas.} https://hablemosdeempresas.com/grandes-empresas/lte-m-despliegue-soluciones-iot/

\bibitem{Referencian8}S{\'a}nchez Rosado, David,\emph{NB-IoT tecnolog{\'\i}as celulares narrow-band: an{\'a}lisis pr{\'a}ctico de las soluciones de Telef{\'o}nica y Vodafone},2019

\bibitem{Referencian14} M. Cid. \emph{Categorías LTE o 4G: qué son y qué velocidades máximas ofrece cada una de ellas.} Xataka Móvil - Teléfonos móviles, tarifas, operadores de telefonía. https://www.xatakamovil.com/conectividad/categorias-lte-o-4g-que-son-y-que-velocidades-maximas-ofrece-cada-una-de-ellas

\bibitem{Referencian15}\emph{¡No aceleres! Estos son los nuevos límites de velocidad 2022 en México.} ADNPolítico. https://politica.expansion.mx/mexico/2022/05/19/estos-son-nuevos-limites-velocidad-2022 

\bibitem{Referencian16}\emph{MP4 - EcuRed.} EcuRed. https://www.ecured.cu/MP4\#:~:text=Un\%20archivo\%20de\%20MP4\%20lleva\%20sonido\%20y\%20video,de\%2020\%20segundos\%20de\%20clips\%20de\%20audio\%20(MP4/20s).

\bibitem{Referencian17}C. Brunner, A. Garavaglia, M. Mittal, M. Narang, and J. Vargas Bautista \emph{Inter-System Handover Parameter Optimization. In: Proceedings of IEEE Vehicular Technology Conf.} 2006.





\bibitem{CoberturaNacional} "Cobertura 3G / 4G / 5G Telcel Mobile - nPerf.com". Internet Speed test : Test your broadband connection - nPerf.com. https://www.nperf.com/es/map/MX/-/2004799.Telcel-Mobile/signal/ (accedido el 22 de diciembre de 2022).



\bibitem{algoritmosdeaprendizaje} https://www.alteryx.com/es-419/glossary/supervised-vs-unsupervised-learning\#:~:text=Hay\%20una\%20diferencia\%20clave\%20entre,etiquetados\%20con\%20la\%20respuesta\%20correcta


\bibitem{EstadodelAarte1} Pachouly, S., Bhondve, N., Dalvi, A., Dhande, V., \& Bhamare, N. (2020, 6 de junio). Driver drowsiness detection using machine learning with visual behaviour. www.ijcrt.org. https://ijcrt.org/papers/IJCRT2006408.pdf

\bibitem{EstadodelAarte2} Kanojia, G., Kanojiya, V., \& Mendonza, G. (2020, diciembre). Detection of drowsiness and distraction of drivers using cnn. https://www.trendytechjournals.com/files/issues/volume4/issue7-5.pdf

\bibitem{EstadodelAarte3} Sri, M. K., \& Annamani, T. (2022, abril). Driver drowsiness detection system using convolutional neural networks. https://ijarsct.co.in/Paper3399.pdf 

\bibitem{facedetection} Mayank Chauhan, Mukesh Sakle, \emph{Study \& Analysis of Different Face Detecion Techniques}


\bibitem{EstadodelAarte4} Rodriguez, A., \& Luis, D. J. (2021, mayo). Diseño e implementación de sistema de visión artificial para alerta y detección de somnolencia mediante aprendizaje profundo aplicable en conductores de vehículos. https://dspace.unitru.edu.pe/handle/UNITRU/16872


\bibitem{EstadodelAarte5} M. Limaquispe y E. Sánchez. "SISTEMA DE DETECCIÓN DE SOMNOLENCIA MEDIANTE INTELIGENCIA ARTIFICIAL EN CONDUCTORES DE VEHÍCULOS PARA ALERTAR LA OCURRENCIA DE ACCIDENTES DE TRÁNSITO"". Repository. http://repositorio.unh.edu.pe/handle/UNH/2327

\bibitem{EstadodelAarte6} Eugenio, B. L. H., Alejandra, G. P. K., \& Pichardo Iniesta José Alejandro. (2019, junio). Diseño de un sistema electrónico para detectar somnolencia en automovilistas por medio de la actividad ocular. https://tesis.ipn.mx/handle/123456789/27287

\bibitem{EstadodelAarte7} Becerril, E. L., Ramírez, A. M., \& Velázquez, E. T. J. (s.f.). Sistema para la detección del estado de somnolencia en seres humanos, con reconocimiento de patrones. $https://uptexcoco.edomex.gob.mx/sites/uptexcoco.edomex.gob.mx/files/files/2020/articulos-Tesis/sistema_somnolencia.pdf$

\bibitem{EstadodelAarte8} Solís, H. F. (2022, 13 de septiembre). Sistema de detección de somnolencia. https://riull.ull.es/xmlui/bitstream/handle/915/30312/Sistema%20de%20deteccion%20de%20somnolencia.pdf?sequence=1&amp;isAllowed=y

\bibitem{EstadodelAarte9} Pacay, C., \& Blanca Fanny. (2020). Desarrollar un prototipo de reconocimiento facial basado en Machine Learning para detectar estado de Somnolencia en conductores de una cooperativa de transporte. http://repositorio.ug.edu.ec/handle/redug/49449?mode=full

\bibitem{EstadodelAarte10} E. L. Benavides y M. M. Medina. "Sistema Basado en la Detección y notificación de somnolencia para conductores de autos". Repositorio Universidad de Córdoba. https://repositorio.unicordoba.edu.co/bitstream/handle/ucordoba/536/Trabajo%20de%20grado.pdf?sequence=1&amp;isAllowed=y

\bibitem{EstadodelAarte11} Adrián, Ñ. H. (2022, 30 de junio). Detección de somnolencia para conducción sin accidentes. http://hdl.handle.net/10045/124695

\bibitem{EstadodelAarte12} Avila, R., \& Arturo, W. (2016). Geolocalización transaccionalidad mapa ecuador cne democracia localización ubicación. http://repositorio.ug.edu.ec/handle/redug/16806

\bibitem{EstadodelAarte13} Vilca, G., \& Eduardo, J. (2016, 3 de agosto). Diseño e implementación de un sistema de geolocalización en interiores para plataforma Android via la red Enterprise WLAN de la PUCP. https://tesis.pucp.edu.pe/repositorio/handle/20.500.12404/7156

\bibitem{EstadodelAarte14} Federico, A., Guillermo, C., \& Guzmán, P. (2018). Geolocalizacoón con LoRa mediante multilateración. https://www.colibri.udelar.edu.uy/jspui/handle/20.500.12008/20293

\bibitem{EstadodelAarte15} Ramírez, C. E. E., Flores, R. E. R., \& Hernández, J. A. V. (2018). Propuesta de un sistema de geolocalización y monitoreo vía GPS/GSM/GPRS aplicado a un pulsómetro para personas con enfermedades vasculares. https://tesis.ipn.mx/handle/123456789/27690

\bibitem{EstadodelAarte16} Espinoza, B. R. A. V. (2017). Influencia de un sistema de geolocalización en el control y monitoreo de vehículos con dispositivos GPS en una empresa logística.


\bibitem{EstadodelAarte17} Juan Carlos, C. P. (2017, 15 de febrero). Diseño de la red de acceso LTE en el distrito de Jesús María ¡https://tesis.pucp.edu.pe/repositorio/handle/20.500.12404/7847

\bibitem{conapra} M. Paez y Emilio Abarca. \emph{Resumen Boletines}, Instituto Mexicano del Transporte.
https://imt.mx/resumen-boletines.html?IdArticulo=449\&amp;IdBoletin=168 (accedido 
el 18 de marzo de 2022).


\bibitem {NodeJs} Jonathan Wexler, \emph{Get Programming with Node.js}, Manning, 2019

\bibitem {js} Marjin Haverbeke \emph{Eloquent Javascript}, Third Edition, No Starch Press, 2020


\bibitem {AWS} Amazon, \emph{Amazon Amplify}, https://aws.amazon.com/es/amplify/

\bibitem {deepedgebench} Stepahn Baller, Anshul Jindal \emph{DeepEdgeBench: Benchmarking Deep Neural Networks on Edge Devices}


\bibitem {mongo} Kyle Banker, \emph{MondoDB in Action}, Second Edition, Manning, 20216

\bibitem{python} Irv Kalb, \emph{Object-Oriented Python}, Primera Edición ,No Starch-Press, 2021
%Libro
\bibitem{Referencia2}
V.Moret Bonillo, \emph{Fundamentos de Inteligencia Artificial}, Segunda Edición,Santiago de Compostela: Universidad de La Coruña Servicio de Publicaciones, 2005.

\bibitem{Referencia3} Ian Sommerville, \emph{Ingeniería de Software}, Novena Edición , Pearson Eduación de México, 2011


\bibitem{nanovspi} Gunan Dewantoro, Jamil Mansuri, \emph{Comparative Study of Computer Vision Based Line Followers using Rasperry Pi and Jeston Nano}

\bibitem{Referencia5} Aurélien Géron, \emph{Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow}, Segunda Edición , O'Reilly, 2009


\bibitem{Referencia7} Kurt Demaagd, Anthony Oliver, Nathan Oostendorp y Katherine Scott \emph{Practical Computer Vision with OpenCV}, Tercera Edición, O'Reilly, 2017

\bibitem{Referncia8}Cuno Plister, \emph{Getting Started with Internet of Things},Primera Edición, O'Reilly, 2011

\bibitem{Referencia9} Vilca Espinoza, R.A, \emph{Influencia de un sistema de geolocalización en el control y monitoreo de vehículos con dispositivos GPS en una empresa logística}, 2007

\bibitem{Referencia10} S. Pachouly, N. Bhondve, A. Dalvi, V. Dhande y N. Bhamare. "Driver drowsiness detection using machine learning with visual behaviour". https://ijcrt.org/papers/IJCRT2006408.pdf (accedido el 2 de noviembre de 2022).






\end{thebibliography}

\end{document}



