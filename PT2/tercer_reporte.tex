\documentclass[12pt,letterpaper]{article}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{anysize}
\usepackage{array}
\usepackage{multicol}
\usepackage{lmodern}
\usepackage{adjustbox}
\usepackage{enumitem}
\usepackage{float}
\marginsize{2cm}{2cm}{1cm}{1cm}
\usepackage{fancyhdr}
\usepackage{listings}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\footnotesize UPIITA}
%\fancyfoot[R]{\footnotesize Diseño}
\fancyfoot[R]{\thepage}
\fancyfoot[L]{\footnotesize Proyecto Terminal 2}
\renewcommand{\footrulewidth}{0.4pt}
\usepackage{graphics}
\usepackage{capt-of}
\usepackage[pdftex=false,colorlinks=true,plainpages=true,citecolor=blue,linkcolor=blue]{hyperref}
\setlength\parindent{0pt}
\usepackage[usenames]{color}
\usepackage{pdfpages}
\usepackage{float}
\usepackage{shapepar}

\begin{document}
\renewcommand{\tablename}{Tabla}
\renewcommand{\listtablename}{Índice de tablas}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.3mm}}

\includegraphics[scale=0.45]{imagenes/ipn}
\hspace{10cm}
\includegraphics[scale=0.15]{imagenes/upiita}
\\


\begin{center}


\textsc{\Large ``Sistema para el monitoreo, detección y alerta de somnolencia del conductor mediante visión artificial, comunicación inalámbrica y geolocalización''}\\[0.5cm]



\HRule \\[0.4cm]
{ \huge \bfseries Tercer Reporte Parcial}\\[0.4cm]

\HRule \\[1.5cm]

\begin{center}

Lista de actividades
 

\begin{itemize}
\item Implementación del sistema de Geolocalización
\item Despliegue de la aplicación web 
\item Realizar la conexión de la aplicación web con el Módulo Central de Procesamiento
\item Implementación del modelo de red neuronal para la detección de somnolencia en la Jetson Nano
\item Realizar la integración de los periféricos al Módulo Central de Procesamiento


\end{itemize}

\end{center}


\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{\\Autores:}\\
Alan Eduardo Gamboa Del Ángel\\
Maite Paulette Díaz Martínez\\

%Grupo:4MM6\\
\end{flushleft}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{flushright} \large
\emph{Asesores:} \\
M.en C. Niels Henrik Navarrete Manzanilla\\
Dr. Rodolfo Vera Amaro\\

\end{flushright}
\end{minipage}

\vfill

19 de Mayo 2023

\end{center}


\end{titlepage}
\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\listoftables

\newpage
\section{Implementación del Sistema de Geolocalización}

\subsection{Objetivo}
Implementar el sistema de geolocalización en la Jetson Nano.
Además de mostrar en la aplicación web la ubicación en tiempo
real.


\subsection{Descripción}

\textbf{Habilitar GPS y obtener datos de posición GPS desde la Jetson Nano }

Se inicio habilitando el GPS en la Jetson Nano a través de la terminal:
\begin{itemize}

\item Configuración del puerto serial: 

\begin{lstlisting}
sudo stty -F /dev/ttyTHS1 115200
\end{lstlisting}

/dev/ttyTHS1 es el dispositivo del puerto serial utilizado y 115200 es la velocidad de transmisión.\\

\item Habilitar el GPS: 
el comando echo envia comandos AT al módulo GPS y habilita su funcionalidad.

\begin{lstlisting}
echo "AT+CGNSPWR=1" > /dev/ttyTHS1
\end{lstlisting}


\item Verificar el estado del GPS:  
El comando cat, lee la salida del puerto serial y verificar el estado del GPS. 

\begin{lstlisting}
cat /dev/ttyTHS1
\end{lstlisting}


Al ejecutar el comando cat /dev/ttyTHS1 en la terminal, se mostrará la salida del puerto serial /dev/ttyTHS1. Si el GPS se habilitó correctamente, se observará la respuesta del módulo GPS indicando que está listo para recibir datos de posición. Esta respuesta confirmará que el GPS está funcionando correctamente y listo para proporcionar información de ubicación.\\
\end{itemize}

Para obtener los datos de posición GPS, fue necesario interactuar con el módulo SIM7600X a través del programa en Python:

\begin{center}
  \includegraphics[scale=0.6]{imagenes/GPSpy1.JPG}
\captionof{figure}{Código que permite obtener la posición GPS parte 1}
 \label{fig:GPSpy1} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.6]{imagenes/GPSpy2.JPG}
\captionof{figure}{Código que permite obtener la posición GPS parte 2}
 \label{fig:GPSpy2} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.6]{imagenes/GPSpy3.JPG}
\captionof{figure}{Código que permite oibtener la posición GPS parte 3}
 \label{fig:GPSpy3} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.7]{imagenes/GPSpy4.JPG}
\captionof{figure}{Código que permite obtener la posición GPS parte 4}
 \label{fig:GPSpy4} 
\end{center} 

\textbf{AWS Maps}\\

AWS Maps es un servicio de Amazon Web Services que proporciona capacidades de mapas y geolocalización en la nube. Permite a crear, visualizar y analizar datos geoespaciales en aplicaciones y servicios.\\

Se creó un mapa en AWS Maps donde se configuró la apariencia y funcionalidad del mismo, incluyendo los estilos de visualización, las capas de datos y las interacciones del usuario. El propósito de este mapa es mostrar información geográfica, como ubicaciones, rutas, geovallas, puntos de interés, entre otros. La configuración del mapa permitió personalizar su aspecto y adaptarlo a las necesidades del proyecto.\\

Para crear el mapa se inició sesión en la Consola de administración de AWS. Luego,se accedió a la página de AWS Maps Service en la consola de administración. A continuación, se hizo clic en "Crear mapa" para comenzar a crear el mapa.En el proceso de creación, se seleccionó un nombre para el mapa y se especificó la región de AWS donde se deseaba crearlo. Seguidamente, se eligió el estilo de mapa y posteriormente  se configurarón las capas del mapa, pudiendo agregar capas para mostrar datos como carreteras, edificios, ríos, y también pudo agregar sus propios datos geoespaciales como capas personalizadas, finalmente, se  de creo el mapa.\\

Una vez que creado el mapa en AWS Maps, se agrego y configuro un rastreador para realizar el seguimiento del dispositivo llamado "mydevice" en el mapa. Los rastreadores se encargaron de recopilar y actualizar la ubicación de los dispositivos, brindando información en tiempo real.\\

A continuación, se presenta un resumen de cómo se creó un rastreador en AWS Maps:

En la página del mapa en la consola de administración de AWS Maps, se hizo clic en "Crear rastreador". Se seleccionó un nombre para el rastreador y se especificó la región de AWS donde se deseaba crear. Se procedió a configurar los detalles del rastreador, como la frecuencia de actualización de la ubicación de los dispositivos en este caso cada 10m envía las coordenadas. Finalmente, se hizo clic en "Crear rastreador" para finalizar la configuración del mismo.


\begin{center}
  \includegraphics[scale=0.5]{imagenes/Mymapaws.png}
\captionof{figure}{Mapa creado en AWS - MyMap}
 \label{fig:Mymapa} 
\end{center} 


\textbf{Ubicación geográfica en la Aplicación web}

Para obtener el historial de posiciones de un dispositivo, se definió la función llamada "getDevicePosition". Posteriormente, se utilizó la función "client.getDevicePositionHistory" con el argumento "params" para solicitar el historial de posiciones del dispositivo. Después, se creó la variable "tempPosMarkers" para almacenar los resultados obtenidos al mapear los elementos de "data.DevicePositions". Para cada elemento "devPos" en "data.DevicePositions", se imprimió su posición en la consola y se generó un nuevo objeto con propiedades "index", "Long" y "lat", que representaban los valores de la posición del dispositivo. Este archivo se guardó con la extensión .jsx.

\begin{center}
  \includegraphics[scale=0.35]{imagenes/RealTimeMap}
\captionof{figure}{Código para obtener la ubicación geográfica en la aplicación web}
 \label{fig:RealTimeMap} 
\end{center} 


\subsection{Resultados}

Obtención de coordenadas geográficas 

\begin{center}
  \includegraphics[scale=0.55]{imagenes/Mymapaws2.png}
\captionof{figure}{coordenadas geográficas en la Jetson Nano}
 \label{fig:Mymapadet} 
\end{center} 


Mapa creado en AWS Maps 

\begin{center}
  \includegraphics[scale=0.55]{imagenes/Mymapaws2.png}
\captionof{figure}{Detalles del mapa creado en AWS}
 \label{fig:Mymapadet} 
\end{center} 


coordenadas geográficas que recibe la página web 

\begin{center}
  \includegraphics[scale=0.65]{imagenes/RealTimeMap2}
\captionof{figure}{coordenadas geográficas que recibe la página web }
 \label{fig:CorGeo} 
\end{center} 


\newpage
\section{Despliegue de la aplicación web} \label{base_hat}

\subsection{Objetivo}
Desplegar el frontend y backend de la aplicación en su totalidad
en un servidor dedicado para que pueda ser accesible desde cualquier dispositivo con acceso a internet y con un navegador.
\subsection{Descripción}

Para poder alojar y desplegar la aplicación web en un servicio de \emph{hosting}, se utilizará Amplify Hosting.	

Se necesita ingresar a la consola de AWS y seleccionar el servicio de Amplify Hosting

\begin{center}
  \includegraphics[scale=0.5]{imagenes/hosting}
\captionof{figure}{Amplify Hosting
}
 \label{fig:hat} 
\end{center} 

Hosting requiere algúna fuente de alojamiento de código para poder desplegar la apliación web. En este caso, la aplicación web fue alojada utilizando \emph{Github}, por lo tanto, se selecciona esta opción.

Posteriormente, se requiere seleccionar el repositorio el cual será alojado, en este caso, el nombre de dicho repositorio es \emph{eb}. A su vez, se selecciona la ramificación \emph{main} para ser desplegada.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/repo}
\captionof{figure}{ramificación de repositorio de Github}
 \label{fig:libraries} 
\end{center} 


\subsection{Resultados}
Acceso a la pagina web desde el buscador con la siguiente URL: \\
https://main.dcst1c83llut3.amplifyapp.com/login

\begin{center}
  \includegraphics[scale=.45]{imagenes/paginaweb.JPG}
\captionof{figure}{Acceso a la página web desde el buscador}
 \label{fig:libraries} 
\end{center} 

\newpage

\section{Realizar la conexión de la aplicación web con el Módulo Central de Procesamiento´}

\subsection{Objetivo}
Implementación de técnicas y configuraciones necesarias para realizar la conexión de la aplicación web


\subsection{Descripción}

La primer configuración que se realizó, fue la habilitación y activación de la red 4G Lte en la Jetson Nano por medio de la interfaz wwan0, que nos permite conectarnos a internet por medio de la red celular.


Posteriormente se realizó la conexión del Módulo Central de Procesamiento y la apliación web, se utilizó la librería \textbf{Boto3}

Boto3 es una biblioteca de Python desarrollada por Amazon Web Services (AWS) que permite interactuar con los servicios de AWS de manera programática. Proporciona una interfaz de programación de aplicaciones (API) fácil de usar para acceder y administrar recursos en la nube de AWS.

Para crear una conexión a AWS Amplify utilizando Boto3, se siguieron los siguientes pasos:

En primer lugar, se instaló Boto3 utilizando el comando: pip install boto3. A continuación, se configuraron las credenciales de AWS, proporcionando las claves de acceso de IAM que otorgan acceso a los servicios de AWS. Estas credenciales se configuraron manualmente en el archivo de configuración. Luego, se importó el módulo Boto3 en el script de Python y se creó una conexión al servicio de AWS Amplify utilizando las credenciales configuradas anteriormente. A partir de la conexión establecida, se pudieron utilizar los métodos proporcionados por el cliente de Boto3 para interactuar con AWS Amplify.


\subsection{Resultados}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/4glte.jpeg}
\captionof{figure}{Red 4G LTE activa por medio de la interfaz wwan0}
 \label{fig:4GLTE} 
\end{center} 

Conexión a AWS Amplify utilizando Boto3

\begin{center}
  \includegraphics[scale=0.85]{imagenes/ConexionPw.JPG}
\captionof{figure}{Conexión hacía Aws}
 \label{fig:addstorage} 
\end{center} 



\newpage
\section{Implementación del modelo de red neuronal para la detección de somnolencia en la Jetson Nano}


\subsection{Objetivo}
Integrar la red neuronal entrenada en conjunto con los
algoritmos de detección de rostro y ojos, y la metrica MOR.
	
\subsection{Descripción}
Se cargó el modelo de red neuronal convolucional (CNN) previamente entrenado para la detección de ojos cerrados y abiertos. Luego, se inicializó la cámara para capturar el flujo de video utilizando el método gstreamer pipeline. A continuación, se inició un bucle infinito para procesar cada cuadro de video capturado. Dentro del bucle, cada cuadro de video se convirtió a escala de grises y se utilizaron clasificadores de cascada de Haar para detectar caras y ojos en el cuadro de video. Posteriormente, se extrajo el área de interés correspondiente a cada ojo detectado.
Se realizó el preprocesamiento necesario en cada ojo para que coincidiera con el formato de entrada del modelo y se llevó a cabo una predicción utilizando el modelo entrenado para determinar si los ojos estaban cerrados o abiertos. Se calculó un puntaje basado en el número de ojos cerrados detectados y se mostró este puntaje junto con un texto que indica si los ojos estaban cerrados o abiertos en el cuadro de video. Si el puntaje supera el umbral determinado, se consideraba que la persona estaba somnolienta y se activaba una alerta. El bucle continúa hasta que se presiona la tecla 'q', momento en el cual se liberaran los recursos de la cámara y se cierran las ventanas de visualización

\begin{center}
  \includegraphics[scale=0.6]{imagenes/CodigoSomnolencia1.JPG}
\captionof{figure}{Código de somnolencia parte 1}
 \label{fig:Somnolencia1} 
\end{center}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/CodigoSomnolencia2.JPG}
\captionof{figure}{Código de somnolencia parte 2}
 \label{fig:Somnolencia1} 
\end{center}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/CodigoSomnolencia3.JPG}
\captionof{figure}{Código de somnolencia parte 3}
 \label{fig:Somnolencia1} 
\end{center}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/CodigoSomnolencia4.JPG}
\captionof{figure}{Código de somnolencia parte 4}
 \label{fig:Somnolencia1} 
\end{center}

El archivo respecto a la métrica MOR, se complementó con la grabación del video y el envió del video hacía la página web.

\begin{center}
  \includegraphics[scale=0.6]{imagenes/MORcodigo1.JPG}
\captionof{figure}{ Grabación del video y el envió del video hacía la página web}
 \label{fig:Somnolencia1} 
\end{center}

\subsection{Resultados}


\begin{center}
  \includegraphics[scale=0.4]{imagenes/OE.jpeg}
\captionof{figure}{Prueba de somnolencia ojos abiertos}
 \label{fig:crearConductor} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/CE.jpeg}
\captionof{figure}{Prueba de somnolencia ojos cerrados}
 \label{fig:crearConductor} 
\end{center} 


\begin{center}
  \includegraphics[scale=0.4]{imagenes/MOR2.jpeg}
\captionof{figure}{Prueba de la metrica MOR 1}
 \label{fig:crearConductor} 
\end{center} 


\begin{center}
  \includegraphics[scale=0.4]{imagenes/MOR1.jpeg}
\captionof{figure}{Prueba de la metrica MOR 2}
 \label{fig:crearConductor} 
\end{center} 




\newpage
\section{Realizar la integración de los periféricos al Módulo Central de Procesamiento}


\subsection{Objetivo}
Integrar dentro de un contenedor los periféricos junto con la Jetson Nano
\subsection{Descripción}

Se integraron los periféricos dentro del contenedor para la Jetson Nano.

El contenedor de la Jetson Nano es una carcasa de metal con un ventilador de refrigeración de 5 V, diseñado específicamente para ser compatible con la placa de desarrollo NVIDIA Jetson Nano (versión B01 con 4 GB de RAM).

Esta carcasa ofrece varias características adicionales, como soporte para reinicio de cámara, un botón de encendido y una compatibilidad específica con la cámara Waveshare IMX219 Series. Además, el contenedor también tiene soporte para adaptadores inalámbricos Wireless-AC8265, lo que permite la conectividad Wi-Fi y Bluetooth en la Jetson Nano. Otra característica destacada es la compatibilidad con el módulo de placa de expansión LTE CAT4 basado en SIM7600G-H. Este módulo proporciona capacidades de comunicación inalámbrica, como llamadas telefónicas, mensajes de texto (SMS) y posicionamiento GPS utilizando los sistemas BeiDou y Glonass.


\begin{center}
  \includegraphics[scale=0.25]{imagenes/Perifericos1.jpeg}
\captionof{figure}{Carcasa sin armar}
 \label{fig:crearConductor} 
\end{center} 


\subsection{Resultados}

contenedor de la Jetson nano y los periféricos integrados:


\begin{center}
  \includegraphics[scale=0.3]{imagenes/Perifericos2.jpeg}
\captionof{figure}{Carcasa armada con la Jetson Nano y periféricos integrados}
 \label{fig:crearConductor} 
\end{center} 


\newpage
\section{Conclusiones}

En conclusión, en este proyecto se habilitó el GPS en la Jetson Nano a través de la terminal utilizando comandos AT y se verificó su estado mediante la lectura de la salida del puerto serial. Luego, se interactuó con el módulo SIM7600X a través de un programa en Python para obtener los datos de posición GPS. Se utilizó AWS Maps, un servicio de Amazon Web Services, para crear un mapa personalizado en la nube. Se configuraron la apariencia y la funcionalidad del mapa, incluyendo los estilos de visualización, las capas de datos y las interacciones del usuario.  Se implementó una función para obtener el historial de posiciones del dispositivo, utilizando la función "client.getDevicePositionHistory" de AWS. Los resultados se mapearon en un objeto que contenía las propiedades de la posición del dispositivo. Se guardó este archivo con extensión .jsx. Para desplegar la aplicación web en su totalidad, se utilizó Amplify Hosting como servicio de hosting. Se seleccionó el repositorio alojado en GitHub y se configuró la conexión utilizando la biblioteca Boto3 de Python, que permite interactuar con los servicios de AWS. Además, se cargó un modelo de red neuronal convolucional (CNN) previamente entrenado para la detección de ojos cerrados y abiertos. Se utilizó la cámara de la Jetson Nano para capturar el flujo de video y se procesó cada cuadro de video para detectar caras y ojos. Se realizó una predicción utilizando el modelo entrenado para determinar si los ojos estaban cerrados o abiertos. Se mostró un puntaje y un texto indicando si los ojos estaban cerrados o abiertos, y se activó una alerta si el puntaje superaba un umbral establecido. Finalmente se integraron los periféricos junto con la Jetson nano dentro de una carcasa de metal.

Este proyecto integró el uso del GPS en la Jetson Nano, la visualización de datos geográficos en un mapa personalizado utilizando AWS Maps, la obtención de historial de posiciones del dispositivo, el despliegue de una aplicación web utilizando Amplify Hosting, la detección de ojos cerrados y abiertos utilizando un modelo de red neuronal convolucional y la integración de los périfericos con la Jetson Nano dentro de una carcasa de metal.


\newpage
\section{Bibliografia}
%\bibliographystyle{apacite}

\begin{thebibliography}{10} %10 significa el número máximo de items
%Aquí ponga la bibliografía y referencias usadas

%Artículo:

\bibitem {react} React Dev Team, \emph{React}, React. https://react.dev/ (accedido el 1 de abril de 2023).

\bibitem {waveshare} Waveshare Electronics, \emph{SIM7600G-H 4G for Jetson Nano - Waveshare Wiki}, Waveshare Electronics\url{https://www.waveshare.com/wiki/SIM7600G-H_4G_for_Jetson_Nano_4G_connecting} (accedido el 16 de abril de 2023).

\bibitem {graphql} Facebook Dev Team, \emph{Introduction to GraphQL | GraphQL | A query language for your API} https://graphql.org/learn/ (accedido el 4 de abril de 2023).


\bibitem{Nvidia} NVIDIA, "Get Started with the Jetson Nano Developer Kit", NVIDIA Developer, 2019. [Online]. Disponible: https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit\#intro. [Accedido: Abril 02 2023].

\bibitem{sdimage} Nvidia Developer, "Get Started with Jetson Nano Devkit," Nvidia Developer. [En línea]. Disponible: https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit\#write. [Accedido: 2 de abril de 2023].

\bibitem{JetsonInf}Dusty, N. "Building the Repo - NVIDIA Jetson Inference," GitHub. [Online]. Disponible en: https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md. [Accedido en: 02-abr-2023].


\end{thebibliography}


\end{document}


