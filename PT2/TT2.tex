\documentclass[12pt,letterpaper]{article}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{anysize}
\usepackage{array}
\usepackage{lmodern}
\usepackage{adjustbox}
\usepackage{titlesec}
\usepackage{float}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage{verbatim}

\marginsize{2cm}{2cm}{1cm}{1cm}
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\footnotesize UPIITA}
%\fancyfoot[R]{\footnotesize Diseño}
\fancyfoot[R]{\thepage}
\fancyfoot[L]{\footnotesize Proyecto Terminal 1}
\renewcommand{\footrulewidth}{0.4pt}
\usepackage{graphics}
\usepackage{capt-of}
\usepackage[pdftex=false,colorlinks=true,plainpages=true,citecolor=blue,linkcolor=blue]{hyperref}
\setlength\parindent{0pt}
\usepackage[usenames]{color}
\usepackage{pdfpages}
\usepackage{float}
\usepackage{shapepar}

\begin{document}
\newcommand\tab[1][1cm]{\hspace*{#1}}
\renewcommand{\tablename}{Tabla}
\renewcommand{\listtablename}{Índice de tablas}


\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\listoftables

\newpage
\section{Glosario de Abreviaturas}
\textbf{Glosario de Abreviaturas}

\begin{itemize}

    %\item \textbf{CNN} \tab[4cm] \emph{Convolutional Neural Network}
    \item \textbf{CPU} \tab[4cm] \emph{Central Processing Unit}
    \item \textbf{GPU} \tab[4cm] \emph{Graphical Processing Unit}
    \item \textbf{LTE} \tab[4cm] \emph{Long Term Evolution for Machines}
    \item \textbf{RAM} \tab[4cm] \emph{Random Access Memory}
    \item \textbf{SBGD}  \tab[4cm] Sistema Gestor de Base de Datos
    \item \textbf{SQL} \tab[4cm] \emph{Structured Query Language}
    
\end{itemize}

\newpage
\section{Resumen}

El sistema propuesto para la detección de somnolencia en conductores utiliza técnicas de visión artificial para analizar en tiempo real la posición del rostro, los ojos y la boca a través de un flujo de video. Se clasifican los estados de los ojos y la boca para identificar síntomas de somnolencia mediante puntos de referencia faciales. La medición de la relación de apertura en los ojos y la boca se realiza mediante el seguimiento de parpadeos y bostezos. En caso de detectar somnolencia, el sistema activa una alarma y genera un reporte de incidencia enviado a una base de datos. Se emplea una Jetson Nano para la portabilidad del sistema. A su vez, se ha desarrollado una aplicación web que ofrece el monitoreo en tiempo real de la ubicación del conductor, además de proporcionar un sistema de administración que permite a los usuarios acceder y visualizar la información de los reportes de incidencia, así como detalles específicos de cada conductor.
\\

\emph{\textbf{Palabras Clave:}} Somnolencia, Visión Artificial, Geolocalización, Alerta, Aplicación web, Sistema de Administración.

\section{Abstract}
The proposed system for detecting drowsiness in drivers uses artificial vision techniques to analyze in real-time the position of the face, eyes, and mouth through a video stream. The states of the eyes and mouth are classified to identify drowsiness symptoms using facial reference points. The measurement of the opening ratio in the eyes and mouth is carried out through tracking blinks and yawns. If drowsiness is detected, the system activates an alarm and generates an incident report sent to a database. A Jetson Nano is used for system portability. Additionally, a web application has been developed that provides real-time monitoring of the driver's location, along with offering an administration system that allows users to access and visualize information from incident reports, as well as specific details for each driver.\\


\emph{\textbf{Keywords:} Drowsiness, Artificial Vision, Geolocation, Alert, Web Application, Management System.} 

\newpage
\section{Capítulo I: Introducción}

De acuerdo con el Informe sobre la situación mundial de la seguridad vial 2018, publicado por la Organización Mundial de la Salud (OMS), se registraron alrededor de 1,35 millones de muertes anuales debido a accidentes de tránsito. Estas cifras alarmantes no solo afectan a los conductores y pasajeros, sino también a los peatones, ciclistas y motociclistas, especialmente en países en desarrollo \cite{WHO}. 
\\ 
Para abordar esta problemática, se busca prevenir la somnolencia al conducir, la cual es reconocida como un factor contribuyente a los accidentes viales. En México, por ejemplo, se estima que anualmente fallecen en promedio 16,500 personas debido a estos percances. Además, los accidentes viales representan un costo significativo para el país, estimado en alrededor de 150 mil millones de pesos, equivalente al 1.7\% del Producto Interno Bruto (PIB), considerando costos directos e indirectos \cite{IMT}.
\\ 
En el desarrollo logístico de empresas que se encargan de transportar a pasajeros o que se encargan de repartir paquetería, los datos pueden verse de forma más alarmante o preocupante, ya que, usualmente, las personas designadas como conductores se enfrentan a largas horas de jornada sin descanso y, en muchos casos, rotan por horarios que pueden ser en el día o en la noche, aumentando el riesgo de accidentarse por el desbalance de tener un horario mixto.
\\ 
Muchas de estas empresas optan por sistemas de rastreo de vehículos, que hoy en día son un recurso determinante para la planificación de rutas de distribución al optimizarlas y, lo más importante, al estar en constante monitoreo se puede tener la certeza de que se está siguiendo la ruta marcada correctamente \cite{RastreoSatelital}.
\\ 

Teniendo en cuenta este contexto, resulta relevante analizar y diseñar un sistema que aborde la problemática de la somnolencia al conducir. Este sistema se basará en el uso de una cámara digital y algoritmos de visión artificial para detectar signos de somnolencia en el conductor. Además, se incluirá un sistema de administración que permitirá la geolocalización en tiempo real, así como la gestión de conductores y reportes de incidencias.
\\ 

El desarrollo de este sistema busca aprovechar los avances tecnológicos recientes en el campo de la visión artificial y el aprendizaje automático, así como la disponibilidad de microordenadores eficientes y las mejoras en las tecnologías de telecomunicaciones, como el 4G y el Internet de las Cosas (IoT). Estas tecnologías permitirán detectar y alertar los síntomas de somnolencia en los conductores, brindando una solución más asequible en comparación con las opciones tradicionales de rastreo satelital. \\

En resumen, el objetivo principal del presente trabajo es desarrollar un sistema portátil que pueda detectar la somnolencia al conducir, alertar al conductor y monitorear la ubicación en tiempo real, además de gestionar las incidencias detectadas. \\
  

\newpage
\subsection{Planteamiento del problema} \label{planteamientodelproblema}

La somnolencia es un fenómeno complejo de analizar debido a los factores que pueden intervenir. Algunas de las características más notorias de un estado de somnolencia se pueden apreciar principalmente en el rostro de las personas: frecuencia de parpadeo, bostezos, movimientos faciales y cabeceos, los cuales son parámetros clave para determinar si una persona está en estado de somnolencia o vigilia.\\

Gracias a los avances tecnológicos en los últimos años, se han desarrollado técnicas de visión artificial y aprendizaje automático que permiten detectar patrones de manera más eficiente. En el área del hardware, se han desarrollado microordenadores capaces de realizar tareas que requieran un nivel moderado de computación de manera eficaz. Finalmente, en el área de telecomunicaciones, tecnologías como el 4G y avances en el \emph{Internet of Things} han permitido mayores velocidades de transmisión de datos, así como mayor cobertura dentro del territorio nacional \cite{iot}. \\ 

Hoy en día, se están comenzando a utilizar tecnologías para prevenir y detectar síntomas de fatiga y somnolencia en conductores.

Uno de estos métodos está basado en el comportamiento del vehículo, el cual detecta el estado del conductor mediante el análisis de distintas métricas como son: movimientos del volante, posición del vehículo, la presión del acelerador o del freno, cambio de velocidades, con los cuales se determina la posibilidad de que el conductor se encuentre en estado de somnolencia. El principal problema de dicho método es que las características individuales del vehículo, del conductor y de la carretera repercuten en la eficacia del sistema. \\

Por otra parte, se encuentran los métodos que se basan en el análisis de variables fisiológicas, los cuales permiten la detección de somnolencia en sus fases tempranas con una baja tasa de falsos positivos. Se destacan los métodos basados en: electroencefalograma (EEG), electromiograma (EMG), electrocardiograma (ECG) y electrooculograma (EOG). Entre todos los métodos, el EEG es el más común para la detección de la somnolencia, donde se analizan diferentes bandas de frecuencia. Todas estas señales brindan información adicional al momento de analizar el estado de somnolencia de una persona. Sin embargo, estos métodos requieren contacto con el conductor y el uso excesivo de canales de encefalogramas, lo cual resta comodidad, maniobrabilidad y practicidad al conductor, además de poder llegar a ser invasivos, lo cual puede entorpecer el desempeño del conductor. 
\\

Finalmente, se encuentra el análisis de características visuales que puede presentar un conductor somnoliento, como los movimientos faciales, parpadeos rápidos y constantes, cabeceos y bostezos frecuentes. Sin embargo, los bostezos se presentan generalmente antes de que el conductor entre en somnolencia, mientras que los cabeceos normalmente ocurren cuando el conductor se duerme. Por lo que estos métodos no son capaces de detectar con exactitud cuando un conductor está empezando a entrar en un estado de somnolencia. Se debe tomar en cuenta las diferencias temporales entre los distintos signos visuales, por lo que realizar la combinación de varias de estas características aumentará la robustez final del sistema, logrando una mejor eficiencia. \cite{Sisdesomnolencia}.
\\

Actualmente existen distintas opciones para la geolocalización de vehículos en tiempo real, pero con costos elevados, como lo es el rastreo satelital, el cual requiere un pago por servicio con una suscripción anual o mensual. Entonces, surge una oportunidad para desarrollar soluciones más asequibles y que sean igualmente eficaces, como es el caso de las redes móviles LTE \cite{GeolocalizacionVehiculos}.
\\
Dadas las posibles soluciones antes mencionadas, se plantea la siguiente pregunta: ¿Cómo desarrollar un sistema portátil que pueda detectar la somnolencia, alertar al conductor, además de monitorear la ubicación en tiempo real y gestionar las incidencias detectadas en el conductor? 


\subsection{Propuesta de solución} \label{solucion}

Como respuesta a la problemática planteada en la sección \ref{planteamientodelproblema}, se propone el desarrollo de un sistema portátil que sea capaz de detectar somnolencia en conductores y a su vez activar una alarma que permita alertar al conductor. Como parte del sistema, un subsistema permitirá la administración y validación de las incidencias reportadas, así como el monitoreo GPS del conductor en tiempo real dentro de la Ciudad de México.
\\

Los problemas que resolverá el sistema se listan a continuación: \\

\begin{itemize}
\item El sistema será portátil, por lo que se hará uso de un microordenador para poder ser instalado y que funcione dentro de un vehículo.
\item Mediante una cámara digital conectada al microordenador, el sistema analizará el rostro del conductor en tiempo real, tomando en cuenta como parámetros de análisis los ojos y la boca del conductor.
\item El sistema hará uso de técnicas de visión artificial para poder detectar si el conductor presenta signos de somnolencia.
\item En caso de presentarse un caso de somnolencia, el sistema activará una alarma para alertar al conductor.
\item Al mismo tiempo, el sistema realizará y almacenará un reporte de incidencia que contendrá datos como fecha, hora, ubicación geográfica y un pequeño videoclip que muestre el momento en que el conductor presentó signos de somnolencia.
\item Posteriormente, el sistema hará uso de redes de telecomunicaciones móviles para enviar el reporte de incidencia previamente generado hacia una estación base que funcionará mediante una aplicación web, donde un administrador podrá verificar este reporte con el fin de confirmar que se trata de un caso de somnolencia y no un falso positivo.
\item A su vez, el administrador podrá consultar la ubicación en tiempo real del conductor desde la misma estación base.
\item En la Figura 1 se muestra la propuesta del diagrama general de diseño de la arquitectura del sistema.
\end{itemize}


\begin{center}
  \includegraphics[scale=0.9]{imagenes/diagramageneral2}
\captionof{figure}{Diagrama general del diseño de la arquitectura del sistema.}
 \label{fig:Arquitecturapreliminar} 
\end{center} 


\subsection{Alcances}

A continuación, se describen los alcances de la propuesta de solución:

\begin{itemize}
\item Detectar posibles síntomas de somnolencia del conductor.
\item Alertar al conductor mediante una alarma en caso de que se detecten síntomas de somnolencia.
\item El sistema realizará un reporte de incidencia al detectar somnolencia.
\item Solicitar el posicionamiento mediante una tecnología de geolocalización en tiempo real.
\item La transmisión de los datos del módulo de procesamiento se realizará mediante una red inalámbrica.
\item Se marcará la posición GPS en el mapa del conductor y se visualizará en la aplicación web.
\item Las pruebas a realizar se llevarán a cabo en la Ciudad de México, que cuenta con cobertura de redes móviles.
\item La aplicación web permitirá consultar las incidencias de cada conductor registrado y la ubicación del conductor en tiempo real.
\end{itemize}

\clearpage
\subsection{Escenario de pruebas}

Las pruebas se dividirán en dos fases:\\
 
\textbf{Fase 1:}

En la primera fase se probará el sistema de somnolencia y el sistema de comunicaciones de manera separada, con el propósito de analizar los resultados obtenidos. El sistema de detección de somnolencia será colocado dentro del vehículo, sin embargo, dicho vehículo permanecerá estacionado y con el motor apago, esto con el fin de realizar pruebas de la precisión del sistema y poder ajustar parámetros en caso de ser necesario.\\   

Estado de los ojos:  

-bostezos por minuto 
-arpadeos por minuto 
-ojos cerrados 
-duracion de los ojos 

De acuerdo a los objetivos especificos se evaluara. 

\begin{itemize}
\item El sistema de visión artificial sea capaz de detectar somnolencia.
\item alertar al conductor en caso de detectar incidencia 
\item Evaluar incidencia 

\item  interconexión entre el sistema de visión artificial y el sistema de administración. 

\item Visualización en tiempo real de la ubicación GPS del conductos usando redes de telecomunicaciones móviles.
\item Funcionalidad del sistema de administración para la gestión de usuarios, almacenamiento de datos y consultas de las incidencias de cada conductor. 

\end{itemize}



\begin{itemize}
\item Abiertos, cerrados. 
\item Duración de estos estados. 
\end{itemize}

Bostezos: 

\begin{itemize}
\item Apertura de la boca. 
\end{itemize}

Estas pruebas se realizarán durante el día con diferentes conductores para comprobar la detección de somnolencia. Asimismo, se verificará que la alarma se active correctamente al detectar somnolencia en el conductor.
\\
Para el sistema de administración, se probará la aplicación web que incluye el acceso al sistema, la geolocalización del conductor en tiempo real y la visualización de las incidencias.
\\
 
\textbf{Fase 2:}

En la segunda fase, se probará el sistema completo con el vehículo en movimiento, donde el sistema estará monitoreando el estado de somnolencia del conductor durante el trayecto. 
\\
Para el sistema de administración, se corroborará que, en los casos en que el sistema de somnolencia detecte una incidencia, esta será enviada correctamente y podrá ser visualizada desde el sistema de administración. A su vez, se constatará que la información de la ubicación geográfica del sujeto de prueba esté disponible en tiempo real.a información de la ubicación geográfica del sujeto de prueba esté disponible en tiempo real.  

\subsection{Justificación}

Actualmente, se han desarrollado diferentes avances tecnológicos tales como el internet de las cosas (IoT) el cual permite la comunicación con dispositivos y da pauta al desarrollo de sistemas inteligentes que resuelven problemas complejos de manera automática y eficaz en ambientes específicos, la inteligencia artificial, el machine learning, el procesamiento masivo de datos en menor tiempo, entre muchos otros. 
\\\\
El sistema propuesto será capaz de detectar la somnolencia apoyado en el análisis de los aspectos fisiológicos del rostro, donde se delimitan los datos biométricos del estado de somnolencia mediante el uso de visión artificial. Estos datos serán posteriormente enviados a una estación base con ayuda de redes inalámbricas. 
\\
Al haber accidentes de tránsito por somnolencia en México, este proyecto tiene como objetivo implementar un sistema de detección de somnolencia mediante visión artificial y el uso de una alarma auditiva para que el conductor se mantenga alerta. Además, se busca integrar un sistema que permita el monitoreo del vehículo mediante la geolocalización del mismo y un sistema interactivo con el usuario. Este sistema permitirá visualizar las incidencias que puedan presentarse por parte de los conductores, con el fin de obtener registros que nos permitan realizar estadísticas y recabar información relevante para retroalimentar el rendimiento de cada conductor.
\\ 

Ofreciendo así un sistema portátil de monitoreo, detección de somnolencia y alerta, que incluye una aplicación web con registros detallados de incidencias y estadísticas para evaluar la eficiencia de los conductores.


\subsection{Metodología}

\textbf{Espiral} 

El artículo de Barry Boehm \cite{Metodologia}, publicado en 1986, introduce la Metodología Espiral como un enfoque para el desarrollo de software que combina elementos de modelos de desarrollo en cascada y prototipos. La metodología espiral se destaca por su enfoque flexible y adaptativo, permitiendo ajustes a lo largo del ciclo de desarrollo.
\\
La Metodología Espiral se basa en la premisa de que el desarrollo de software es un proceso iterativo y evolutivo. Se propone un modelo en espiral dividido en cuatro cuadrantes: determinación de objetivos, evaluación de riesgos, desarrollo y planificación. Cada iteración aborda estos cuadrantes de manera secuencial. 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/spiral-model.png}
\captionof{figure}{Modelo en espiral \cite{Espiral}.}
 \label{fig:JetsonNano} 
\end{center} 

\begin{itemize}
\item En la fase de \textbf{determinación de objetivos}, se establecen metas específicas para la iteración.
\item La \textbf{evaluación de riesgos} implica identificar y gestionar proactivamente los riesgos asociados con los objetivos establecidos.
\item   La fase de \textbf{desarrollo} implica la implementación de funcionalidades, utilizando enfoques como prototipos y desarrollo incremental.
\item  La \textbf{planificación} implica revisar el progreso, ajustar planes según sea necesario y prepararse para la próxima iteración.
\end{itemize}
  
El sistema se dividió en módulos, lo que permitió analizarlo por partes. Para cada módulo, se determinaron los objetivos o requisitos que debía cumplir, así como la delimitación, la implementación y la evaluación de los resultados obtenidos.

\subsection{Objetivos}

\subsubsection{Objetivo General}

Diseñar un sistema portátil para la detección de síntomas de somnolencia y alerta del conductor. Además de ser capaz de obtener la ubicación del conductor en tiempo real para ser monitoreada desde una aplicación web que a su vez permita gestionar y visualizar los reportes de incidencias del mismo. 

\subsubsection{Objetivos Específicos}

\begin{itemize}
\item Diseñar un sistema de visión artificial que sea capaz de detectar y alertar la somnolencia en conductores.
\item Integrar herramienttas de geolocalización en tiempo real usando redes de telecomunicaciones móviles.
\item Diseñar un sistema de administración para la gestión de usuarios, almacenamiento de datos y consultas de las incidencias de cada conductor. 
\item Integrar un sistema de comunicaciones que permita la interconexión entre el sistema de visión artificial y el sistema de administración. 
\end{itemize}


\newpage
\section{Capítulo II: Marco de Referencia}

\subsection{Marco Teórico}

\subsubsection{Somnolencia}

La somnolencia es la necesidad o tendencia que tiene una persona a quedarse dormido. La intensidad de somnolencia está determinada por la calidad de sueño, la cantidad, y el ritmo circadiano de la persona    \cite{Intensidad}. 
\\

Se han propuesto tres clases de métodos para poder medir el grado de somnolencia en una persona:

\begin{itemize}
\item \textbf{Mediciones del comportamiento} 

Se basan en la observación del comportamiento del individuo. Entre estos se encuentran: el bostezo, la actividad ocular, expresiones faciales y pestañeo.

\item \textbf{Test de funcionamiento}

Se usan para medir los efectos de somnolencia en diferentes aspectos del funcionamiento, como por ejemplo: las variaciones en el tiempo de reacción, vigilancia psicomotora y simuladores de manejo.

\item \textbf{Test Neurofisiológicos}

Son diseñados bajo la premisa de cuantificar la somnolencia de manera objetiva. 


\end{itemize}

\subsubsection{Jetson Nano}

Jetson Nano es una computadora pequeña y poderosa que permite ejecutar múltiples redes neuronales en paralelo para aplicaciones como clasificación de imágenes, detección de objetos, segmentación y procesamiento de voz. En una plataforma fácil de usar que funciona con 5 vatios \cite{JetsonNano}. 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/JetsonNano}
\captionof{figure}{Kit para Desarrolladores Jetson Nano \cite{JetsonNano}. }
 \label{fig:JetsonNano} 
\end{center} 


\subsubsection{Visión Artificial}

La visión artificial es un campo de la IA que permite que las computadoras y los sistemas obtengan información significativa de imágenes digitales, videos y otras entradas visuales, y tomen acciones o hagan recomendaciones basadas en esa información. La visión artificial necesita de muchos datos. Ejecuta análisis de datos una y otra vez hasta identificar diferencias y, finalmente, reconocer imágenes \cite{IBMvision}.

La visión artificial es una tecnología que utilizan las máquinas para reconocer automáticamente las imágenes y describirlas de manera precisa y eficiente.Las aplicaciones de visión artificial utilizan inteligencia artificial y el machine learning (IA/ML) para procesar estos datos con precisión para la identificación de objetos y el reconocimiento facial, así como para la clasificación, la recomendación, el monitoreo y la detección \cite{IAaws}

%\subsubsection{Red Neuronal}

%Una red neuronal es un sistema que pretende emular ciertas características propias de los seres humanos, tales como la capacidad de memorizar o y asociar hechos o características. Este sistema está se basa en el concepto de \emph{neurona}.

%\begin{center}
%  \includegraphics[scale=0.5]{imagenes/neurona}
%\captionof{figure}{Módelo estándar de una neurona artificial}
% \label{fig:neurona}
%\end{center}

%Un módelo simplificado de una neurona artificial consta de dos etapas.
%En la primera etapa, las entradas provenientes de otras neuronas son combinadas tomando en cuenta los pesos de las sinapsis. Como resultado de esta etapa surge la entrada neta o \emph{excitación} de la neurona. En la segunda etapa, la entrada neta se utiliza para determinar el valor de salida de la neurona, que posteriormente será propagada a otras neuronas.

%En la etapa de integración de las entradas, una neurona combina las distintas entradas $ x_i$ con sus pesos para así determinar su entrada neta $z_j$: 

%\begin{equation}
%zj = \sum_{i}w_{ij}x_i
%\end{equation}

%Dónde $w_{ij}$ representan los pesos sinápticos asociadas desde la \emph{i}-ésima neurona hasta la \emph{j}-ésima. Estos pesos tendrán valores real. Positivos para modelar conexiones excitatorias y negativos para conexiones inhibitorias.

%Por otra parte, en la etapa de activación de una neurona, esta utiliza el valor asociado a su entrada neta para generar una salida $y_j$:

%\begin{equation}
%y_j(t)= F(y_j(t-1), z_j(t)) = F(y_j(t-1),net_j(t))
%\end{equation}

%\subsubsection{Redes Neuronales Convolucionales}

%Las redes neuronales convolucionales, tambien conocidas como \emph{redes convolutivas}, son redes neuronales artificiales que se utilizan comunmente para resolver problemas que requieren el procesamiento de imágenes. Sus casos de uso más frecuentes van desde la detección de objetos, hasta generar una descripción textual del contenido de una imagen. Particularmente, sus entradas y salidas pueden ser estructuradas. Esto quiere decir, que en lugar de recibir un vector de entradas, se puede recibir un vector (1D), matriz (2D) o tensor($>2D$). En el caso de señales bidimensionales, las entradas pueden pertenecer a los pixeles de una imágen capturada por una cámara \cite{Referencia0}.

%Como su nombre lo indica, esta red neuronal utiliza la operación de convolución. La convolución es una operación matemática que se realiza sobre dos funciones para producir una tercera que se suele interpretar versión modificada (filtrada) de las funciones originales \cite{Referencia0}.
%\\

%La convolución entre las funciones \emph{f} y {g} se representa de la siguiente manera:
%\begin{equation}
%(f\star g)(t) = \int_{-\infty}^{\infty} f(\tau )g(t-\tau )d\tau = \int_{-\infty}^{\infty} f(t-\tau)g(\tau)d\tau
%\end{equation}


%En el caso particular de procesamiento digital de imágenes, las variables $[n_1,n_2]$ corresponden a %cordenadas $[x,y]$ de los píxeles de una imagen. Además, el signo menos que aparece en la Ecuación 8, %se suele sustituir por un signo más, por lo cual la definición de convolución se expresaría como:

%\begin{equation}
%(x\star h)[x,y] = \sum_{k_1=0}^{K_1-1}\sum_{k_2=0}^{K_2-1} h[k_1,k_2] x[x+k_1,y +k_2]
%\end{equation}


%\emph{Capas convolutivas}\\
%El componente clave de las redes neuronales convolucionales son las capas, que sustituyen la tradicional multiplicación de pesos por entradas. La entrada de una capa convolutiva es una señal,en el caso de imágenes, una señal bidimensional. Dicha señal es procesada realizando una convolución con una máscara o \emph{kernel}. Los pesos correspondientes al \emph{kernel} serán los parámetros de la capa convolutiva que será entrenada.
%A continuación se presenta la representación más simple de las capas de una red neuronal convolucional.

%\begin{center}
%  \includegraphics[scale=0.45]{imagenes/cnn2} 
%\captionof{figure}{Arquitectura general de una Red Neuronal Convolucional \cite{CNNpresentacion}.}
% \label{fig:boost}
%\end{center}

%\begin{itemize}
%	\item Capa Convolucional
	
%Esta capa se utiliza para extraer las diversas características de las imágenes de entrada. En esta capa se realiza la convolución entre la imagen de entrada y un \emph{kernel} de un tamaño particular $MxM$.

%La salida se denomina mapa de características, que nos brinda información sobre la imagen, como las esquinas y los bordes. Posteiormente, este mapa de características se alimenta a otras capas para aprender otras características de la imagen de entrada.

%La capa de convolución en CNN entrega el resultado a la siguiente capa una vez que se aplica la  en la entrada.

%\item Capa de \emph{Pooling}

%El objetivo principal de esta capa es disminuir el tamaño del mapa de características convolucionado para reducir los costos computacionales. Esto se realiza disminuyendo las conexiones entre capas y opera de forma independiente en cada mapa de características. Según el método utilizado, existen varios tipos de operaciones de agrupación. Básicamente resume las características generadas por una capa de convolución. El tipo de pooling más utilizado es el \emph{max-pooling}. Este devuelve el valor máximo del fragmento de la imágen filtrada por el kernel.

%\begin{center}
%  \includegraphics[scale=1]{imagenes/maxpool} 
%\captionof{figure}{Ejemplo de Max Pooling}
% \label{fig:boost}
%\end{center}

%\item \emph{Fully Connected Layer}

%La capa totalmente conectada  consta de los pesos y sesgos junto con las neuronas y se utiliza para conectar las neuronas entre dos capas diferentes.La imagen de entrada de las capas anteriores se aplana y se alimenta esta capa. Luego, el vector aplanado pasa por unas pocas capas  más donde normalmente tienen lugar las operaciones de las funciones matemáticas. En esta etapa comienza el proceso de clasificación.

%\item \emph{Output Layer}

%Esta capa se encarga de mejorar el rendimiento de un modelo de aprendizaje automático, ya que evita el sobreajuste al simplificar la red. Descarta neuronas no escenciales de la red neuronal durante el entrenamiento.

%\item \emph{Funciones de activación}

%Son funciones matemáticas que determinan la salida de una capa de la red neuronal, y se utilizan en capas convolucionales así cómo en las capas completamente conectadas. Estas funciones se utilizan para asignar los valores de las salidas de cada capa entre valores definidos, para así facilitar que el modelo se adapte a una gran variedad de datos. 

%\item \emph{Flattening}

%Flattening consiste en convertir los datos de salida de la capa convolucional a una matriz unidimensional para ser llevada a la capa siguiente.


%\end{itemize}
%\subsubsection{Cascadas Haar}
%Existen técnicas de visión artificial que permiten el reconocimiento de objetos en una imágen o cuadros en un video. Entre los que más destacan, se encuentran las Cascadas Haar. Esta técnica fue presentada por primera vez por Viola y Jones. Las Cascadas Haar implica entrenar una serie de clasificadores simples  y luego combinar su salida \cite{viola}.\\

%Posteiormente estas salidas de transforman en un \emph{clasificador h(x)} como una suma de valores de \emph{aprendices débiles}:



%\begin{equation}
%h(x) = sgn \left [  \sum_{j=0}^{m-1} \alpha_{j}h_j(\bold{x}) \right ]
%\end{equation}


%los aprendices débiles $h_j(\bold{x})$ son funciones extremadamente simples de la entrada.
%En la mayoría de las variantes de Cascadas Haar, los aprendices débiles son funciones umbrales,
%que también son conocidos como \emph{desicion stumps} consideradas como la forma más simple de un árbol de decisiones.

%\begin{center}
%  \includegraphics[scale=0.5]{imagenes/clasificadores}
%\captionof{figure}{Boosting}
% \label{fig:boost}
%\end{center}

%Después de que cada clasificador débil es seleccionado, los \emph{data points} que han sido clasificados de manera incorrecta aumentan su peso. El clasificador final es una combinacion lineal de los clasificadores débiles \cite{viola}.


\subsubsection{\emph{Content Delivery Network}}

Una Red de Distribución de Contenido, o CDN por sus siglas en inglés. Es una red de servidores interconectados que acelera la carga de las páginas web para las aplicaciones que tienen un uso intensivo de datos. CDN puede significar red de entrega de contenido o red de distribución de contenido. Cuando un usuario visita un sitio web, los datos del servidor de ese sitio tienen que viajar a través de Internet para llegar a la computadora del usuario. Si el usuario se encuentra lejos de ese servidor, un archivo de gran tamaño, como un video o una imagen del sitio web, se demorará mucho en cargar. En su lugar, el contenido del sitio web se almacena en servidores de CDN ubicados geográficamente más cerca de los usuarios, por lo que el contenido llega a sus computadoras mucho más rápido \cite{CDN}. 

\begin{center}
  \includegraphics[scale=0.5]{imagenes/cdn-diagram} 
\captionof{figure}{Arquitectura de una CDN \cite{CDNimg}.}
 \label{fig:boost}
\end{center}

Además de esto, una CDN es capaz de detectar cambios en la información existente, así como detectar la disponibilidad de nuevo contenido en los servidores de origen.

\subsubsection{\emph{Cloud Computing}}
El Cloud Computing, o computación en la nube, se refiere a la entrega de servicios informáticos a través de Internet, permitiendo el acceso bajo demanda a recursos compartidos como almacenamiento, servidores, bases de datos, redes y software. En lugar de tener que mantener y administrar infraestructuras locales, los usuarios pueden utilizar recursos en la nube de forma flexible y escalable, pagando solo por lo que utilizan \cite{IBMCC}.

\subsubsection{Estándares y Protocolos de Comunicación Inalámbrica}

Para transferir datos o información de un punto a otro sin la utilización de cableado o algún medio físico, existen las redes inalámbricas que utilizan ondas de radio para conectar a los 
dispositivos permitiendo así, a los dispositivos remotos, se conecten sin 
dificultad y sin importar que estos dispositivos estén a unos metros o incluso a varios 
kilómetros de distancia. Se dividen en 4 tipos dependiendo del alcance requerido y se definen por el estándar 802.11 del IEEE que es el organismo de estandarización internacional.

\begin{itemize}

\item \textbf{Red  inalámbrica de area amplia (WWAN)}\\

Usan ondas de radio pero transmite a uno o varios puntos de acceso inalámbrico donde un usuario inalámbrico puede conectarse a la red, al disponer de un ancho de banda más elevado ofrece una mejor cobertura. \\\\
Como ejemplo de estas redes se tienen la tecnologías 4G y 5G. 
Son conocidas como redes de largo alcance con cobertura de hasta 100km, pueden dar soporte a gran parte del territorio geográfico \cite{Referencian5}. 
\end{itemize}
En esta red se incluyen:
\begin{itemize}
\item \textbf{Celulares}\\
Es conocida como la red de telefonía móvil.
\end{itemize}
\begin{itemize}
\item \textbf{LPWAN(\emph{Low Power Wide Area Network}): Red de Área Amplia de Baja Frecuencia}\\
son redes de área amplia y de baja potencia, es un 
protocolo de transporte inalámbrico de datos que hoy en día se utiliza como uno de los 
protocolos básicos para la implementación de IoT.
Existen varias implementaciones del protocolo LPWAN, tales como Sigfox,LoRaWAN, NB-IoT y LTE. Hay muchas diferencias entre cada una de ellas en 
cuanto a los esquemas de modulación, el alcance geográfico, la cantidad de información
transmitida y a sus capacidades de encriptación y autenticación\cite{Referencian6}.
\end{itemize}


\subsubsection{LTE}

LTE (Long-Term Evolution) es un estándar inalámbrico de cuarta generación (4G) que proporciona mayor capacidad de red y velocidad para teléfonos móviles y otros dispositivos celulares en comparación con la tecnología de tercera generación (3G). Las capas superiores de LTE se basan en el Protocolo de control de transmisión/Protocolo de Internet, lo que da como resultado una red basada exclusivamente en el Protocolo de Internet, como la de las comunicaciones por cable. LTE admite transmisiones de datos como tráfico mixto de datos, voz, vídeo y mensajería \cite{LTE}.
\\\\
LTE ofrece a los usuarios varias funciones, incluidas las siguientes:

\begin{itemize}

\item \textbf{Transmisión de audio y vídeo.} LTE tiene velocidades de descarga y carga más rápidas que 2G y 3G.

\item \textbf{Conexión a servicios en tiempo real.} Con voz sobre LTE, los usuarios pueden hablar con otras personas sin experimentar retrasos ni fluctuaciones.

\item \textbf{Velocidades aún más rápidas con LTE-Advanced.} Las velocidades de descarga y carga con LTE-Advanced son dos o tres veces más rápidas que las de LTE estándar. Todos los dispositivos LTE Advanced son compatibles con versiones anteriores del estándar LTE.

\item \textbf{Agregación de operadores.} Esta función LTE-Advanced mejoró la capacidad de la red, agregando ancho de banda de hasta 100 MHz en cinco operadores (bandas) componentes con un ancho de banda de 20 MHz cada uno. Los teléfonos LTE-A combinan frecuencias de múltiples operadores de componentes para mejorar la señal, la velocidad y la confiabilidad.

\end{itemize}



\clearpage
\subsubsection{Teorema de Shannon-Hartley}

Un sistema óptimo es el que cuenta con la capacidad de minimizar la probabilidad de error de bit a la salida del sistema, esto depende de las restricciones de la energía transmitida y del ancho de banda del canal.

El teorema de Shannon-Hartley establece la máxima cantidad de información que puede ser transmitida sin error con un ancho de banda específico y que está expuesto a la interferencia de ruido. La ecuación para la capacidad de canal es:

\begin{equation}C= B\cdot log (1+\frac{S}{N}) 
\end{equation}

Donde C es la capacidad de canal, es decir, la velocidad máxima a 
la que se puede transmitir la información a lo largo del canal sin error, medida en bits por 
segundo, B es el ancho de banda en hertz, S es la potencia de la señal útil en watts y N es la potencia de ruido presente en el canal expresada en watts. Al término S/N se le conoce como relación señal a ruido \cite{shannon}.

\subsubsection{Geolocalización}
La Geolocalización consiste en la identificación de la posición de un dispositivo móvil en 
el espacio real. El Sistema de Posicionamiento Global GPS por sus siglas en inglés es la forma más común y precisa en que se realiza la localización geográfica, y es capaz de ubicar el aparato con 
una precisión de unos pocos metros.
\\\\
El GPS es una red satelital que cuenta con al menos 30 satélites y que se mantienen en órbita alrededor de la tierra. Si bien el sistema en sus inicios tenía un propósito militar, en la actualidad cualquier persona puede ocuparlo.
Cuando se solicita el posicionamiento por medio del GPS este envía señales de radio que permiten localizar a los satélites, el centro de comando transmite la información de la órbita, el tiempo y la posición de los otros satélites en el mismo sistema GPS. Estos satélites envían simultáneamente la información de tiempo y órbita a la tierra y finaliza cuando el dispositivo GPS utiliza la información recibida para determinar su localización la cual se interpreta mayormente en dos conjuntos: la latitud y longitud \cite{Geolocalizacion}.


\newpage
\subsection{Estado del Arte} 

\subsubsection{\emph{Driver Drowsiness Detection Using Machine Learning with Visual Behaviour}}
Este trabajo de investigación propone un sistema de detección de signos de somnolencia en conductores utilizando un modelo de Red Neuronal Convolucional para detectar la posición de los ojos, y OpenCV junto con Dlib para la detección de la boca y realizar el conteo del número de bostezos por minuto. Para alimetnar a la red Neuronal, se utilizaron el conjunto de datos de NTHU-DDD. También fue utilizado el método PERCLOS para obtener el número de parpadeos del sujeto de estudio. Este trabajo concluye que las mayores dificultades a la hora de detección de rostros fueron el uso de gafas oscuras, así como cambios en la iluminación \cite{EstadodelAarte1}.

\subsubsection{\emph{Detection Of Drowsiness And Distraction Of Drivers Using CNN}}

En este trabajo se implementó el aprendizaje automático y el paquete Keras para construir un modelo de CNN, el cual, clasifica si el conductor se encuentra somnoliento o distraído,el sistema emite un tono de alerta al detectar correctamente la somnolencia, dando al conductor una alerta temprana. Se utilizó el clasificador Open CV Haar-Cascade,un clasificador en cascada basado en características, usando sus funciones integradas, se detetó el rostro y la región de los ojos \cite{EstadodelAarte2}.


% https://www.trendytechjournals.com/files/issues/volume4/issue7-5.pdf

\subsubsection{\emph{Driver Drowsiness Detection System Using Convolutional Neural Networks}}
En este trabajo realizado en la Universidad Anurag se presenta una forma de analizar y anticipar la somnolencia del conductor mediante la aplicación de una red neuronal convolucional sobre la cara del conductor de un marco de secuencia. Se uso un conjunto de datos para dar forma y aprobar el modelo, usando redes convolucionales 3D basadas en modelos de múltiples capas de arquitectura de red neuronal repetitiva para detectar la somnolencia del conductor. Tras una sesión de entrenamiento, se obtuvo una precisión que se acerca al 92\% de aceptación \cite{EstadodelAarte3}.


\subsubsection{\emph{Rasperry Pi based System for Visual Object Detection and Tracking}}
Este trabajo aborda la implementación de un sistema capaz de realizar el seguimiento de varios objetos mediante una cámara digital conectada a una Rasperry Pi. El motor de este sistema fue desarrollado utilizando C++ y se ejecuta sobre un sistema operativo basado en GNU/Linux.
Este sistema también logra transmitir las coordenadas y el tamaño de los objetos detectados a otras computadores dentro de una red de local de Internet \cite{EstadodelAarte4}.

%https://a-lab.ee/edu/sites/default/files/Ivask_BSc.pdf

% https://ijarsct.co.in/Paper3399.pdf

\subsubsection{Diseño e implementación de sistema de visión artificial para alerta y detección de somnolencia mediante aprendizaje profundo aplicable en conductores de vehículos}
En este trabajo realizado en la facultad de Ingeniería de la Universidad Nacional de Trujillo, se desarrolló un sistema de extracción de características faciales tales como pestañeo, cabeceo y bostezos. Para la extracción de regiones de interés se utilizaron cascadas Haar, y la clasificación de estas características se realizó utilizando un modelo de red LeNet. Además el trabajo incluye la creación de una base de datos de las regiones de interés de la cara utilizando imágenes propias y también utilizando conjunto de datos externos. Para el desarrollo de este trabajo se utilizó el lenguaje de programación Python, junto con las librerías de OpenCV, Tensorflow y Keras \cite{EstadodelAarte5}.

\subsubsection{Aplicación de visión por computador y machine learning al guiado de un robot móvil basado en Rasperry Pi}

Esta investigación realizada en la Universidad de Sevilla, detalla el desarrollo de un vehículo con guiado autónomo basado en visión artificial. Se utilizó una red neuronal convolucional para realizar el seguimiento de objetos. El sistema desarrollado consta de una integración de una computadora remota a la par de una Rasperry Pi \cite{EstadodelAarte6}.

\subsubsection{Evaluación de la plataforma Nvidia Jetson Nano para aplicaciones de visión artificial}

Este trabajo de investigación aborda distintos proyectos tales como: Estimación de pose humana en tiempo real y Reconocimiento de matrícula en tiempo real sobre una Nvidia Jetson Nano. Se realizaron pruebas de rendimiento para conocer las limitaciones de la Jetson Nano. Los resultados presentados muestra que la Jetson Nano permite trabajar tanto como imágenes como con vídeos de forma fluida, aunque con ciertas limitaciones en el uso de redes neuronales profundas. Sin embargo, al utilizar la aceleración de hardware ofrecida por Nvdia, se redujo considerablemente los tiempos de ejecución de los procesos \cite{EstadodelAarte7}.
%https://repositorio.uam.es/bitstream/handle/10486/698381/jimenez_varela_natalia_tfg.pdf?sequence=1

\subsubsection{\emph{Comparative Study of Computer Vision Based Line Followers using Rasperry Pi and Jetson Nano}}
Esta investigación realiza una comparación del rendimiento entre la Rasperry Pi y la Jetson Nano aplicado a un sistema de guía utilizando líneas rectas en el suelo. Los resultados de este trabajo muestran que ambas ofrecen un buen rendimiento. Sin embargo, la Jetson Nano demostró ser 20 segundos más rápida en cuanto al procesamiento de imágnes, y obtuvo un porcentaje del 100\% de efectividad al recorrer el trayecto trazado por el circuito de líneas. Por otro lado, la Rasperry Pi, obtuvo un porcentaje de 98\% de efectividad en cuanto al seguimiento del circuito. Por lo anterior, el estudio concluyó que la Jetson Nano ofrece un mejor rendimiento y efectividad en tareas de visión artificial \cite{EstadodelAarte8}.


\subsubsection{Sistema de detección de somnolencia mediante inteligencia artificial en conductores de vehículos para alertar la ocurrencia de accidentes de tránsito}

Este proyecto fue realizado por estudiantes de la Escuela Profesional de Ingeniería de Perú y consistió en llevar a cabo un sistema para la detección de la somnolencia y la distracción del conductor. El sistema se desarrolló utilizando C\# con EmguCV para detectar la distracción y orientación de los ojos utilizando técnicas de visión artificial. Además, cuenta con un sistema de alarma compuesto por un zumbador de 12v, que se activa a recibir la orden el microcontrolador al procesar el sistema de visión artificial junto a una red neuronal \cite{EstadodelAarte9}.

\subsubsection{Diseño de un sistema electrónico para detectar la somnolencia en automovilistas por medio de la actividad ocular}

Este trabajo realizado por alumnos de la ESIME Culhuacán en el año 2019 detalla el diseño y la implementación de un sistema que se basa en la fusión de dos señales. Una de ellas proviene de la detección del estado de los ojos utilizando información proveniente de una cámara digital. Para lo anterior, se realiza una segmentación de las regiones de la piel y posteriormente se obtiene la ubicación y el rastero de los ojos. La segunda señal se obtiene a partir de los datos proveniente de un acelerómetro colocado sobre la cabeza del conductor, cuya función es detectar los cabeceos asociados con somnolencia. El procesamiento de dicha señal del acelerómetro se lleva a cabo con la ayuda de la Transformada Wavelet Discreta. Estas dos señales son correlacionadas para tener como salida dos alarmas secuenciales que son percibidas por el conductor. La primera le alerta sobre un primer estado de posible somnolencia y la segunda acciona un control difuso para el control momentáneo del auto y la corrección del volante para el seguimiento del carril. Los resultados obtenidos por este trabajo demuestran una eficacia para la detección de ojos cerrados del 86\% y para la detección de cabeceo superior al 90\% \cite{EstadodelAarte10}.


\subsubsection{Sistema para la detección del estado de somnolencia en seres humanos, con reconocimiento de patrones }

En este artículo se muestra la implementación de un sistema de detección del estado de somnolencia en
seres humanos, a través de la identificación de patrones faciales y la frecuencia de parpadeo de los ojos. Utilizando técnicas de inteligencia artificial, visión por computadora y un sistema embebido con cámara integrada para la adquisición de imágenes.El cual permite detectar en tiempo real el estado de fatiga de un conductor automovilístico y su grado de somnolencia, todo con el objetivo de disminuir la tasa de accidentes viales causados precisamente por la somnolencia en México. Se hizo uso del lenguaje de programación Python, bibliotecas como OpenCV, Dlib y Scipy, las cuales, fueron requeridas debido a los modelos predefinidos que
establecen una mayor precisión en la detección de puntos faciales específicos, utilizando como referencia el método de predicción de 68 puntos específicos del rostro. El sistema propuesto tiene la característica de funcionar con luz de día en una primera etapa, y la idea es poder implementarlo en cualquier tipo de vehículo automotriz a un costo accesible a la mayoría de los propietarios de vehículos automotrices \cite{EstadodelAarte11}.


%https://uptexcoco.edomex.gob.mx/sites/uptexcoco.edomex.gob.mx/files/files/2020/articulos-Tesis/sistema_somnolencia.pdf

\subsubsection{Sistema de Detección de Somnolencia}
En este trabajo de fin de grado, realizado por un alumno de la Universidad de La Laguna en el año 2022 se estudió el uso de los modelos de Redes Neuronales para la clasificación de imágenes. Enfocado en la resolución del problema de la somnolencia en los conductores. En el cual se utilizó el lenguaje de programación Python, junto con diversas librerías que facilitan la integración del modelo, y otras que ayudan en la captura de las imágenes \cite{EstadodelAarte12}.

%https://riull.ull.es/xmlui/bitstream/handle/915/30312/Sistema%20de%20deteccion%20de%20somnolencia.pdf?sequence=1&isAllowed=y

\subsubsection{Desarrollar un prototipo de reconocimiento facial basado en Machine Learning para detectar estado de Somnolencia en conductores de una cooperativa de transporte} 

En este trabajo, realizado por alumnos de la Universidad de GUAYAQUIL en el año 2020-2021 se plantea el desarrollo un prototipo para la detección de la somnolencia del conductor de una cooperativa de transporte el cual dicho conductor se había sobrepasado el límite de horas de trabajo, usando la técnica de reconocimiento facial, basándose específicamente en el estado de los ojos. Para ello se realizó una investigación bibliográfica relacionada con patrones biométricos, inteligencia artificial y programación mediante Machine Learning, así como, las principales variables que permiten identificar un estado de somnolencia. Dentro de esta investigación también se determinan cuáles son los algoritmos a utilizar (CV2, Imutils, etc.) siendo la herramienta Python y su librería principal Visión por Computadora las seleccionadas para el estudio \cite{EstadodelAarte13}.


\subsubsection{Sistema basado en la detección y notificación de somnolencia en conductores de autos}
En este trabajo, realizado por alumnos de la Universidad de Córdoba en el año 2015 se plantea el desarrollo que permite alertar a los conductores en estado de somnolencia leve, utilizando la tecnología de reconocimiento de objetos de Kinect y la librería OpenCV con el lenguaje C\# para el reconocimiento de imágenes. Además, se diseña una aplicación móvil del sistema operativo Android para la notificación de somnolencia utilizando una conexión socket tipo TCP. Para el procesamiento de imágenes, se utilizó el algoritmo Viola-Jones, el cual se basa en una nueva forma de representación de imágenes llamada Integral Image, permitiendo que las características del detector se conmuten rápidamente \cite{EstadodelAarte14}.

\subsubsection{Detección de somnolencia para conducción sin accidentes}
En este trabajo de fin de grado, realizado por un alumno de la Universidad de Alicante en el año 2022 se propuso crear una aplicación real para detectar la somnolencia al volante haciendo énfasis a un bajo coste económico. Donde se realizó una comparativa entre una solución mediante Machine Learning (ML) y Principal Component Analysis (PCA) \cite{EstadodelAarte15}.

%http://hdl.handle.net/10045/124695

\subsubsection{Diseño e implementación de un sistema de geolocalización en interiores para plataforma Android vía la red enterprise WLAN de la PUCP}
En este proyecto de titulación de la Pontifica Universidad Católica Del 
Perú del 2016 se desarrolló una aplicación móvil capaz de geolocalizar a un usuario 
dentro de las instalaciones de la universidad usando la técnica de Huellas de Señal 
(fingerprinting), que minimiza el error debido a reflexiones y obstáculos, basada en 
el estimador de máxima verosimilitud (ML por sus siglas en inglés Maximum 
Likehood) junto a las mediciones de señal de los Access Points cercanos usando la 
red Wi-Fi. La tecnología de radiofrecuencia que se usó fue la de redes inalámbricas 
de área local, Wi-Fi. Que ofrece conectividad por radiofrecuencia, con alcance local a 
un dispositivo que envíe datos Ethernet desde la ubicación del mismo hasta una 
conexión a la red fija, que en este caso la universidad contaba con 32 access points 
que recibirían la señal de datos a través de cobre o fibra. La técnica del fingerprinting, 
que está dirigida a geolocalización en interiores, consiste en un mapeo de datos que 
se encuentran en un escenario para luego asociarlos a una localización y 
almacenarlos en una base de datos, para estimar la localización más probable se 
utilizó el algoritmo de ML basado en el teorema de Bayes de probabilidad. En las 
conclusiones señalan que este sistema obtuvo una precisión del 100\% en la 
estimación del ambiente con un error menor de 2.4m en las pruebas realizadas \cite{EstadodelAarte16}.


\subsubsection{Propuesta de un sistema de geolocalización y monitoreo vía GPS/GSM/GPRS aplicado a un pulsómetro para personas con enfermedades cardiovasculares}
Tesis del Instituto Politécnico Nacional de la Escuela Superior de Ingeniería Mecánica 
y Eléctrica Unidad Zacatenco del año 2018, donde se empleó un sensor de pulso 
cardiaco el cual proporciona información en tiempo real de los latidos del corazón
mientras que un microcontrolador procesa los datos y, en caso de que se obtengan 
los datos de que se está presentando una taquicardia, el microcontrolador solicita la 
ubicación al módulo GPS y envía un mensaje de texto a través de GSM/GPRS a la 
persona designada \cite{EstadodelAarte17}.

\subsubsection{Influencia de un sistema de geolocalización en el control y monitoreo de vehículos con dispositivos GPS en una empresa logística}
Tesis del año 2015 de la Universidad César Vallejo de Perú donde se investiga de manera profunda las características y detalles de la tecnología GPS para determinar la influencia de un sistema de geolocalización en el control y monitoreo de vehículos con esta tecnología en una empresa logística \cite{EstadodelAarte18}. 


\newpage
\section{Capítulo III: Análisis}

Partiendo de la propuesta de solución, se dividió el sistema en tres módulos principales: el Módulo de Comunicaciones, el Módulo Central de Procesamiento y el Módulo de la Estación Base, figura \ref{fig:modulos1}. 

\begin{center}
  \includegraphics[scale=0.55]{imagenes/topdowngeneral}
\captionof{figure}{Diagrama del sistema dividido en módulos.}
 \label{fig:modulos1}
\end{center} 

A continuación, se desglosan cada uno de los módulos: \\

\textbf{Módulo Central de Procesamiento:}\\

El módulo Central de procesamiento estará compuesto por un microordenador que será colocado dentro de un automóvil. Este microordenador será alimentado por la corriente proporcionado por dicho automóvil. Además, contará con una cámara digital que analizará el rostro del conductor después de que este encienda el automóvil. A este microordenador también le será acoplado un dispositivo que sea capaz de utilizar redes de telecomunicaciones móviles, esto para que sea posible la conexión con la Estación Base. Finalmente, también contará con una alarma para alertar al conductor si este presenta un estado de somnolencia. \\

\textbf{Módulo de Visión Artificial}\\

Este submódulo se hará cargo de analizar el rostro del conductor utilizando técnicas de visión
artificial. Se tomarán en cuenta los siguientes parámetros para determinar si el conductor presenta
o no signos de somnolencia:

\begin{itemize}
\item estado de los ojos (cerrados, abiertos).
\item estado de la boca (cerrada o abierta).
\end{itemize}  
  
Si el conductor presenta un estado de ojos cerrados por un tiempo prolongado, se considerará como
un estado de somnolencia, por lo que se activará una alarma para alertar al conductor. Así mismo se evaluará el grado de apertura de la boca para determinar si el conductor bosteza y el promedio de bostezos por minuto, si el conductor presenta más de un bostezo dentro de un minuto el sistema lo clasificará como somnolencia. A su vez el sistema tomará un breve videoclip dónde se aprecie el momento en que el conductor presentó un estado de somnolencia. \\

\textbf{Módulo de Comunicaciones}\\

Una vez que se tengan los datos recibidos por el módulo de procesamiento, este módulo se encargará de la transmisión de los datos hacia el módulo de estación base por medio de la tecnología 4G/LTE. Donde la información recibida por el módulo de procesamiento se enviará por medio de la red celular y será subida a la base de datos para después ser descargadas o consultadas por el módulo de Estación Base. La tasa de datos con la que el transceptor funcionará se especifica en la sección \ref{sec:ASD}. En caso de no contar con cobertura, quedarán almacenadas las incidencias en en la unidad externa hasta que puedan ser almacenadas una vez que esta se restablezca la comunicación. \\
 
\textbf{Módulo de Estación Base}\\

Este módulo estará compuesto por una aplicación web y una base de datos que se encargará de almacenar las incidencias de los conductores para ser corroborados por un administrador posteriormente, esto con la intención de descartar un falso positivo y realizar los ajustes necesarios al sistema. La plicación web brindará una base de datos con registros de incidencias por conductor y estadisctica semanal de incidencias que se presenten durante dicho periodo. Asi mismo se podrá consultar la posición gps del conductor. 

\subsection{Análisis y delimitación de la zona geográfica}
El sistema está dirigido principalmente para empresas cuya actividad esté enfocada al transporte de material o personas dentro de la Ciudad de México. Debido a que una parte fundamental del proyecto es la portabilidad, el sistema requiere de un servicio de acceso al internet. Por tanto, se decidió utilizar redes móviles celulares para cumplir con dicho requerimiento.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/MapaCoberturaMexico}
\captionof{figure}{Mapa de cobertura 3G/4G/5G en México.\cite{CoberturaNacional}}  
 \label{fig:mapacoberturaN}
\end{center} 

Tomando en cuenta la información del mapa de cobertura 3G/4G/5G, de redes móviles en México, mostrado en la figura \ref{fig:mapacoberturaN}, se observa que las zonas con mayor cobertura son principalmente las que cuentan con mayor densidad de población, por tanto, se plantea que su funcionamiento sea principalmente en la Ciudad de México, debido a que cuenta con mayor infraestructura en dichas redes.

\begin{center}
  \includegraphics[scale=0.7]{imagenes/CoberturaCDMX}
\captionof{figure}{Mapa de cobertura 3G/4G/5G en la Ciudad de México.\cite{CoberturaNacional}}
 \label{fig:mapacoberturaCDMX}
\end{center}

\clearpage


\subsection{Análisis del Módulo Central de Procesamiento}

\textbf{Análisis de Requerimientos Funcionales}


\begin{table}[H]
\centering
\caption{RF01- Establecer conexión con la base de datos }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Establecer conexión con la base de datos}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:} Se realizará conexión con la Base de Datos.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microodenador\\
\quad $\bullet$ Base de Datos

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Se podrá acceder a la información almacenada y registrar nuevos datos en la base de datos.
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{RF02- Activar Alarma}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Activar Alarma}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema activará el zumbador en caso de que el Submódulo de Visión Artificial detecte somnolencia en el conductor. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microodenador\\
\quad $\bullet$ Alarma

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Utilizando métodos de comprobación ofrecidos por cada uno de las libererías de los periféricos, se comprobará que funcionen de manera correcta, en caso contrario se enviará una alerta al módulo de Estación Base.
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{RF03- Enviar Video de Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Enviar Video de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  Se enviará el video de la incidencia hacia un servicio de almacenamiento en la nube.  \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Video\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El video será almacenado y se obtendrá un ID del video. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}



\begin{table}[H]
\centering
\caption{RF04- Realizar Reporte de Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF04}}                                              & \emph{Realizar Reporte de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:} Se realizará una consulta previa a la Base de Datos para obtener el nombre y apellidos del conductor de acuerdo al id del conductor. Se registrará la fecha, hora y ubicación geográfica del momento en que se detectó la somnolencia. Los datos recabados serán usados en la creación de un documento que contenga los datos de la incidencia. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Id del Conductor  \\
\quad $\bullet$ Nombre de Conductor\\
\quad $\bullet$ Apellidos de Conductor \\
\quad $\bullet$ Fecha\\
\quad $\bullet$ Hora\\
\quad $\bullet$ Ubicación\\
\quad $\bullet$ Id Video\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El documento de la incidencia contendrá los campos necesarios para registrar la incidencia en la base d datos. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{RF05- Enviar Reporte de Incidencia a la Base de Datos }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Enviar Reporte de Incidencia a la Base de Datos}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se enviará el reporte de incidencia hacia la Base de Datos. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Reporte de Incidencia  \\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Reporte de Incidencia será almacenado en la Base de Datos. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}

\clearpage

\begin{table}[H]
\centering
\caption{RF06- Eliminar Video de Incidencia  }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF06}}                                              & \emph{Eliminar Video de Incidencia }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se eliminará el video de Incidencia del almacenamiento externo después de ser almacenado en la nube.   \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Reporte de Incidencia  \\
\quad $\bullet$ URL del Video  \\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El video de la incidencia será eliminado.  
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\subsubsection{Análisis y Elección del microordenador}\label{sec:microordenador}

Como ya se mencionó en la sección \ref{solucion}, se hará uso de un microordenador para permitir que el sistema sea portátil y pueda funcionar dentro de un automóvil. Por tanto, se realizó una investigación de los modelos disponibles enfocados a proyectos de visión artificial, figura \ref{tab:microordenador}.

\begin{table}[h]
\centering
\caption{\label{tab:microordenador} Comparación de microordenadores}
\begin{tabular}{{|m{0.12\linewidth}|m{0.2\linewidth}|m{0.15\linewidth}|m{0.15\linewidth}|m{0.15\linewidth}|m{0.08\linewidth}|}}
\hline
\textbf{Nombre}& \textbf{CPU} & \textbf{RAM}  & \textbf{GPU} & \textbf{Alimentación}                                                 & \textbf{Precio} \\ \hline
Google Coral Dev Board & NXPiMX 8M SoC Dual Core 1.2 GHz & 2GB DDR3                                                &  Hexa Core A-72 2GHz & 5V DC & \$9439 \\ \hline
Rasperry Pi 4B & 1.5 GHZ 64 bit QuadCore Cortex A-72 & 1GB, 2GB, 4GB, 8GB DDR4 & No cuenta con GPU & 5V vía USB-C o puerto GPIO& \$1700\\ \hline
Asus TinkerBoard 2S & Mali-G52 MP6  con 6 núcleos & 2GB/4GB dual- channel LPDDR4 & Integrated GC7000 Lite Graphics  & 12V-19V   & \$4100  \\ \hline
NVIDIA Jetson Nano & ARM A57 2.1 GHz de cuatro núcleos & 4 GB de LPDDR4 de 64 bits & NVIDIA Maxwell de 128 núcleos CUDA & 5V/4A & \$3,699 \\ \hline
\end{tabular}
\end{table}


Los parámetros que se tomaron en cuenta para la elección de que microordenador utilizar fueron los siguientes:
\begin{itemize}
\item Precio
\item Voltaje necesario
\item RAM
\item Módulos compatibles
\end{itemize}

Si bien la Raspberry Pi es uno de los microordenadores con mayor aceptación por parte de la comunidad, esta no cuenta con una GPU, lo cual reduce significativamente su rendimiento en tareas relacionadas con IA que requieren mayor procesamiento. Por lo tanto, al buscar alternativas de microordenadores que cuenten con una GPU y basándose en el estudio \cite{EstadodelAarte8}, se concluyó que la Nvidia Jetson Nano ofrece una ventaja superior en comparación con la Raspberry Pi en cuanto a procesamiento y eficacia en tareas que involucran visión artificial. A pesar de que Asus y Google Coral Dev Board cuentan con una GPU, su potencia no supera a la ofrecida por Jetson Nano \cite{deepedgebench} y su precio es considerablemente mayor, como se puede apreciar en la tabla \ref{tab:microordenador}, por lo cual se descartaron como opciones.
Debido a lo anterior, se concluyó que la Jetson Nano representa la mejor opción para el desarrollo del presente proyecto debido a su bajo costo, bajo consumo de energía y mejor rendimiento en comparación con sus alternativas.


\subsubsection{Análisis y Elección de la alarma }\label{sec:alarma}

Dentro de la búsqueda de modelos de alarma se encontraron dos tipos de zumbadores, el zumbador activo y zumbador pasivo, donde el primero produce un tono audible fijo, al aplicar una tensión de corriente directa. Mientras que el segundo requiere de una señal oscilante, generalmente de tipo PWM, que indique la frecuencia y la duración de la señal.  \\

Para la elección de la alarma se obtuvieron dos de los principales modelos comerciales de cada tipo de zumbador mencionado: 

\textbf{Buzzer Pasivo KY-006}

\begin{itemize}
\item Voltaje: 1.5 V - 5 V 
\item Rango de frecuencia: 1.5 Hz - 2.5kHz 
\item Decibeles: 72 DB
\item Precio: \$50 
\end{itemize}

\textbf{Buzzer Activo KY-012  }

\begin{itemize}
\item Voltaje: 3.5 V - 5.5 V 
\item Rango de frecuencia: 300 Hz - 2.5kHz
\item Decibeles: 85 DB
\item Precio: \$71 
\end{itemize}

Debido a la posibilidad que ofrece el zumbador pasivo para controlar el tono y la duración del mismo, además de su bajo coste en comparación con el zumbador activo KY-012, se optó por el zumbador de tipo pasivo, específicamente el modelo KY-006, en cual se pueden configurar los tonos desde la Nvidia Jetson Nano por medio del lenguaje Python. 

\clearpage  
\subsubsection{Análisis y Elección de la unidad de almacenamiento externa}\label{sec:almacenamientoexterno}

Para utilizar una NVIDIA Jetson Nano, se requiere una tarjeta SD que contenga el sistema operativo y las aplicaciones. La tarjeta SD debe tener una capacidad de almacenamiento de al menos 8 GB. 

\begin{table}[h]
\caption{Cuadro Comparativo de módelos de MicroSD}
\begin{tabular}{{|m{0.12\linewidth}|m{0.15\linewidth}|m{0.1\linewidth}|m{0.1\linewidth}|m{0.13\linewidth}|m{0.13\linewidth}|m{0.1\linewidth}|}}
\hline
Micro SD  & Almacenamiento  & Speed class  & Video class  & Velocidad de escritura  & Velocidad de Lectura  & Precio \\ \hline
SanDisk Extreme A2 & 32-256 (MAX 1T)GB  & Clase 30/U3  & V30 & 90 MB/s  & 160 MB/s  & \$1041  \\ \hline
Kingston ENDURANCE  & 32-256 (MAX 1T)GB  & Clase 10/U1   & - & 45 MB/s  & 95 MB/s  & \$628  \\ \hline
Samsung EVO Plus  & 256 GB  & Clase 10/U3   & V30  & 130 MB/s  & 160 MB/s  &  \$592 \\ \hline
Kingston Canvas React Plus V90 Card  & 64-256 GB  & Clase 10/U3  & V90  & 90 MB/s  & 180 MB/s  & \$3596 \\ \hline

\end{tabular}
\end{table}
  
Tomando en cuenta la capacidad mínima de almacenamiento y el costo de la misma, se decidió usar una unidad de almacenamiento Samsung Evo Plus de 256 GB para la instalación del sistema operativo en la Jetson Nano. Esta elección se fundamenta en las destacadas características de la tarjeta, como su excelente velocidad de escritura, competitiva velocidad de lectura, clasificación de velocidad adecuada y una buena relación entre capacidad y precio.

\clearpage
\subsubsection{Análisis y elección de lenguajes de programación para el microordenador}

Lo que se debe de considerar para la elección de un lenguaje de programación, es que la programación orientada a la inteligencia artificial es diferente al paradigma de la programación convencional. En esta última, el usuario le indica a la máquina exactamente lo que tiene que hacer, mientras que en Machine learning, se le enseña a programarse sola. Lo cúal se ejemplifica en el siguiente gráfico:
\\
\begin{center}
  \includegraphics[scale=0.3]{imagenes/programaclasico}
\captionof{figure}{Programa clásico vs Machine Learning}
 \label{fig:pcvsml}
\end{center}


El proceso de trabajo para aprendizaje automático es muy diferente a la construcción de una aplicación convencional. Por este motivo, la manera de utilizar los lenguajes de programación es diferente. Se deben de tomar en cuenta las características que estos utilizan, así como sus enfoques y paradigmas.\\

Uno de los factores importantes a considerar al momento de elegir un lenguaje de programación orientado a machine learning, es la popularidad el mismo, ya que esta es una señal de la aceptación por parte de la comunidad. A su vez, su el soporte es tanto o mas importante, ya que podemos darnos una idea si dicho lenguaje posee las herramientas adecuadas que se acoplan a nuestras necesidades. La velocidad de ejecución es otro factor importante, sobre todo cuando se requiere una minusiocidad en la ejecución de procesos y el cuidado de la memoria .Finalmente, la versatilidad del lenguaje es otro factor relevante, ya que, si el lenguaje fue diseñado con una determinada tarea o propósito en mente, este será mucho más eficiente y productivo.\\

A continuación, se listan algunos de los lenguajes de programación más populares en el campo de Machine Learning:\\

\begin{itemize}

\item Python
Es uno de los lenguajes más populares en la comunidad de aprendizaje automático y visión artificial debido a su facilidad de uso, gran cantidad de bibliotecas y frameworks disponibles y gran comunidad de desarrolladores.

\item C++: Es un lenguaje de programación de alto rendimiento, es muy adecuado para proyectos de visión artificial que requieren de un gran rendimiento.

\item Matlab: Es un lenguaje de programación y entorno de desarrollo específicamente diseñado para matemáticas y cálculo científico, es muy utilizado en el campo de la visión artificial y procesamiento de imágenes.

\item Java: Es un lenguaje de programación multiplataforma, es muy popular en el desarrollo de aplicaciones y se utiliza en proyectos de visión artificial.

\item R: Es un lenguaje de programación especializado en estadística y análisis de datos. Es ampliamente utilizado en investigación académica, ciencia de datos y análisis estadístico en ciencias sociales, económicas, financieras y biotecnología entre otros.

\end{itemize}

A continuación se presenta una tabla comparativa de las características que se tomaron en cuenta para la elección sobre que lenguaje utilizar.

\begin{table}[h]
\centering
\caption{\label{tab:lenguajes} Tabla Comparativa Lenguajes de Programación}
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Lenguaje} & \textbf{Popularidad} & \textbf{Versatilidad} & \textbf{Velocidad} & \textbf{Soporte} \\ \hline
Python            & Alta                 & Alta                  & Moderada           & Alta             \\ \hline
C++               & Baja                 & Alta                  & Alta               & Moderado         \\ \hline
R                 & Alta                 & Moderada                  & Moderado           & Bajo             \\ \hline
Matlab            & Baja                 & Moderada              & Moderada           & Bajo             \\ \hline
Java        & Moderada             & Moderada              & Baja               & Moderado         \\ \hline
\end{tabular}

\end{table}


Debido a que en el presente proyecto se realizará la integración de sistemas enfocados a Machine Learning y a su vez a la programación orientada a objetos, Python representa la mejor opción para ser implementado, ya que este lenguaje permite desarrollar ambos ámbitos de una manera integral \cite{python}. Por lo cual será utilizado a lo largo del proyecto.


\clearpage

\subsubsection{Análisis del Submódulo Visión Artificial}


\textbf{Submódulo de Visión Artificial:}\\

El submódulo de visión artificial tiene como objetivo realizar la detección de somnolencia del conductor, analizando el rostro con algoritmos de visión artificial. 

\begin{itemize}

\item \textbf{Requerimientos Funcionales}


\begin{table}[h]
\centering
\caption{RF01- Ingresar al Campo Visual}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Ingresar al campo visual}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El conductor ingresará al campo visual de la cámara digital, posicionándose en el asiento del conductor\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Cámara Digital
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
La cámara se posicionará para capturar el rostro del conductor en video como entrada para el sistema. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{RF02- Capturar Video }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Capturar video}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema capturará video en todo momento.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Cámara Digital\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Con el uso de una cámara digital, se capturará video en tiempo real.
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}

%\begin{table}[h]
%\centering
%\caption{RF03- Preprocesar imagen}
%\begin{tabular}{|ll|}
%\hline
%\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
%\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Preprocesar imagen}                                                             \\ \hline
%\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  La imagen de entrada será preprocesada para mejorar la iluminación o eliminar el ruido de la imagen, entre otros factores. \\ \\ \textbf{Elementos:}
%\\
%\quad $\bullet$ Imagen\\

%\end{tabular}} \\ \hline
%\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
%Las imágenes serán preprocesadas para realizar la detección de características faciales.  

%\end{tabular}}                                                    \\ \hline
%\end{tabular}
%\end{table}



\begin{table}[h]
\centering
\caption{RF03- Detectar Características Faciales}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Detectar Características Faciales}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema detectará las características faciales más relevantes; rostro, ojos y boca del conductor, mediante el uso de un método de detección facial.  \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Imagen preprocesada \\
\quad $\bullet$ Método de Detección Facial
 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema obtendrá la posición del rostro y, en base a esta, las posiciones de la boca y los ojos del conductor detectados.
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{RF04- Clasificar imagen}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF04}}                                              & \emph{Clasificar imagen}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema evaluará los signos de somnolencia, como el estado de los ojos y la apertura de la boca para clasificar la imagen en base a la presencia o ausencia de somnolencia mediante técnicas de aprendizaje automático y/o aprendizaje profundo. Así mismo se escalarán y se normalizarán las imágenes que servirán como entrada para dicho proceso.  \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Técnicas de aprendizaje automático y/o aprendizaje profundo.
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema obtendrá el estado de somnolencia del conductor. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{RF05- Enviar señal de Alerta}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Enviar señal de alerta}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se enviará una señal de alerta al módulo central de procesamiento cuando se detecten signos de somnolencia en el conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microordenador\\
\quad $\bullet$ Zumbador

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El módulo Central de procesamiento activará la alarma al recibir la señal de alerta. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}

\clearpage

\begin{table}[h]
\centering
\caption{RF06- Almacenar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Almacenar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF06}}                                              & \emph{Enviar señal de alerta}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se almacenará un fragmento del video en caso de detectar somnolencia en el conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Microordenador\\
\quad $\bullet$ Memoria Externa\\
\quad $\bullet$ Video
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
Se guardará el video de incidencia en caso de no contar con conexión inalámbrica, para ser enviada posteriormente a un srvicio almacenamiento en la nube. 
\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}
\end{itemize}



\begin{center}

  \includegraphics[scale=.5]{imagenes/casosuso_vision}
\captionof{figure}{Diagrama de Casos de Uso - Submódulo de Visión Artificial}
 \label{fig:actividades}
 \end{center}
 
\textbf{Especificación de Casos de Uso}


\begin{table}[h]
\centering
\caption{Caso de Uso 01 - Ingresar al campo visual de la Cámara}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Ingresar al campo visual de la Cámara}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Conductor}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El conductor ingresesará al campo visual de la cámara al entrar al auto \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El conductor deberá encender el auto
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Automóvil
 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 02 - Capturar Video en Tiempo real}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Capturar Video en Tiempo real}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial capturara un video en tiempo real utilizando una cámara digital \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El conductor deberá encender el auto
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Automóvil\\
\quad $\bullet$ Cámara Digital

 \end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 03 - Detectar Rostro}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Detectar Rostro}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial detectará el rostro del conductor. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El conductor deberá permanecer en el campo visual de la cámara
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Automóvil\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[h]
\centering
\caption{Caso de Uso 04 - Reconocer características faciales}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Reconocer características faciales}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial reconocerá características faciales tales cómo: ojos, boca \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber detectado previamente el rostro del conductor
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 05 - Detectar Signos de Somnolencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Detectar Signos de Somnolencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial detectará signos de somnolencia utilizando métricas de tiempo para los ojos y tomará en cuenta la apertura de la boca \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber extraído previamente la información de los ojos y boca
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}
 
\begin{table}[h]
\centering
\caption{Caso de Uso 06 - Enviar Señal de Alerta}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Enviar Señal de Alerta}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial,Módulo Central de Procesamiento}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo de visión artificial enviará una alerta al Módulo Central de Procesamiento para activar la alarma  
 \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber detectado signos de somnolencia en el conductor
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Alerta

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table} 


\begin{table}[h]
\centering
\caption{Caso de Uso 07 - Identificar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Identificar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Submódulo de Visión Artificial}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El submódulo realizará un reporte de incidencia que contenga la fecha hora y lugar de la incidencia \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El sistema deberá haber extraído previamente la información de los ojos y boca
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Ojos\\
\quad $\bullet$ Cámara Digital\\
\quad $\bullet$ Boca\\
\quad $\bullet$ Rostro

 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\clearpage
\subsubsection{Análisis y Elección de herramientas de programación}

\begin{itemize}

\item  \textbf{OpenCV}

Es una biblioteca de procesamiento de imágenes de código abierto, ampliamente utilizada en la investigación académica y la industria. Permite el análisis de imágenes, la detección de objetos, el reconocimiento de patrones y la segmentación de imágenes.

\item \textbf{Numpy}

Es una librería de Python especializada en el cálculo numérico y el análisis de datos, especialmente para un gran volumen de datos. La ventaja de Numpy frente a las listas predefinidas en Python es que el procesamiento de los arrays se realiza mucho más rápido (hasta 50 veces más) que las listas, lo cual la hace ideal para el procesamiento de vectores y matrices de grandes dimensiones \cite{Numpy}.


%\item \textbf{Tensorflow}

%Es una plataforma de código abierto para el aprendizaje automático y el procesamiento de datos. Permite  definir, optimizar y ejecutar operaciones matemáticas, especialmente aquellas que involucran tensores, que son arrays multidimensionales de datos.Una de las principales ventajas de esta herramienta es su capacidad para ejecutarse en diferentes plataformas, desde dispositivos móviles hasta servidores de alta capacidad y sistemas en la nube.

%\item \textbf{Keras}

%Es una biblioteca de software de código abierto para el desarrollo de redes neuronales escrita en Python.Permite la construcción de modelos mediante la definición de capas y la conexión de estas capas para crear una red neuronal completa. También proporciona una serie de funciones de alto nivel para la configuración de optimizadores, pérdidas y métricas, lo que facilita el proceso de entrenamiento y evaluación de un modelo.
\end{itemize}
 

\subsubsection{Análisis y Elección de la cámara digital}\label{sec:camara}

Para la búsqueda de modelos de cámaras digitales, se buscaron modelos que tuvieran compatibilidad con la Nvidia Jetson Nano debido a que el sistema será alojado en este micrordenador.  

Se optó por utilizar la cámara IMX219-160, ya que cuenta con hasta 8 Megapixeles de resolución, además de tener distintos los formatos de salida jpg, RAW, DNG O MP4. También cuenta con diferentes resoluciones de video que van desde 1080p hasta 480p a 30 cuadros por segundo. 

\begin{center}
  \includegraphics[scale=0.5]{imagenes/imx}
\captionof{figure}{Modulo de Cámara IMX219-160}
 \label{fig:CameraModuleV2}
\end{center}


\clearpage 
\subsubsection{Análisis y Elección de algoritmos de visión artificial}

Existen varios métodos y blibliotecas utilizadas para detectar rostros en imágenes y videos en tiempo real, algunos de los más comunes son:

\begin{itemize}

\item \textbf{OpenCV con Haar Cascade:} Utilizar el clasificador Haar Cascade de OpenCV para la detección facial en tiempo real. Este método es rápido y puede implementarse fácilmente.

\item \textbf{Face Recognition Library:} Utiliza bibliotecas específicas para reconocimiento facial, como la biblioteca face\_recognition en Python, que utiliza el detector HOG de dlib.
 
\item \textbf{MTCNN (Multi-Task Cascaded Convolutional Networks):} Implementa MTCNN para la detección facial y la localización de puntos de referencia. Este método es eficiente y puede detectar múltiples rostros en una sola imagen.

\item \textbf{SSD (Single Shot Multibox Detector):} Emplea modelos SSD para la detección de objetos en tiempo real, incluidos los rostros. Utiliza bibliotecas como TensorFlow o PyTorch con modelos SSD preentrenados.

\item \textbf{YOLO (You Only Look Once):} Utiliza YOLO para la detección de objetos, incluidos los rostros. YOLO es conocido por su velocidad y eficiencia en tiempo real.
 

\end{itemize}

%Debido a que el presente proyecto busca conseguir un ahorro en procesamiento, se decidió a utilizar cascadas Haar para la detección de rostro, ya que estas tienen un tiempo de respuesta mayor y requieren menos procesamiento que los demás métodos mencionados.

Debido a los requerimientos el sistema, Face Recognition Library, utiliza el detector HOG de dlib, es una elección sólida para detectar el rostro, los ojos y la boca. Sus principales ventajas incluyen una detección precisa de rostros, la capacidad de localizar puntos faciales específicos, flexibilidad y facilidad de uso. 


%\begin{table}[H]
%\caption{Cuadro Comparativo - Algoritmos de Aprendizaje}
%\begin{tabular}{{|m{0.1\linewidth}|m{0.25\linewidth}|m{0.25\linewidth}|m{0.25\linewidth}|}}
%\hline
%  & \emph{Aplicaciones} & \emph{Ventajas}  & \emph{Desventajas} \\ \hline
%\emph{Neural Networks (CNNs)} & Se utiliza principalmente en las tareas de reconocimiento de imágenes y detección de objetos. Además de sistemas de recomendación y tareas de procesamiento de lenguaje.   & los resultados son más precisos, especialmente para los casos de uso de reconocimiento de imágenes/objetos, en comparación con otros algoritmos  & ara entrenarla se requiere una potencia de cálculo muy alta. Por lo tanto, no es muy rentable. \\ \hline
%\emph{Long Short-Term Memory Networks} & Ideal para tareas como autocompletado de oraciones, generación de subtítulos y análisis de cuadros de video.  & Puede manejar la información en la memoria durante un largo período de tiempo en comparación con RNN.  & Se requiere una gran cantidad de computación y recursos para entrenar el modelo. \\ \hline
%\emph{General Adversarial Networks (GANs)} & Utilizado en la industria creativa para la generación de objetos 3D. 

%Útil en la edición de imágenes (Deepfake), generación de personajes de dibujos animados, ilustraciones para novelas, artículos, etc.  & Capaz de aprender la representación interna (distribuciones desordenadas y complejas) en cualquier dato.  & Cuando genera nuevos datos a partir de datos originales, no hay métrica de evaluación para juzgar la precisión de la salida. 

%Se requiere mucho cómputo y tiempo para el entrenamiento del modelo  \\ \hline
%\emph{Recurrent Neural Networks (RNNs) } & Se utiliza principalmente en los campos del procesamiento del lenguaje natural y el reconocimiento de voz. También es ideal para tareas como autocompletado de palabras, reconocimiento de texto y análisis de cuadros de video.  & Capacidad de recordar información a lo largo del período de entrenamiento. Posibilidad de procesar entradas de cualquier longitud   & Los cálculos requieren mucho tiempo debido a su naturaleza recurrente. 

%Dificultad de acceder a la información desde hace mucho tiempo.  \\ \hline
%\emph{Multilayer Perceptron?s (MLP?s)} & Problemas de clasificación.  

%Voz, reconocimiento de imágenes y compresión de datos.  & Puede distinguir datos que no son linealmente separables. 

%No hace ninguna suposición con respecto a las funciones de densidad de probabilidad  & Al actualizar los pesos en capas, la red puede atascarse en un mínimo local que puede dificultar la precisión.  \\ \hline

%\end{tabular}
%\end{table}

%Debido a que el presente proyecto se basará en el reconocimiento de imágenes y de clasificación de información, se tomó la de decisión de utilizar una CNN o Red Neuronal Convolucional para el reconocimiento de ojos abiertos o cerrados dentro de la imagen, esta aprende directamente de los datos, sin necesidad de extraer características manualmente.  Estas redes son particularmente útiles para encontrar patrones en imágenes para reconocer objetos, caras y escenas, además de permitir su implementación en video en tiempo real, lo cual es indispensable para el presente proyecto.  

%\subsubsection{Análisis y Elección del modelo de Red Neuronal}

%Debido a que el presente proyecto se plantea resolver un problema de clasificación, a continuación se analizará que tipos de modelos de redes neuronales son los más aptos para la resolución de los mismos.

%\begin{itemize}
%\item Redes Neuronales Unicapa
%En el caso mas simple de una red neuronal, las neuronas de la capa de entrada se limitan a recibir las señales de entrada. Estas se encargan de redistribuir estas señales a las neuronas de la capa de salida. A esto se le llama una red neuronal unicapa.


%\begin{center}
%  \includegraphics[scale=0.4]{imagenes/unicapa}
%\captionof{figure}{Redes Unicapa}
% \label{fig:boost}
%\end{center}


%Utilizando la herramienta de \emph{PlayGround Tensorflow} podemos observar la eficacia de este tipo de redes al resolver problemas de clasifiación.
%Si se le pide a esta Red Neuronal que sombree el área del color de los puntos mostrados dentro de la gráfica, se puede observar que es incapaz de realizarlo de manera correcta.

%\begin{center}
%  \includegraphics[scale=0.35]{imagenes/unicapa2}
%\captionof{figure}{Red Neuronal Unicapa}
% \label{fig:boost}
%\end{center}


%\item Redes Neuronales Multicapa


%Existe otro tipo de módelo de red neuronal que utiliza capas intermedias entre la capa de salida y la capa de entrada, a estas redes se les conoce como redes profundas o redes multicapa.

%\begin{center}
%  \includegraphics[scale=0.7]{imagenes/multicapa}
%\captionof{figure}{Redes Neuronales Multicapa}
% \label{fig:boost}
%\end{center}

%En la siguiente figura se puede apreciar que las redes neuronales multicapa tienen una eficiencia mayor a la hora de realizar el mismo problema de clasificación de puntos.Sin embargo, aún no puede resolver este problema correctamente. 


%\begin{center}
%  \includegraphics[scale=0.4]{imagenes/capasocultas}
%\captionof{figure}{Redes Neuronal con 2 Capas Ocultas de 4 Neuronas cada una}
% \label{fig:boost}
%\end{center}

%\item \textbf{Funciones de Activación}

%Una función de activación es un filtro o umbral que modifica o impone límites en los valores resultantes de una capa en una red neuronal. A continucación se muestran los resultados al resolver el mismo problema de clasificación de puntos de colores utilizando distintas funciones de activación.

%\begin{itemize}
%\item \textbf{ReLU}
%Esta función de activación consiste en anular los valores de entrada negativos y conservar los valores positivos con sus valores originales.

%\begin{center}
%  \includegraphics[scale=0.4]{imagenes/funrelu}
%\captionof{figure}{Representación Gráfica de la Función ReLu}
% \label{fig:boost}
%\end{center}


%\begin{center}
%  \includegraphics[scale=0.4]{imagenes/relu}
%\captionof{figure}{Redes Neuronal con 2 Capas Ocultas de 4 Neuronas cada una utilizando la función de Activación ReLu}
% \label{fig:boost}
%\end{center}

%\item \textbf{Tanh}
%La función de la tangente hiperbólica toma cualquier valor real como valores de entrada y de salida en el rango de -1 a 1. Cuanto mayor sea la entrada, más cerca estará del valor de salida de 1.0. Por otro lado, mientras sea menor sea la entrada, el valor de salida se aproximará mas a -1.0


%\begin{center}
%  \includegraphics[scale=0.2]{imagenes/funtanh}
%\captionof{figure}{Representación gráfica de la función Tangente Hiperbólica}
% \label{fig:boost}
%\end{center}


%\begin{center}
%  \includegraphics[scale=0.4]{imagenes/tanh}
%\captionof{figure}{Redes Neuronal con 2 Capas Ocultas de 4 Neuronas cada una utilizando la función de Activación Tanh}
% \label{fig:boost}
%\end{center}

%\end{itemize}
%Existe un tipo de Red Neuronal que integra los puntos anteriormente vistos: capas ocultas y funciones de activación. Este tipo de red se le conoce como Red Neuronal Convolucional. Cómo su nombre lo indica, estas redes se basan en el uso de la operación de convolución, además de hacer uso de las capas de ocultas y funciones de activación. Estas redes son de las mas eficientes en el campo de visión artificial. \cite{Referencia2}. Por lo tanto, se decidió hacer uso de una red convolucional para cumplir los requisitos previamente planteados.

%\end{itemize}

\clearpage

\subsection{Análisis del Módulo de Comunicaciones}
Los sistemas automatizados de comunicación, mayormente inalámbricos, se encargan de recopilar datos remotos y transmitir la información.
La tecnología elegida para la implementación de este módulo es la red 4G/LTE, su estándar es establecido por el 3GPP (Proyecto de asociación de tercera generación) donde establece sus especificaciones en la versión 8 de sus estándares, el cual clasifica hasta 13 categorías LTE \cite{categorias}. En estas categorías se especifica la velocidad máxima de carga y descarga, siendo la categoría 0 la velocidad más baja.
En la Tabla \ref{tab:CLTE} se observan las categorías LTE que existen junto con su velocidad máxima de bajada y subida, de la categoría 0 a la 5 se definen para equipos de usuarios, es decir, telefonía celular. 

\begin{table}[H]
	\begin{center}
	\caption{\label{tab:CLTE} Categorías LTE}
\begin{tabular}{| c | c | c |}
\hline

Categoría & Velocidad Máxima de Bajada(Mbps)& Velocidad Máxima de Subida (Mpbs \\ \hline
0 &  1 &  1   \\ \hline
1 &  10 &  5  \\ \hline
2 &  50 &  25   \\ \hline
3 & 100 &  50  \\ \hline
4 & 150 &  50  \\ \hline
5 & 300 &  75   \\ \hline
6 &  300 &  50  \\ \hline
7 &  300 &  150 \\ \hline
8 & 1200 & 600   \\ \hline
9 &  450 &  50  \\ \hline
10 &  450 &  100  \\ \hline
11 &  600 &  50 \\ \hline
12 &  600 &  100  \\ \hline
13 & 390 &  150  \\ \hline

\end{tabular}

\end{center}
\end{table}

Para este sistema, el análisis debe cumplir con los parámetros que dicta el teorema de Shannon-Hartley establece que, dado un canal con ruido con una capacidad $C$ e información transmitida en una tasa $R$ entonces si $R<C$ existe una técnica de codificación que permite que la probabilidad de error en el $Rx$ se reduzca. Se debe cumplir que la tasa de bits debe ser siempre menor a la capacidad del canal.

Este análisis se divide en:
\begin{itemize}
\item \emph{Telemetría:}\\ El módulo de telemetría es el encargado de recopilar, procesar y transmitir las coordenadas de la ubicación geográfica del conductor a la estación base que se encarga de monitorear los datos obtenidos.

\item \emph{Datos:}\\ El encargado de recopilar, procesar y transmitir los fotogramas que el sistema identifica como somnolencia en el conductor, así como un mensaje informativo.

\item \emph{Cobertura:}\\ Encargado de revisar la cobertura de la zona o regiones presentes en el alcance del sistema.
\end{itemize}

\subsubsection{Análisis del Submódulo de Telemetría }
El objetivo que tiene el módulo de telemetría es mandar el posicionamiento mediante coordenadas (latitud y longitud) del vehículo en movimiento en tiempo real. Las coordenadas serán mandadas en forma de cadena de texto, teniendo un aproximado de hasta 300 bits, otro punto a considerar es el periodo de tiempo entre el envío de cada posición, al tratarse de un vehículo en movimiento y la velocidad máxima siendo regida por Semovi (Secretaría de movilidad de la ciudad de México) que dicta una velocidad promedio de entre 50-80 km/h \cite{Referencian15}.

Se propone una velocidad de 60 km/h:

\begin{equation*}
60 \frac{km}{h} \cdot \frac{1000m}{1km}\cdot \frac{1h}{60min} \cdot \frac{1min}{60s}= 16.6 \frac{m}{s}\approx1 7\frac{m}{s}
\end{equation*}


El automóvil se desplaza aproximadamente 17 metros en 1 segundo por lo que al realizar el envío en periodos de 10 segundos, se  garantiza el trazado de la ruta en el mapa. Teniendo 170 metros recorridos cada 10 segundos del viaje.
Verificando que se cumpla el Teorema de Shannon-Hartley  tenemos:
\begin{equation*}
300 bits \cdot 10 s=3kbps
\end{equation*} 
y la máxima tasa de datos que el transceptor tiene es de 5 Mbps.

Cumpliéndose la relación establecida de $R<C$.
\begin{equation*}
3kbps<5 Mbps
\end{equation*}


\subsubsection{Análisis del Submódulo de Datos }\label{sec:ASD}

El objetivo que tiene el análisis de los datos es enviar fotogramas a la estación base para su futura gestión y validación, así como el almacenamiento de estos; de igual manera, se pretende el envío de mensajes informativos a la estación base.
\\
Para la transmisión del material multimedia a utilizar, se propone que el clip grabado tenga una profundidad de bits de mínimo 8 y una resolución de mínimo 960 x 540 píxeles, comúnmente conocido como QHD o "Quarter of High Definition" por sus siglas en inglés, todo esto en una secuencia de 30 fps.
\\
Tenemos que:

\begin{equation*}
960 \; x \; 540 \; x \; 8=4,147,200 \; bits
\end{equation*}

Cada imagen tiene 4,147,200 bits entonces en 1 segundo se transmiten:
\begin{equation*}
4,147,200 \; x \; 30 fps=124.41 \; Mbps
\end{equation*}

Que rebasa la capacidad del canal de red establecida, por lo que se implementa el uso de un compresor de video MP4 para así modificar la resolución en la que se almacena el video en la estación base. Por otro lado, se envían al menos 2 fotogramas por segundo para no sobrepasar la capacidad del canal para este caso.

\begin{equation*}
640 \; x \; 480 \; x \; 8=2,457,600 \; bits
\end{equation*}
Cada imagen tiene 2,457,600 bits entonces en 1 segundo se transmiten:
\begin{equation*}
2,457,600 \; x \; 2 fps=4.91 \; Mbps
\end{equation*}
Cumpliéndose nuevamente la relación establecida $R < C$.
\begin{equation*}
4.91 Mbps<5 Mbps
\end{equation*}
Más 3 kbps de la tasa de bits a utilizar del texto informativo.


\subsubsection{Análisis del Submódulo de Cobertura}

La red de telefonía celular funciona mediante celdas, figura \ref{fig:handover}), estas celdas tienen el objetivo de mantener conectados a los dispositivos en las diferentes áreas de cobertura y cada una de ellas contiene una estación base o antena. El \emph{handover}  o \emph{handoff} es el proceso de transferir el servicio de una celda a otra\cite{Referencian17} y se tiene la siguiente métrica:
\begin{itemize}
\item Se considera un \emph{handoff} fuerte cuando al ir cambiando de celdas  se presente algún problema en la velocidad de la red logrando así la pérdida de la misma.
\item Se considera un \emph{handoff} suave cuando al ir cambiando de celdas no se presente algún problema de la red o este sea mínimo.
\end{itemize}
Ya sea cuando se pierde la calidad en una de ellas o cuando el dispositivo se va trasladando.Este mecanismo tiene por objetivo el garantizar la correcta realización del servicio en las condiciones mencionadas anteriormente. 
Para el análisis de cobertura de la red LTE se tiene en cuenta el sistema \emph{handoff} porque el dispositivo se va trasladando entre distintas celdas.

\begin{center}
  \includegraphics[scale=0.3]{imagenes/handover}
\captionof{figure}{Esquema \emph{handover} entre dos celdas }
 \label{fig:handover}
\end{center}

La cobertura de LTE por Telcel es la más amplia del país \cite{CoberturaNacional}, su mayor cobertura está concentrada en la Ciudad de México, por lo que existe una buena recepción, aunque en ocasiones debido a la saturación de la red o al transferir el servicio de la antena de una estación base a otra se puede encontrar alguna intermitencia o retraso, en estos casos el módulo va a pasar a modo de espera para enviar la información una vez se restablezca la red.

\begin{center}
  \includegraphics[scale=.9]{imagenes/mapaLTE}
\captionof{figure}{Mapa de cobertura de la red LTE }
 \label{fig:mapaLTE}
\end{center}

En el mapa de cobertura la zona verde hace referencia a zonas con cobertura y la zona amarilla cobertura no garantizada, en caso de realizar pruebas en las zonas amarillas del mapa se va a notar un cambio en la velocidad del dispositivo móvil ya sea para la transferencia de archivos o la conectividad a la red
ocasionando un \emph{handoff fuerte}; por el otro lado, al estar realizando pruebas en la zona verde del mapa su \emph{handoff} será más suave.

\clearpage
\subsection{Análisis del Módulo de Estación Base}
El módulo de la estación base tiene como objetivo que el usuario administrador, visualice y confirme el estado de los reportes de incidencia que se hayan presentado por parte del conductor, por tal motivo, se realizará una aplicación web, la cual se conectará a una base de datos NoSQL. En ella se guardarán los reportes de incidencias y se podrán visualizar por medio de la aplicación web. Cabe aclarar que el video de la incidencia se almacenará en la nube, ya que al ser contenido multimedia no se puede guardar en la base de datos, únicamente se guardará el URL para acceder al video. Las credenciales del usuario serán almacenadas en Amazon Cognito, con la cuales podrán iniciar sesión dentro de la Aplicación Web, la cual estará alojada en un servidor web.


El sistema contará con los siguientes requerimientos:   \\

\textbf{Requerimientos Funcionales del Módulo de Estación Base}

\begin{table}[h]
\centering
\caption{RF01- Guardar Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Guardar Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La base de datos almacenará la información de cada reporte de incidencia que se envié desde el Módulo Central de Procesamiento. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Id del Conductor \\
\quad $\bullet$ Nombre de Conductor\\
\quad $\bullet$ Apellidos de Conductor  \\
\quad $\bullet$ Número de Incidencias\\
\quad $\bullet$ Fecha\\
\quad $\bullet$ Hora\\
\quad $\bullet$ Estado de la Incidencia \\
\quad $\bullet$ Ubicación  \\
\quad $\bullet$ URL del video 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Módulo de Procesamiento Central puede insertar datos en la base datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{RF02- Guardar Video }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Guardar Video }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La base de datos almacenará la información de cada reporte de incidencia que se envié desde el Módulo Central de Procesamiento. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Video de incidencia 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Módulo de Procesamiento Central puede insertar el video en el almacenamiento de objetos, mientras que la base de datos obtiene la URL del video guardado. \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{RF03- Conectar Aplicación Web }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Conectar Aplicación Web }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La base de datos almacenará la información de cada reporte de incidencia que se envié desde el Módulo Central de Procesamiento. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Node.js  \\
\quad $\bullet$ React   \\
\quad $\bullet$ Express   \\
\quad $\bullet$ MongoDB 

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador puede realizar la inserción, modificación, eliminación y consulta de datos desde la aplicación web.  \end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}



\begin{table}[h]
\centering
\caption{RF04- Desplegar Aplicación Web}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF04}}                                              & \emph{Desplegar Aplicación Web  }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La aplicación web se alojará en una red de entrega de contenido (CDN), disponible con una URL.  \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ \emph{Content Delivery Network}  \\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador puede acceder a la interfaz de la aplicación web, haciendo uso de la URL en el navegador web.  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}
\clearpage

\begin{table}[h]
\centering
\caption{RF05- Guardar Credenciales de Usuario Administrador }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Guardar Credenciales de Usuario Administrador }                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se guardarán únicamente las credenciales de los usuarios administradores que podrán acceder a la aplicación web. \\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Servicio de Administración de Acceso e Identidad 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador podrá iniciar sesión en la aplicación web utilizando un servicio de Administración de Acceso e Identidad  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\textbf{Requerimientos No Funcionales del Módulo de Estación Base}

\begin{table}[H]
\caption{Requerimientos No Funcionales del Módulo de Estación Base}
\begin{tabular}{{|m{0.12\linewidth}|m{0.25\linewidth}|m{0.50\linewidth}|}}
\hline
\textbf{ID} & \textbf{Nombre del requerimiento} & \textbf{Descripción } \\ \hline
\emph{RNF01 } & Disponibilidad & La disponibilidad del sistema será continua, el usuario podrá acceder a la información las 24 horas del día.  \\ \hline
\emph{RNF02 } & Interoperabilidad  & El sistema será capaz de intercambiar información con el Módulo Central de Procesamiento a través del Módulo de Telemetría.  \\ \hline
\emph{RNF03 } & Seguridad  & El sistema hará uso de encriptación AES-256 para garantizar la seguridad de las credenciales de los usuarios. \\ \hline
\emph{RNF04 } & Usabilidad  & El sistema estará enfocado a la visualización de reportes, por lo que este tendrá una interfaz intuitiva y amigable para el usuario. El sistema proporcionará mensajes de advertencia orientados al usuario, en caso de ocurrir un error en el Módulo Central de Procesamiento. \\ \hline

\end{tabular}

\end{table}

\clearpage
\textbf{Análisis de Casos de Uso}

Con base en los requerimientos se realizó el siguiente diagrama de casos de uso, el cual muestra las actividades y la interacción con el Módulo de Estación base y el Módulo Central de Procesamiento. 

\begin{center}
  \includegraphics[scale=.55]{imagenes/CasosdeusosMEB}
\captionof{figure}{Diagrama de Casos de Usos del Módulo de Estación Base}
 \label{fig:CasosdeusosMEB}
\end{center}


\begin{table}[h]
\centering
\caption{Caso de Uso 01 - Guardar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Guardar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento, Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema almacenará las incidencias recibidas por el módulo de Comunicaciones. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con una conexión al Módulo de Comunicaciones\\
\quad $\bullet$ Contar con una conexión a la Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Reporte de Incidencia\\
\quad $\bullet$ Módulo de Comunicaciones\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[h]
\centering
\caption{Caso de Uso 02 - Guardar Video }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Guardar Video}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se almacenará el video recibido por el Módulo de Comunicaciones \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con una conexión al Módulo de Comunicaciones\\
\quad $\bullet$ Contar con una conexión a la Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Video\\
\quad $\bullet$ Módulo de Comunicaciones\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 03 - Conectar Aplicación Web }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Conectar Aplicación Web}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Se realizará la conexión de la aplicación web y la base de datos \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con el servicio de Hosting Disponible
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Aplicación Web\\
\quad $\bullet$ Base de Datos\\ 
\quad $\bullet$ Servicio de Hosting\\   \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 04 - Desplegar Aplicación Web}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Desplegar Aplicación Web}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento, Módulo de Estación Base}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:} Utilizando el servicio de Hosting ofrecido por Amazon Amplify se desplegará la aplicación web\\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con una cuenta registrada en Amazon Amplify
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Aplicación Web\\
\quad $\bullet$ Base de Datos\\
\quad $\bullet$ Servicio de Hosting \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\clearpage 
\begin{table}[h]
\centering
\caption{Caso de Uso 05 - Guardar Credenciales de Usuario Administrador }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Guardar Credenciales de Usuario Administrador}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Módulo Central de Procesamiento}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Utilizando Amazon Congito, el sistema permitirá almacenar nuevos usuarios administradores \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con el servicio de la aplicación web Desplegado
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Elementos:}\\
\quad $\bullet$ Amazon Cognito
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\subsubsection{Análisis de la Aplicación Web}


A continuación se listan los requerimientos Funcionales obtenidos

\begin{itemize}


\item \textbf{Análisis de Requerimientos Funcionales}
\begin{table}[H]
\centering
\caption{RF01- Iniciar Sesión}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF01}}                                              & \emph{Iniciar Sesión}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{@{}l@{}}\textbf{Descripción:}  El sistema permitirá iniciar sesión en la aplicación web\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Servicio de Administración de Acceso e Identidad\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Credenciales\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema, con la ayuda un servicio de administración de acceso e identidad del cliente, comprobará que las credenciales ingresadas por parte del usuario administrador se encuentren en la base de datos. En caso contrario, la aplicación web indicará que ese usuario no se encuentra registrado en la base de datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[H]
\centering
\caption{RF02- Mostrar el Historial de Reportes de Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF02}}                                              & \emph{Mostrar el Historial de Reportes de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema desplegará en forma de lista todas las incidencias que se tengan registradas en la base de datos\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Incidencias\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema recuperará de la base de datos todas las incidencias que se tengan registradas.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}




\begin{table}[H]
\centering
\caption{RF03- Visualizar Reporte de Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF03}}                                              & \emph{Visualizar Reporte de Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema desplegará los detalles específicos de cada incidencia registrada.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Incidencia\\
\quad $\bullet$ Administrdor\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador podrá visualizar los reportes individuales de incidencias de cada conductor al hacer click en cualquiera de las incidencias mostrada en la lista principal. Los reportes contendrán información sobre la fecha, hora, ubicación y un video corto del momento en que fueron detectados síntomas de somnolencia.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF04- Confirmar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF04}}                                              & \emph{Confirmar Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}  El sistema permitirá al administrador confirmar la incidencia, esto para descartar que se trate de un falso positivo.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Incidencia\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El usuario administrador podrá confirmar la incidencia después de haber revisado el videoclip del momento de somnolencia con la intención de descartar falsos positivos. Esto será posible ingresando a una incidencia específica mostrando sus detalles.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[H]
\centering
\caption{RF05 - Recuperar Contraseña}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF05}}                                              & \emph{Recuperar Contraseña}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema contará con una opción para recuperar la contraseña del administrador en caso de que sea olvidada la contraseña.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Servicio de Administración de Acceso e Identidad\\
\quad $\bullet$ Email\\
\quad $\bullet$ Administrador\\
\quad $\bullet$ Gestor de Base de Datos
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema requerirá que el usuario administrador ingrese el correo con el que fue registrado. Posteriormente se le enviará un código de recuperación de contraseña a ese correo. El administrador ingresará se código en el apartado de recuperar contraseña y así podrá ingresar una nueva contraseña.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF06- Mostrar perfil del Conductor}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF06}}                                              & \emph{Mostrar Perfil Conductor}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema permitirá al usuario administrador visualizar los datos de cada conductor registrado en la base de datos.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Perfil\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Gestor de Base de Datos

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El administrador podrá consultar cada uno de los perfiles de los conductores registrados en la base de datos dando click en el nombre del mismo. En dicho perfil se mostrarán datos como nombre, apellido, así como el número de incidencias de dicho conductor, con sus respectivos detalles.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF07- Mostrar ubicación Geográfica}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF07}}                                              & \emph{Mostrar Ubicación Geográfica}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}La aplicación web, con ayuda de los datos proporcionados por el módulo de telemetría, mostrará la ubicación en tiempo real de un conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Ubicación en Tiempo Real\\
\quad $\bullet$ Módulo de Telemetría\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema permitirá al administrador consultar la ubicación de los conductores en tiempo real. Para esto el administrador deberá de ingresar previamente al perfil del conductor del cual desea consultar dicha ubicación.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[H]
\centering
\caption{RF08- Descartar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF08}}                                              & \emph{Descartar Incidencia}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema permitirá catalogar una incidencia como Falsa si fuera el caso.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Incidencia\\
\quad $\bullet$ Administrador\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
En caso de presentarse una incidencia falsa, después de haber sido revisada por el administrador, esta podrá ser catalogada como falsa incidencia y será eliminada automáticamente de la base de datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF09- Registrar Usuario}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF09}}                                              & \emph{Registrar Usuario}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema le permitirá al administrador registrar nuevos conductores.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ ID\\

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El Administrador podrá registrar a nuevos conductores en el sistema. El sistema generará de manera automática el ID del nuevo conductor\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\centering
\caption{RF10- Mostrar el Historial de Reportes de Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF10}}                                              & \emph{Modificar Usuario}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema le permitirá al administrador modificar los datos del conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Administrador

\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El administrador podrá editar los datos de los conductores como nombre o apellido.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

\begin{table}[H]
\caption{RF11- Mostrar el Historial de Reportes de Incidencia}
\centering
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{ID}}                                                & \textbf{Nombre corto del Requerimiento}                                             \\ \hline
\multicolumn{1}{|l|}{\emph{RF11}}                                              & \emph{Elimininar Usuario}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El sistema le permitirá al administrador eliminar los datos del conductor.\\ \\ \textbf{Elementos:}
\\
\quad $\bullet$ Conductor\\
\quad $\bullet$ Administrador


\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Solución del Requerimiento:}\\
El sistema le permitirá al eliminar los datos de conductores de la base de datos.\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}

	        
\item \textbf{Análisis de Requerimientos no Funcionales}

A continuación se mencionan los requerimientos no funcionales de la aplicación web.

\begin{table}[H]
\caption{Requerimientos No funcionales - Aplicación Web}
\begin{tabular}{|l|l|l}
\cline{1-2}
\textbf{Requerimiento No Funcional} & \textbf{Descripción}                                                                                                                                                                   &  \\ \cline{1-2}
Disponibilidad                      & \begin{tabular}[c]{@{}l@{}}La aplicación web deberá estar \\ disponible las 24 horas del día\end{tabular}                                                                              &  \\ \cline{1-2}
Interoperabilidad                   & \begin{tabular}[c]{@{}l@{}}La aplicación deberá ser accesible desde \\ cualquier sistema operativo \\ mientras se cuenta con un \\ navegador web en su versión más actual\end{tabular} &  \\ \cline{1-2}
Eficiencia                          & \begin{tabular}[c]{@{}l@{}}La aplicación tendrá tiempos de respuesta\\ menores a 100ms.\end{tabular}                                                                                   &  \\ \cline{1-2}
Escalabilidad                       & \begin{tabular}[c]{@{}l@{}}La aplicación web deberá ofrecer la oportunidad de \\ agregar nuevas funcionalidades y \\ soportar un mayor número de usuarios a \\ futuro\end{tabular}     &  \\ \cline{1-2}
Estabilidad                         & \begin{tabular}[c]{@{}l@{}}La aplicación deberá ofrecer un buen \\ funcionamiento mientras se tenga \\ una conexión a internet mínima de 1Mbps\end{tabular}                                      &  \\ \cline{1-2}
\end{tabular}

\end{table}
cupera
\clearpage
\item \textbf{Análsis de Casos de Uso}

\begin{center}
  \includegraphics[scale=.5]{imagenes/casosdeusoweb}
\captionof{figure}{Diagrama de Casos de Uso - Aplicación Web }
 \label{fig:scaraindust}
\end{center}

\textbf{Especificación de Casos de Uso}

\begin{table}[h]
\centering
\caption{Caso de Uso 01 - Iniciar Sesión }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Iniciar Sesión}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD, Amazon Cognito}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador ingresará los datos correspondientes para iniciar sesión en la aplicación web. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ El administrador deberá contar sus credenciales registradas en Amazon Cognito
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Email\\
\quad $\bullet$ Contraseña
 \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 02 - Registrar Usuario }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Registrar Usuario}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}Solo los usuarios administradores podrán registrar a nuevos conductores en el sistema. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de acceso como administrador 
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ Edad
 
\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 03 - Modificar Usuario }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Modificar Usuario}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El usuario Administrador podrá modificar los datos de los conductores previamente registrados. \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador \\
\quad $\bullet$ Que exista una entrada del conductor a modificar
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Nombre\\
\quad $\bullet$ Apellido\\
\quad $\bullet$ Edad
 
  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 04 - Eliminar Usuario}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Eliminar Usuario}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El usuario administrador podrá dar de baja a un conductor \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador \\
\quad $\bullet$ Que exista una entrada del conductor a eliminar
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ ID del conductor\\

\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}



\begin{table}[h]
\centering
\caption{Caso de Uso 05 - Confirmar Incidencia}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Confirmar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá confirmar las incidencias \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador \\
\quad $\bullet$ Haber inciado sesión previamente \\
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ Correo \\
\quad $\bullet$ Contraseña\\\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}


\begin{table}[h]
\centering
\caption{Caso de Uso 06 - Visualizar Incidencia }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Visualizar Incidencia}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá reproducir un video dónde se muestre el momento en que ocurrió la incidencia \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de administrador
\quad $\bullet$ Haber seleccionado una incidencia
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas}\\
\quad $\bullet$ ID incidencia\end{tabular}}                                                    \\ \hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Caso de Uso 07 - Recuperar Contraseña}
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Recuperar Contraseña}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, BBDD}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá recuperar contraseña en caso de olvidarla \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de administrador
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas}\\
\quad $\bullet$ Email\\
\quad $\bullet$ Nueva Contraseña

\end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}
\clearpage

\begin{table}[h]
\centering
\caption{Caso de Uso 08 - Visualizar Ubicación en Tiempo Real }
\begin{tabular}{|ll|}
\hline
\multicolumn{1}{|l|}{\textbf{Nombre del Caso de Uso}}                                                & \emph{Visualizar Ubicación en Tiempo Real}                                             \\ \hline
\multicolumn{1}{|l|}{\textbf{Actores}}                                              & \emph{Administrador, Módulo de Comunicaciones}                                                             \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Descripción:}El administrador podrá visualizar la ubicación en tiempo real de los conductores registrados \\ \\ \textbf{Precondiciones:}
\\
\quad $\bullet$ Contar con credenciales de Administrador\\
\quad $\bullet$ Haber iniciado sesión previamente
\end{tabular}} \\ \hline
\multicolumn{2}{|l|}{\begin{tabular}[c]{p{0.7\linewidth}@{}l@{}}\textbf{Entradas:}\\
\quad $\bullet$ ID del conductor
  \end{tabular}}                                                    \\ \hline
\end{tabular}

\end{table}
\end{itemize}


\subsubsection{Análisis y Elección del manejador de bases de datos  }
Debido a la escalabilidad horizontal, facilidad de implementación, bajo coste y flexibilidad que ofrecen los gestores de bases de datos NoSQL para adaptarse a las necesidades del proyecto, se optó por la elección de un gestor de este tipo. Además, se contemplaron las posibles modificaciones dentro del modelado de la base de datos, las cuales tendrán como motivo cumplir los requisitos del sistema y presentar la información necesaria en la aplicación web. Las modificaciones necesarias podrán ser fácilmente aplicadas usando un SGBD NoSQL, ya que ofrecen una mayor facilidad de realizar cambios dentro del esquema, a diferencia de un SGBD SQL.

\begin{table}[h]
\caption{Cuadro Comparativo de los Sistemas de Gestión de Bases de Datos No Relacionales}
\begin{tabular}{{|m{0.16\linewidth}|m{0.18\linewidth}|m{0.18\linewidth}|m{0.18\linewidth}|m{0.18\linewidth}|}}
\hline
 & \textbf{Cassandra } & \textbf{MongoDB } & \textbf{Redis } & \textbf{Amazon DynamoDB } \\ \hline
 \textbf{Tipo de base de datos }& NoSQL \emph{wide-column}  & NoSQL Orientado a documentos  & NoSQL clave-valor  & NoSQL clave-valor  \\ \hline
 \textbf{Licencia }& Codigo abierto  & Codigo abierto SSPL & Codigo abierto BSD 3-clause  & Vendor \\ \hline
 \textbf{Cumplimiento ACID }& No & Si  &  Si &  Si \\ \hline
 \textbf{Lenguaje de consulta principal }& CQL  & JavaScript  & Permite el uso de varios lenguajes  & DQL  \\ \hline
 \textbf{Principales casos de uso }& Análisis social, análisis en tiempo real, venta al por menor y mensajería & Gestión de IOT, análisis en tiempo real, desarrollo de aplicaciones, inventario y personalización & Almacenamiento en caché, colas, filtrado y estadísticas  & Juegos, comercio minorista, servicios financieros, publicidad y transmisión de medios  \\ \hline
 \textbf{Seguridad  }& Seguridad integrada para la autorización, cifrado y autenticación, la seguridad está desactivada de forma predeterminada para facilitar su uso dentro de los clústeres  & Seguridad incorporada para autorización, autenticación y encriptación  & Se inicia automáticamente en modo de protección y ofrece sugerencias de seguridad  & Seguridad integrada para datos y aplicaciones; software, hardware, instalaciones y red seguros del proveedor  \\ \hline
 \textbf{Escalabilidad }& Horizontal  & Horizontal  & Horizontal  & Horizontal  \\ \hline

\end{tabular}
\end{table}

Se eligió Amazon DynamoDB como SGBD NoSQL debido a su facilidad de integración con los servicios de autenticación y despliegue de AWS Amplify que se usarán para el alojamiento de la aplicación \ref{server}. DynamoDB ofrece una solución escalable y totalmente administrada, lo que complementa eficientemente la arquitectura de la aplicación, permitiendo una gestión sencilla y eficaz de los datos junto con características clave de autenticación y despliegue proporcionadas por AWS Amplify.


\subsubsection{Análisis y Elección de lenguajes de programación web}

Al igual que en el desarrollo del \emph{backend}, existen diversas opciones para el desarrollo del frontend, e incluso en mayor medida. En este caso, los elementos fundamentales para el desarrollo del frontend de una aplicación son HTML, JavaScript y CSS. 

JavaScript ha experimentado una evolución significativa y cuenta con una comunidad considerable, lo cual lo posiciona como uno de los principales lenguajes para el desarrollo frontend. 


A continuación se describen sus características más importantes:

\begin{itemize}

\item \textbf{Versatilidad}

JavaScript es un lenguaje que permite crear interactividad y dinamismo en las aplicaciones web. Su capacidad para manipular el contenido y la apariencia de una página en tiempo real, así como interactuar con elementos del DOM (Document Object Model), lo convierte en una elección ideal para crear interfaces de usuario interactivas y atractivas.

\item \textbf{Multiplataforma}
Javascript puede ser ejecutado en prácticamente cualquier navegador web moderno sin necesidad de plugins o complementos adicionales. Esto asegura que las aplicaciones frontend desarrolladas con JavaScript sean accesibles y funcionen de manera consistente en diferentes entornos y dispositivos.

\item \textbf{Procesamiento asíncrono}

El procesamiento asíncrono es una de las características más útiles del lenguaje JavaScript. Usando JavaScript, un bloque del script no podrá detenerse o dejar que el otro bloque de código espere a que comience la respuesta. Si se está procesando una solicitud, otras también trabajarán en paralelo con la solicitud anterior en lugar de esperar la respuesta de la solicitud anterior. Ahorra mucho tiempo al ejecutar scripts en paralelo.

\item \textbf{Poca carga de Procesamiento del servidor}

JavaScript permite realizar funcionalidades básicas en el lado del cliente. Por tanto el servidor no tendrá que procesar las funcionalidades básicas que mejoran el rendimiento del servidor.

\end{itemize}


\clearpage

\subsubsection{Análisis y Elección del servidor de alojamiento} \label{server}
Para el presente proyecto se requiere una capacidad de almacenamiento que nos permita el uso de archivos multimedia, concretamente archivos de video.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Tipo de Multimedia} & \textbf{Ejemplos}             \\ \hline
Imágenes                    & JPEG, GIF, PNG, Archivos TIFF \\ \hline
Audio                       & MP3, WAV, ACC                 \\ \hline
Video                       & QuickTime, MP4, Youtube       \\ \hline
\end{tabular}
\caption{Tipos de Archivo Multimedia}
\end{table}

Si se requiere alojar una aplicación web cuyo contenido predominante sea multimedia, se deberá de tomar en cuenta los siguientes factores:


\begin{itemize}
\item  Ancho de banda

El ancho de banda y el almacenamiento son una función de su plan de alojamiento. Generalmente un plan de alojamiento en la nube  permite pagar por un uso menor durante las horas de menor actividad y explotar cuando recibe mucho tráfico. No se paga por ancho de banda o espacio de almacenamiento que en realidad no se utiliza.

\item Almacenamiento

Si se tiene una gran cantidad de archivos multimedia, entonces se requiere gran capacidad de almacenamiento. Lo ideal sería contar con almacenamiento ilimitado, pero esto significaría un aumento considerable al costo de alojamiento. Se debe de analizar un aproximado de almacenamiento necesario y en base a eso se deberá elegir el plan de almacenamiento que mejor cubra esas necesidades.

\item CDN (\emph{Content Delivery Network})

Lo último que debe considerar con el alojamiento de medios es una red de entrega de contenido o CDN. Una CDN intenta mejorar el rendimiento de la transmisión de medios mediante la ubicación de servidores que están geográficamente cerca del usuario mediante sofisticados algoritmos de ubicación y de ruteo.

\end{itemize}

Sabiendo lo anterior, se procede a realizar el análisis de distintos proveedores de alojamiento con la propósito de seleccionar saber aquel que ofrezca la capadidad de alojar y almacenar contenido multimedia.

\begin{itemize}
\item AWS Amplify Hosting
AWS Amplify Hosting es un servicio de alojamiento e Integración Continua/Entrega Continua completamente administrado para aplicaciones estáticas, rápidas, seguras, fiables, renderizadas del lado del servidor y que escalan a la par. Algunas de sus principales ventajas son:

\begin{itemize}
\item \textbf{Implementación de contenido web con rapidez}

AWS permite la implementación continua de una aplicación web estática o renderizada del lado del servidor, una página de inicio de la aplicación móvil o una aplicación progresiva en cada confirmación de código\cite{AWS}.


\item \textbf{CDN}

Cuenta con la red de entrega de contenido (CDN) de Amazon CloudFront con cientos de puntos de presencia en todo el mundo. Lo que permite un tiempo de respuesta de hasta menos de 10ms.

\item \textbf{Monitoreo}

AWS cuenta con un sistema de monitoreo de tráfico en tiempo real. También permite crear alarmas personalizadas para enviar notificaciones cuando la métrica haya superado el límite establecido. 

\item \textbf{Precio}

AWS cuenta con dos planes, uno gratuito y otro de paga, a continuación, se detallan las características de cada uno.

\begin{center}
  \includegraphics[scale=.5]{imagenes/amplify}
\captionof{figure}{Planes de Alojamiento AWS Amplify}
 \label{fig:DiagramadeactividadMEB}
\end{center}

\item \textbf{A2Hosting}

\begin{itemize}
\item \textbf{Alojamiento Compartido}

A2 Hosting cuenta con dos tipos de planes de alojamiento, el primero con costo de renovación que  va desde \$10.99 dls . Si se llegara a necesitar un servidor dedicado, el plan que nos ofrece está característica tiene un precio de  \$25.99 por mes.

\item \textbf{VPS}

VPS significa servidor privado virtual por sus siglas en inglés. Es una forma de dividir un servidor en (sub)servidores individuales más pequeños. Esto significa que se puede configurar de acuerdo a las necesidades del cliente y no tener que compartir recursos con otros clientes. Un VPS en A2 Hosting cuesta desde tan solo \$7.65 al mes hasta alrededor de \$200 dependiendo del número de subdivisiones necesarias.

\item \textbf{CDN}
A2 Hosting no ofrece servicio de CDN, sin embargo, cualquiera de sus planes ofrecen la posibilidad de contratar un servicio de CDN proveedores externos pagando un precio extra del precio base dependiendo del plan contratado.

\end{itemize}


\item \textbf{HosGator}
\begin{itemize}

\item \textbf{Tiempo de Respuesta}

De acuerdo con el sitio Bitcatcha, que se dedica a evaluar los tiempos de respuestas de los servidores de páginas web, HostGator poseé tiempos de respuestas mínimos para el territorio de Estados Unidos. A continuación se muestra los tiempos de respuesta de distintos territorios:


\begin{center}
  \includegraphics[scale=.5]{imagenes/respuesta}
\captionof{figure}{Tiempos de Respuesta de servidores de HostGator}
 \label{fig:DiagramadeactividadMEB}
\end{center}

HostGator posee solo 2 datacenters, uno localizado en el área oeste, y otro en el este. Esto puede ocasionar que los tiempos de respuesta no sean los mejores en áreas que estén alejadas de las antes mencionadas


\item \textbf{Disponibilidad}
HosGator ofrece una disponibilidad del 99.9\%, esto quiere decir que los sitios que se decida alojar en los servidores de HostGator deberían ser accesibles la mayoría del tiempo.


\end{itemize}


\end{itemize}



\end{itemize}


Después de haber analizado los distintos proveedores de alojamiento así como sus características, se llegó a la conclusión de utilizar AWS Amplify. Ya que este contiene una suite de herramientas que facilitan la implementación de una aplicación web, como por ejemplo S3, que es un servicio de alojamiento en la nube utilizado para archivos multimedia de gran tamaño, además de contar con su propia CDN que facilitará el acceso a los datos almacenados.

\clearpage
\section{Capítulo IV: Diseño}

\subsection{Diseño del Módulo Central de Procesamiento}

Si todos los sistemas funcionan correctamente, el Módulo de Procesamiento Central entrará en modo de espera por los datos proporcionados por el Submódulo de Visión Artificial. En caso de que este último envíe una señal de alerta de somnolencia, el Módulo Central activará la alarma en forma de buzzer.

Posteriormente, se obtendrá la ubicación geográfica con la ayuda del Módulo de Comunicaciones. Se realizará un reporte de incidencia que contendrá la fecha, hora, ubicación y un pequeño videoclip del momento en que se detectó la somnolencia. Este será enviado a la Estación Base, que se encargará de almacenarlo en su respectiva base de datos. Como se indicó inicialmente, el sistema estará disponible mientras se encuentre conectado a una fuente de alimentación; esto significa que el estado del sistema se encuentra conectado.\\

\begin{center}
  \includegraphics[scale=.5]{imagenes/diagrama_secuenciamc}
\captionof{figure}{Diagrama de Secuencia - Módulo Central de Procesamiento}
 \label{fig:secuenciamc}
\end{center}

Siguiendo los procesos de la Figura 4, se procede a dar un análisis superficial en la concurrencia de los mismos. También se detallan las peticiones y respuestas de los distintos submódulos y sistemas.

\subsubsection{Elección de la Unidad Contenedora de Procesamiento}

Para el diseño de la unidad contenedora del módulo de procesamiento, se tomaron en cuenta los elementos físicos que estarán dentro de la unidad y sus respectivas medias. Cabe mencionar que los elementos que respectan al modelo del ordenador, el modelo de la cámara, el modelo del zumbador y el modelo de la microSD fueron previamente seleccionados en la secciones \ref{sec:microordenador}, \ref{sec:camara}, \ref{sec:alarma} y \ref{sec:almacenamientoexterno}. 
\\
Elementos físicos que contendrá la unidad:

\begin{itemize}

\item \textbf{Nvidia Jetson Nano}\\
De acuerdo con las especificaciones físicas de la Jetson Nano se tiene las siguientes medidas en milímetros:\\



\begin{center}
  \includegraphics[scale=.6]{imagenes/nanodim}
\captionof{figure}{Dimensiones Nvidia Jetson Nano}
 \label{fig:scaraindust}
\end{center}


\begin{center}
  \includegraphics[scale=.4]{imagenes/nano}
\captionof{figure}{Nvidia Jetson Nano}
 \label{fig:scaraindust}
\end{center}



\item Zumbador Pasivo KY-006\\
Dimensiones 18 x 15mm. 
\begin{center}
  \includegraphics[scale=.2]{imagenes/KY-006}
\captionof{figure}{Zumbador Pasivo KY-006}
 \label{fig:scaraindust}
\end{center}

\item Modulo de Cámara IMX219-160\\
Dimensiones de la placa: 11 x 5.11 x 2.39 cm.

\begin{center}
  \includegraphics[scale=.4]{imagenes/imx}
\captionof{figure}{Modulo de Cámara IMX219-160}
 \label{fig:scaraindust}
\end{center}
 

\item Cable macho-hembra\\

\begin{center}
  \includegraphics[scale=.2]{imagenes/Jumpers}
\captionof{figure}{Jumpers}
 \label{fig:scaraindust}
\end{center}

Se utilizarán 2 cables macho-hembra para la conexión del zumbador pasivo hacia los pines GND y Vcc de la Jetson Nano. 
Largo 10 cm. 

\item Micro SD\\  
Dimensiones: 15 x 11 x 1 mm. 

\begin{center}
  \includegraphics[scale=.4]{imagenes/MicroSD}
\captionof{figure}{Micro SD}
 \label{fig:scaraindust}
\end{center}


\end{itemize}

\clearpage

En un principio se tenía propuesto diseñar la unidad contenedora de procesamiento. Sin embargo, al buscar alternativas, se encontró una carcase especificamente diseñada para la Nvidia Jetson Nano, que cuenta con una plataforma para colocar una cámara digital además de orificios para antenas 4G, por lo que se decidió a utilizar esta carcasa para proteger los componentes.

\begin{center}
  \includegraphics[scale=.6]{imagenes/waveshare}
\captionof{figure}{Carcasa Waveshare}
 \label{fig:scaraindust}
\end{center}

Esta carcasa está hecha de metal y además incluye un ventilador para disipar el calor.

\begin{center}
  \includegraphics[scale=.8]{imagenes/wavecompo}
\captionof{figure}{Componentes de la Unidad Contenedora de Procesamiento}
 \label{fig:scaraindust}
\end{center}
 


\newpage
\subsubsection{Diseño del Submódulo de Visión Artificial}
Con base a los requerimientos definidos en la sección de Análsis, se procedió a realizar distintos diagramas que muestren las interacciónes y el funcionamiento de los distintos módulos.


En el siguiente Diagrama de Actividades se describen las actividades y sus interacciones con el Submódulo de Visión Artificial y la Estación Base. Para que el sistema principal pueda iniciar, se necesita que el conductor encienda el auto, ya que este sistema funcionará utilzando la alimentación electrica.
\\\\ 

\begin{center}

  \includegraphics[scale=.45]{imagenes/actividades_vision}
\captionof{figure}{Diagrama de Actividades - Submódulo de Visión Artificial}
 \label{fig:actividades}

\end{center}

\begin{center}
  \includegraphics[scale=.5]{imagenes/flujo_vision}
\captionof{figure}{Diagrama de Flujo - Submódulo de Visión Artificial}
 \label{fig:landmark}
\end{center}

La cámara digital capturará la imagen en tiempo real a una resolución de 640x480 píxeles. Dado que buscamos ahorrar recursos de procesamiento, el uso de una mayor resolución o una tasa de cuadros por segundo más alta podría resultar en un funcionamiento ineficiente de los procesos en los distintos módulos.

Para la detección de rostro, ojos y boca, se utilizarán las librerías Dlib y OpenCV. Posteriormente, se determinará si el conductor tiene los ojos abiertos o cerrados mediante la medición de distancias utilizando puntos de referencia. En caso de detectar ojos cerrados, se iniciará un contador. Si este contador llega a los 4 segundos de detectar ojos cerrados, el sistema determinará que el conductor presenta un caso de somnolencia y activará la alarma para alertar al conductor. Posteriormente, se generará un reporte de incidencia que incluirá datos del conductor y de la incidencia, como fecha, hora y ubicación, así como un videoclip de menos de 1 minuto que muestre el momento en que se detectó la incidencia. El sistema continuará activando la alerta hasta que se detecte un cambio en el estado de los ojos (de cerrados a abiertos). Finalmente, el reporte de incidencia será enviado a la Estación Base para su posterior revisión.

\begin{itemize}


\item \textbf{Puntos de Referencia}

\begin{center}
  \includegraphics[scale=.42]{imagenes/landmark}
\captionof{figure}{Puntos de referencia}
 \label{fig:landmark}
\end{center}



A su vez, se utilizarán puntos de referencia con la ayuda de el software OpenCV y el modelo iBUG 300-W para delimitar la región de interés de la boca.

En la siguiente tabla se muestra la delimitación y agrupación de los puntos de interés, tales como: ojo derecho, ojo izquierdo y boca. De este modelo de detección de rostro, solo serán utilizados el grupo de 48 a 67, que delimitarán la región de la boca.
\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{|l|c|}
\hline
Partes        & \multicolumn{1}{l|}{Puntos de Referencia} \\ \hline
Boca          & {[}48-67{]}                               \\ \hline
Ojo Derecho   & {[}36-41{]}                               \\ \hline
Ojo Izquierdo & {[}42-46{]}                               \\ \hline
\end{tabular}
\caption{\label{tab:landmakrs} Agrupación de Puntos de Referencia}
\end{table}
\end{center}


\item \textbf{Mouth Opening Ratio}


Debido a que bostezar es un signo de cansancio, se propone medir el tamaño y la forma de la boca es necesario para identificar un bostezo. Para esto, se utilizara el \emph{Mouth Opening Ratio} que es un método que utiliza puntos de referencia para medir la apertura de la boca. Entre más grande sea este valor, más es la aperatura de la boca, por lo tanto cumple con las características de un bostezo.


\begin{center}
  \includegraphics[scale=.5]{imagenes/MOR}
\captionof{figure}{\emph{Mouth Opening Ratio}}
 \label{fig:landmark}
\end{center}

La formula general para calular el \emph{MOR} es la siguiente:
\begin{equation}
MOR = \frac{\left \|p_{2}-p_{8}  \right \| +\left \|p_{3}-p_{7}  \right \|+\left \| p_{4}-p_{6} \right \|}{2\left \| p_{1}-p_{5}\right \|}
\end{equation}

Utilizando nuestros puntos de referencia, se podrá calcular el MOR de la siguiente manera:

\begin{equation}
MOR = \frac{\left \|P49-P59  \right \| +\left \|P51-P57  \right \|+\left \| P53-P55 \right \|}{2\left \| P48-P54\right \|}
\end{equation}

De tal manera, cuanto mayor sea el valor del \emph{MOR}, mayor será la apertura de la boca. Por lo cuál, se tomará un valor de 0.60, que es un estándar establecido para el valor de un bostezo.\cite{mor}
\end{itemize}

\clearpage

\subsection{Diseño del Módulo de Comunicaciones}
Para el diseño de este módulo se tiene contemplado ejecutar dos procesos asíncronos, es decir, que se ejecutan al mismo tiempo o de manera paralela.

A continuación se muestra el diagrama de Flujo del Módulo de Comunicaciones
\begin{center}
  \includegraphics[scale=0.6]{imagenes/DF-modCom}
\captionof{figure}{Diagrama de Flujo del Módulo de Comunicaciones}
 \label{fig:DF-modCom}
\end{center}

\newpage
a ubicación del conductor se obtendrá mediante el Módulo de Telemetría cada 10 segundos, con la intención de no consumir demasiados recursos de procesamiento y energía. Posteriormente, esta información será enviada a la Estación Base utilizando el módulo SIM27600G. En caso de no contar con cobertura que permita la conexión a la estación base, la ubicación del conductor permanecerá en la última obtenida hasta que se actualice desde la Unidad de Procesamiento Central.



\begin{figure}
  \includegraphics[scale=0.5]{imagenes/DG-modCom}
\captionof{figure}{Diagrama Actividades del Módulo de Comunicaciones}
 \label{fig:DG-modCom}
\end{figure}



\newpage
\subsection{Diseño de la Estación Base}

Con base en los requerimientos, se plantea realizar el diseño de la arquitectura del Módulo de Estación Base, integrando el Módulo de Procesamiento Central. El cual hará énfasis en la organización y comunicación de los elementos que lo conforman.  \\

La Figura \ref{fig:DisenoMEB} a muestra la arquitectura del sistema de Estación base, el cual se compone de las interacciones de los elementos que permitirán al usuario acceder e interactuar con la aplicación web. El diagrama también muestra la participación del Módulo de Procesamiento Central ya que el registro de incidencias y el envío del video de incidencia serán realizados por dicho módulo. La información de los reportes de incidencias y el registro de los conductores serán almacenados en DynamoDB, mientras que los videos de incidencia se almacenarán en Amazon S3. Las credenciales de los Usuarios Administradores que tendrán permitido acceder a la aplicación se almacenarán en Amazon Cognito. Para la aplicación web, el \emph{backend} será desarrollado en node.js mientras que el \emph{frontend} será desarrollado en React, posteriormente los archivos se almacenarán en un repositorio dentro de Github. La aplicación web será alojada y desplegada desde AWS Amplify, lo cual le permitirá al cliente acceder a la aplicación desde una URL.   


\begin{center} 
  \includegraphics[scale=.5]{imagenes/DisenoMEB} 
\captionof{figure}{Diagrama de Diseño - Módulo de Estación Base} 
\label{fig:DisenoMEB} 
\end{center} 


El diagrama de comunicación muestra las interacciones entre elementos que se involucran en cada requerimiento funcional.  Así mismo, dan profundidad al diagrama de Arquitectura del Módulo de Estación Base. La aplicación web hará uso de la Base de Datos y el \emph{backend} de la aplicación web, que se realizará con Node.js. Mientras que para el despliegue de la aplicación web se requiere del servidor AWS Amplify para permitirle al usuario entrar a la aplicación web. El sistema almacenará el video de incidencia en Amazon S3, enviado desde el Módulo Central de Procesamiento, al cual se podrá acceder por medio del ID. El envío de incidencia requiere la interacción del Módulo Central de Procesamiento el cual se encargará de realizar y enviar el Reporte de Incidencia, posteriormente será almacenado en la Base de Datos.

\begin{center} 
  \includegraphics[scale=.7]{imagenes/diagramaMEB} 
\captionof{figure}{Diagrama de Comunicación - Módulo de Estación Base} 
\label{fig:DisenoMEB2} 
\end{center} 

\clearpage
\subsubsection{Diseño de la Aplicación Web}

Para el diseño y desarrollo de la Aplicación web, se  decidió utilizar el lenguaje Javascript, ya que este cuenta con las herramientas y/o frameworks que mejor se adaptan a los requisitos previamente definidos.
A su vez, se decidió utilizar el NodeJs para el sistema backend.

Node.js, es un entorno en tiempo de ejecución multiplataforma basado en JavaScript. Este es controlado por eventos, permitiendo establecer y gestionar múltiples conexiones al mismo tiempo. Gracias a esta característica, el bloqueo de procesos no existe. NodeJs trabaja fundamentalmente bajo dos características: \emph{asincronía}, que permite la ejecucción de varios procesos al mismo tiempo, y \emph{Entrada/salida sin bloqueo}, que significa poder trabajar con múltiples solicitudes sin bloquear un hilo para una sola solicitud. \cite{NodeJs}

NodeJs es capaz de manejar distintas peticiones sin que tener que esperar a que una petición sea respondida para continuar con la siguiente petición. De ahí la elección de este entorno de Javascript para el desarrollo de la aplicación web.\\

A continuación se muestran diversos diagramas de secuencias que describen los procesos de los requerimientos definidos en la sección de Análisis.


\begin{center}
  \includegraphics[scale=.6]{imagenes/diagramaclasesaw}
\captionof{figure}{Diagrama de Clases - Aplicación Web}
 \label{fig:clasesaw}
\end{center}

En la Figura \ref{fig:clasesaw} se pueden observar las clases que estarán dentro de la aplicación web, así como sus atributos y las interacciones entre estas.


\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_reporte_incidencia}
\captionof{figure}{Diagrama de Secuencia Detalle Reporte Incidencia }
 \label{fig:scaraindust}
\end{center}

El Administrador podrá consultar el reporte de incidencia de cada uno de los conductores. Accediendo a la base de de datos.
 

\begin{center}
  \includegraphics[scale=.7]{imagenes/sec_ubicacion}
\captionof{figure}{Diagrama de Secuencia Consultar Ubicación}
 \label{fig:scaraindust}
\end{center}

De igual manera, el Administrador podrá consultar la ubicación en tiempo real del conductor.
 
\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_rcontrasena}
\captionof{figure}{Diagrama de Secuencia Recuperar Contraseña }
 \label{fig:scaraindust}
\end{center}

También podrá recuperar su contraseña en caso de que esta sea olvidada.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_confirmar}
\captionof{figure}{Diagrama de Secuencia Confirmar Incidencia}
 \label{fig:scaraindust}
\end{center}

Para evitar falsos positivos, el Administrador podrá confirmar una incidencia una vez mirando el videoclip del incidente.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_perfil}
\captionof{figure}{Diagrama de Secuencia Consultar Perfil}
 \label{fig:scaraindust}
\end{center}
El Administrador podrá consultar el perfil de cada conductor. 

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_registrar}
\captionof{figure}{Diagrama de Secuencia Registrar Conductor }
 \label{fig:scaraindust}
\end{center}

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_modificar}
\captionof{figure}{Diagrama de Secuencia Modificar Conductor}
 \label{fig:scaraindust}
\end{center}

En caso de que los datos del conductor sean incorrectos, el administrador podrá modificarlos.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_eliminar}
\captionof{figure}{Diagrama de Secuencia Eliminar Conductor }
 \label{fig:scaraindust}
\end{center}

El Administrador también tendrá la opción de dar de baja a un conductor.

\begin{center}
  \includegraphics[scale=.6]{imagenes/sec_estado}
\captionof{figure}{Diagrama de Secuencia Estado de los Periféricos }
 \label{fig:scaraindust}
\end{center}

La aplicación web indicará si alguno de los periféricos no se encuentra en correcto funcionamiento, lanzando una alerta indicando el número de Unidad y a qué conductor pertenece.

A continuación se muestra el diseño propuesto de cada una de las vistas que tendrá la aplicación web.

\begin{center}
  \includegraphics[scale=.3]{imagenes/login}
\captionof{figure}{Página Inicio de Sesión }
 \label{fig:login}
\end{center}
En la Figura \ref{fig:login} se observa la página dónde el Administrador podrá iniciar sesión ingresando su correo y su contraseña.
 
\begin{center}
  \includegraphics[scale=.3]{imagenes/homescreen}
\captionof{figure}{Página Principal}
 \label{fig:homescreen}
\end{center}

En la Figura \ref{fig:homescreen} se muestra la página principal, dónde se muestran la lista de las incidencias, dónde cada una tendrá un estado de confirmada, rechazada, o pendiente de revisión. También se mostrarán una lista de todos los conductores para poder acceder al perfil de cada uno.

\begin{center}
  \includegraphics[scale=.3]{imagenes/profile}
\captionof{figure}{Página Perfil del Conductor }
 \label{fig:profile}
\end{center}

En la Figura \ref{fig:profile} se aprecia la página de perfil del conductor, que mostrará sus datos personales, así como una lista de todas las incidencias acumuladas.

\begin{center}
  \includegraphics[scale=.3]{imagenes/incident}
\captionof{figure}{Página Detalle de Incidencia }
 \label{fig:incident}
\end{center}

En al Figura \ref{fig:incident}, se puede observar la página desde dónde el administrador podrá revisar el videoclip de las incidencias de cada conductor. También cuenta con las opciones de confirmar o rechazar la incidencia dependiendo de cuál sea el caso.

\begin{center}
  \includegraphics[scale=.3]{imagenes/location}
\captionof{figure}{Página Ubicación en Tiempo Real }
 \label{fig:location}
\end{center}
 
 
En la Figura \ref{fig:location} se muestra la página web dónde el Administrador podrá consultar la ubicación de un conductor en tiempo real.


\subsubsection{Diseño de la Base de Datos}

DynamoDB es un servicio de base de datos NoSQL proporcionado por Amazon Web Services (AWS). Su modelo de datos difiere del modelo relacional tradicional y se basa en conceptos clave como tablas, índices y claves primarias. 

\begin{enumerate}
    \item \textbf{Tablas:}
    \begin{itemize}
        \item DynamoDB almacena datos en tablas. Cada tabla es un conjunto de ítems (datos) relacionados.
        \item Las tablas no tienen un esquema fijo; cada ítem en una tabla puede tener diferentes atributos.
    \end{itemize}
    
    \item \textbf{Atributos:}
    \begin{itemize}
        \item Cada ítem en una tabla es un conjunto de atributos. Los atributos son pares clave-valor.
        \item Los atributos pueden ser de diferentes tipos de datos, como texto, número, binario, lista y mapa.
    \end{itemize}
    
    \item \textbf{Claves Primarias:}
    \begin{itemize}
        \item Cada tabla en DynamoDB debe tener una clave primaria, que puede ser simple o compuesta.
        \item La clave primaria puede consistir en uno o dos atributos: la clave de partición y, opcionalmente, la clave de ordenación.
        \item La clave de partición determina la ubicación física de los datos en DynamoDB, mientras que la clave de ordenación ordena los ítems con la misma clave de partición.
    \end{itemize}
    
    \item \textbf{Índices:}
    \begin{itemize}
        \item DynamoDB admite índices locales y globales.
        \item Los índices locales están limitados a una única clave de partición y pueden tener una o varias claves de ordenación.
        \item Los índices globales pueden tener cualquier clave, ya sea solo de partición o compuesta de partición y ordenación.
    \end{itemize}
\end{enumerate}

\begin{verbatim}
{
  "TableName": "Conductores",
  "KeySchema": [
    { "AttributeName": "IDConductor", "KeyType": "HASH" }
  ],
  "AttributeDefinitions": [
    { "AttributeName": "IDConductor", "AttributeType": "N" },
    { "AttributeName": "Nombre", "AttributeType": "S" },
    { "AttributeName": "Apellido", "AttributeType": "S" },
    { "AttributeName": "Incidencias", "AttributeType": "N" },
    { "AttributeName": "ContadorEnMarcha", "AttributeType": "N" }
  ],
  "ProvisionedThroughput": {
    "ReadCapacityUnits": 5,
    "WriteCapacityUnits": 5
  }
}
\end{verbatim}

El modelo de la tabla para Conductores, se usará para registrar el nombre y apellido de cada conductor, así mismo se contabilizará el número de incidencias que presenté cada uno de ellos, el contador del conductor en marcha aumentará cada vez que el Módulo Central de Procesamiento envié un reporte de incidencia a la base de datos. Si el Usuario Administrador del Módulo de la Estación Base revisa el video de la incidencia y lo cataloga como Descartar entonces se restará la incidencia, si esta es catalogada como Confirmar, el contador permanecerá igual.  Es importante mencionar que el registro de cada conductor se realizará desde la Aplicación Web.

\begin{verbatim}
{
  "TableName": "Incidencias",
  "KeySchema": [
    { "AttributeName": "IdIncidencia", "KeyType": "HASH" }
  ],
  "AttributeDefinitions": [
    { "AttributeName": "IdIncidencia", "AttributeType": "N" },
    { "AttributeName": "IdConductor", "AttributeType": "N" },
    { "AttributeName": "FechaHora", "AttributeType": "S" },
    { "AttributeName": "NombreConductor", "AttributeType": "S" },
    { "AttributeName": "ApellidoConductor", "AttributeType": "S" },
    { "AttributeName": "EstadoIncidencia", "AttributeType": "S" }
  ],
  "ProvisionedThroughput": {
    "ReadCapacityUnits": 5,
    "WriteCapacityUnits": 5
  }
}

\end{verbatim}

El modelo de la tabla de Incidencias, se usará para registrar el Reporte de Incidencia que presente un conductor, el cual será enviado desde el Módulo Central de Procesamiento, por tanto, se realizará una consulta previa a la colección Conductores para obtener el id, nombre y apellido del conductor en marcha. Posteriormente se realizará el reporte de la incidencia, el cual contendrá el Id del conductor, la fecha y hora de la incidencia, el nombre y apellido del conductor, y el estado de incidencia, este último muestra si la incidencia fue catalogada como descartada o confirmada por parte del Usuario Administrador después de revisar el video de la incidencia.  

\textbf{Amazon Cognito \\}

Es una suite de herramientas que ofrece autenticación, autorización y administración de usuarios para aplicaciones móviles o web. Amazon Cognito utiliza dos componentes principales: los grupos de usuarios y grupos de identidades. Los grupos de usuarios se tratan de directorios que proporcionan a los usuarios de las aplicaciones opciones para inscribirse e iniciar sesión. Por otro lado, los grupos de indentidades conceden a los usuarios acceso a otros servicios de \emph{Amazon Web Services} 

A continuación se muestra el funcionamiento de Amazon Cognito

\begin{center}
  \includegraphics[scale=.5]{imagenes/cognito}
\captionof{figure}{Arquitectura Amazon Cognito}
 \label{fig:DocumentoIncidencias}
\end{center}

\begin{enumerate}
\item En primer lugar, el usuario inicia sesión a través de su respectivo grupo de usuarios y recibe \emph{tokens} de grupos de usuario despuées de una autenticación correcta.
\item Después, la aplicación intercambia dichos tokens del grupo de usuarios por las credenciales de AWS mediante un grupo de identidades.
\item Finalmente, el usuario puede utilizar estas credenciales de AWS para obtener acceso a otros servicios como Amazon S3.
\end{enumerate}

Amazon Cognito se encuentra disponible en varias regiones alrededor del mundo. \\

\textbf{Amazon S3 (\emph{Simple Storage Service})}

Amazon S3, es un servicio de almacenamiento de objetos en la nube. Es utilizado para almacenar datos en la nube de una forma segura, eficienta y escalable. Este servicio utiliza elementos llamados \emph{buckets}, que se encargan de almacenar objetos. Un objeto es un archivo o cualquier metadato que describa dicho archivo. Para almacenar datos en S3, primero se debe especificar el nombre de un bucket y la región dónde se planea que opere la aplicación. Esto con la intención de que el acceso a los datos se realice de manera eficiente.




\clearpage
\section{Implementación}

\subsection{Módulo Central de Procesamiento}

\subsubsection{Instalación del entorno de desarrollo en la NVIDIA Jetson Nano}

El Jetson Nano Developer Kit utiliza una tarjeta microSD como dispositivo de arranque y almacenamiento principal. Por tanto, fue necesario instalar un entorno de desarrollo en la propia placa, para lo cual se requirió una tarjeta microSD de un mínimo recomendado de 32 GB, según la documentación de Nvidia \cite{Nvidia}.\

Como primer paso, se descargó el \emph{JetPack SDK 4.6.3} \cite{JetPackSDK}, que es un archivo de imagen del sistema operativo específicamente diseñado y optimizado para ser utilizado en la placa de desarrollo NVIDIA Jetson Nano. La imagen incluye un sistema operativo Linux, controladores de hardware específicos para la Jetson Nano y una configuración predefinida. Para el presente proyecto, se utilizó la última versión disponible para la Jetson Nano 4GB, JetPack SDK 4.6.3 \cite{JetPackSDK}.\

Posteriormente, se instaló la imagen en la tarjeta microSD con el apoyo de BalenaEtcher 1.7.9, que se utilizó para crear una unidad de arranque.

\begin{center}
  \includegraphics[scale=0.6]{imagenes/Balena.JPG}
\captionof{figure}{Instalación del JetPack SDK realizado con BalenaEtcher.}
 \label{fig:BalenaEtcher} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.2]{imagenes/JNconexiones.jpeg}
\captionof{figure}{Periféricos de entrada para el Kit de desarrollo Jetson Nano.}
 \label{fig:JNconexiones} 
\end{center}  

\textbf{Configuración y primer arranque}\\

Para iniciar e interactuar con el kit de desarrollo, se requirió conectar un mouse, pantalla, teclado y una fuente de alimentación. Cabe mencionar que estos elementos no se incluyen con la compra del kit de desarrollo Jetson Nano. Posteriormente, se realizó la configuración inicial del sistema operativo, la cual incluyó los siguientes pasos:

\begin{itemize}
\item Revisar y aceptar el EULA del software NVIDIA Jetson.
\item Seleccionar el idioma del sistema, la distribución del teclado y la zona horaria.
\item Crear un nombre de usuario, contraseña y nombre de la computadora.
\item Seleccionar el tamaño de partición de la aplicación; se utilizó el tamaño máximo sugerido.
\end{itemize}

\textbf{Instalación de librerías y dependencias}\

Después de haber iniciado la Jetson Nano, se abrió una terminal y se ingresaron los siguientes comandos para la instalación de las librerías a utilizar:

\begin{enumerate}
\item Actualizar el sistema
\begin{verbatim}
sudo apt-get update 
sudo apt-get upgrade 
\end{verbatim}

\item dlib
\begin{verbatim}
pip3 install dlib
\end{verbatim}

\item boto3
\begin{verbatim}
sudo pip3 install boto3
\end{verbatim}

\item imutils
\begin{verbatim}
pip3 install imutils
\end{verbatim}

\item geocoder
\begin{verbatim}
pip3 install geocoder
\end{verbatim}

\item Tensorflow
En el caso de Tensorflow se debe instalar una versión compatible con Python 3.6 y la versión instalada del JetPack \cite{Tensorflow}.
\begin{verbatim}
sudo apt-get update
sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran
sudo apt-get install python3-pip
sudo pip3 install -U pip testresources setuptools
sudo ln -s /usr/include/locale.h /usr/include/xlocale.h
sudo pip3 install -U numpy==1.19.4 future mock keras_preprocessing keras_applications gast==0.2.1 protobuf pybind11 cython pkgconfig packaging
sudo pip3 install --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v461 tensorflow
\end{verbatim}

\item Keras
\begin{verbatim}
pip3 install keras==2.7.0
\end{verbatim}
\end{enumerate}

Se importaron las librerías con Python 3 para verificar que hayan sido correctamente instaladas.
\begin{center}
  \includegraphics[scale=0.6]{imagenes/librerias2.jpeg}
\captionof{figure}{Importación de librerías instaladas con Python.}
 \label{fig:Librerias} 
\end{center}  

Se instaló Jetson Stats, la cual es una herramienta de monitoreo del sistema que proporciona información de rendimiento de Jetson en tiempo real. Muestra información sobre el uso de la CPU, la GPU, la memoria y otros recursos del sistema. jtop muestra la salida de los monitores de energía Jetson y los sensores de temperatura \cite{JetStats}.
\\
Comandos usados para la instalación de Jetson Stats:

\begin{verbatim}
sudo apt install python3-pip
sudo pip3 install -U jetson-stats
sudo reboot
jtop
\end{verbatim}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/Jtop.jpeg}
\captionof{figure}{Interfaz despues de la instalación de Jetson Stats.}
 \label{fig:Jtop} 
\end{center}  

Archivo Swap

El swap es un espacio de intercambio, que bien puede ser una partición lógica en el disco o simplemente un archivo. En lugar de utilizar espacio en la memoria RAM, el swap utiliza espacio en el disco duro para almacenar datos temporales, reduciendo así el uso de la RAM. El conjunto combinado de la memoria RAM y el swap crea una memoria virtual mayor a la que trae el ordenador por defecto. Así, el Kernel de Linux puede ejecutar procesos que requieren más memoria de la que se encuentra físicamente disponible \cite{SwapFile}.
Comandos utilizados para configurar memoria virtual:

\begin{verbatim}
sudo systemctl disable nvzramconfig
sudo fallocate -l 4G /mnt/4G.swap
sudo mkswap /mnt/4G.swap
sudo swapon /mnt/4G.swap

cd ..
cd ..
cd etc/

sudo gedit fstab
\end{verbatim}

El comando gedit abre un archivo que se debe modificar añadiendo la siguiente línea y posteriormente guardando los cambios realizados.
\begin{verbatim}
/mnt/4G.swap	none	swap	sw	0	0
\end{verbatim}

Luego, se verificó el tamaño de todos los intercambios:
\begin{verbatim}
free -h
\end{verbatim}

Para habilitar la memoria zram de nuevo se utiliza el comando:
\begin{verbatim}
sudo systemctl enable nvzramconfig
\end{verbatim}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/swap.jpeg}
\captionof{figure}{verificación del archivo swap credo.}
 \label{fig:Swap} 
\end{center}  

OpenCV con CUDA (Arquitectura de dispositivo unificado de cómputo)
Por defecto, la versión del JetPack SDK 4.6.3 viene instalada con OpenCV 4.1.1 sin CUDA, el cual es un marco que permite la computación paralela en la GPU. Para activar CUDA, se utilizó el script proporcionado en el repositorio de GitHub \cite{CUDA}, el cual además instala la versión 4.5 de OpenCV:

\begin{verbatim}
git clone https://github.com/mdegans/nano_build_opencv.git
cd nano_build_opencv/
gedit build_opencv.sh
\end{verbatim}

El archivo se modificó colocando la variable JOBS=4 después de haber modificado el archivo de intercambio (\textit{swapfile}). Posteriormente, se ejecutó el archivo.

\begin{verbatim}
./build_opencv.sh 4.5.4
\end{verbatim}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/OpencvCuda.jpeg}
\captionof{figure}{Visualización de la instalación exitosa de OpenCV con Cuda en Jtop.}
 \label{fig:Swap} 
\end{center}  


\subsubsection{Implementar algoritmo para la detección del rostro y ojos }


\clearpage
\subsubsection{Implementar puntos faciales en el rostro y la metrica MOR}



\subsubsection{Integración de los periféricos y accesorios al Módulo Central de Procesamiento}


Se integraron los periféricos dentro del contenedor para la Jetson Nano.

El contenedor de la Jetson Nano es una carcasa de metal con un ventilador de refrigeración de 5 V, diseñado específicamente para ser compatible con la placa de desarrollo NVIDIA Jetson Nano (versión B01 con 4 GB de RAM).\\

Esta carcasa ofrece varias características adicionales, como soporte para reinicio de cámara, un botón de encendido y compatibilidad específica con la cámara Waveshare IMX219 Series. Además, el contenedor también tiene soporte para adaptadores inalámbricos Wireless-AC8265, lo que permite la conectividad Wi-Fi y Bluetooth en la Jetson Nano. Otra característica destacada es la compatibilidad con el módulo de placa de expansión LTE CAT4 basado en SIM7600G-H. Este módulo proporciona capacidades de comunicación inalámbrica, como llamadas telefónicas, mensajes de texto (SMS) y posicionamiento GPS utilizando los sistemas BeiDou y Glonass.

\begin{center}
  \includegraphics[scale=0.25]{imagenes/Perifericos1.jpeg}
\captionof{figure}{Carcasa sin armar}
 \label{fig:crearConductor} 
\end{center} 


Contenedor de la Jetson Nano junto con los periféricos integrados:

\begin{center}
  \includegraphics[scale=0.3]{imagenes/Perifericos2.jpeg}
\captionof{figure}{Carcasa armada con la Jetson Nano y periféricos integrados}
 \label{fig:crearConductor} 
\end{center} 

\newpage
\subsubsection{Aplicar el algoritmo de detección con el módulo central de procesamiento}

Se cargó el modelo de red neuronal convolucional (CNN) previamente entrenado para la detección de ojos cerrados y abiertos. sinembargo,debido a los recursos limitados de la jetson nano, los fps resultantes en tiempo real al correr el script fueron de 1 a 3 fps. Como resultado perdemos capturas por segundo del rostro que brindan información para la predicción en tiempo real. Por tanto se optó por una alternativa que utiliza menos recursos de la GPU para poder realizar más capturas por segundo y no perder información que permita detectar de una forma correcta los ojos y la boca del conductor y que a su vez permita medir la somnolencia.  
Se realizó una captura del video y se procedió a detectar el rostro del conductor, posteriormente se aplicó una malla de puntos faciales la cual nos permite tomar los puntos requeridos, en este caso se uso los puntos que referencian el ojo derecho, el ojo izquierdo y la boca para medir la distancia entre puntos y detectar si se encuentran abiertos o cerrados. Posteriormente se aplicó la logica que permite medir la duración de los parpadeos y bostezos, tomando en cuenta la duración se establecieron parámetros definidos que permitan detectar un posible caso de somnolencia. 

\begin{center}
  \includegraphics[scale=0.7]{imagenes/CodigoSomnolencia1.JPG}
\captionof{figure}{Código de somnolencia parte 1}
 \label{fig:Somnolencia1} 
\end{center}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/CodigoSomnolencia2.JPG}
\captionof{figure}{Código de somnolencia parte 2}
 \label{fig:Somnolencia1} 
\end{center}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/CodigoSomnolencia3.JPG}
\captionof{figure}{Código de somnolencia parte 3}
 \label{fig:Somnolencia1} 
\end{center}

\begin{center}
  \includegraphics[scale=0.6]{imagenes/CodigoSomnolencia4.JPG}
\captionof{figure}{Código de somnolencia parte 4}
 \label{fig:Somnolencia1} 
\end{center}

El archivo respecto a la métrica MOR \cite{68LandPoints}, se complementó con la grabación del video y el envió del video hacía la página web.

\begin{center}
  \includegraphics[scale=0.6]{imagenes/MORcodigo1.JPG}
\captionof{figure}{ Grabación del video y el envió del video hacía la página web}
 \label{fig:Somnolencia1} 
\end{center}

\begin{center}
  \includegraphics[scale=0.4]{imagenes/MOR2.jpeg}
\captionof{figure}{Prueba de la metrica MOR 1}
 \label{fig:crearConductor} 
\end{center} 


\begin{center}
  \includegraphics[scale=0.4]{imagenes/MOR1.jpeg}
\captionof{figure}{Prueba de la metrica MOR 2}
 \label{fig:crearConductor} 
\end{center} 



\subsection{Módulo de Comunicaciones}

\subsubsection{Investigación de la documentación del módulo 3G/4G LTE-Base Hat} \label{base_hat}

Para el presente proyecto, se hará uso del Base-Hat SIM7600G-H 4G para Jetson Nano. 

\begin{center}
  \includegraphics[scale=0.6]{imagenes/hat}
\captionof{figure}{Módulo Base-Hat SIM7600G-H}
 \label{fig:hat} 
\end{center} 

En primer lugar, utilizando la terminal del sistema operativo Ubuntu, se ingresan los siguientes comandos:

\begin{center}
  \includegraphics[scale=0.6]{imagenes/libraries}
\captionof{figure}{Instalación de librerías}
 \label{fig:libraries} 
\end{center} 

Los comandos ingresados en la figura \ref{fig:libraries} se encargan de instalar todas las bibliotecas y el software necesario para poder comenzar a utilizar la red LTE mediante el módulo SIM7600G-H. Además, también se crea un directorio que contendrá la configuración de usuario, así como una cuenta enlazada al módulo.

Posteriormente, probamos que el puerto GPIO de nuestra Jetson Nano esté funcionando con los siguientes comandos:

\begin{center}
  \includegraphics[scale=0.6]{imagenes/gpio}
\captionof{figure}{Instalación de librerías}
 \label{fig:gpio} 
\end{center}

Después de haber realizado los pasos anteriores, el pin con el nombre NET deberá parpadear constantemente, lo que significa que el módulo está listo para ser utilizado.

Para realizar la comunicación LTE, primero se ingresa a la librería minicom utilizando los siguientes comandos:
\begin{center}
  \includegraphics[scale=0.6]{imagenes/minicom}
\captionof{figure}{Minicom}
 \label{fig:gpio} 
\end{center}

Posteriormente, se necesita actualizar los drivers:

\begin{center}
  \includegraphics[scale=0.6]{imagenes/drivers}
\captionof{figure}{Actualización de drivers}
 \label{fig:gpio} 
\end{center}

Finalmente se establece una dirección IP con el siguiente comando:

\begin{center}
  \includegraphics[scale=0.6]{imagenes/modulo}
\captionof{figure}{Establecer dirección IP}
 \label{fig:gpio} 
\end{center}


\subsubsection{Implemetación del sistema de Geolocalización}
\textbf{Habilitar GPS y obtener datos de posición GPS desde la Jetson Nano \cite{Waveshare}}

Se inicia abriendo una terminal e instalando bibliotecas con los siguientes comandos.

Se remplaza your\_user\_name con el nombre de usuario nano.

\begin{center}
  \includegraphics[scale=0.9]{imagenes/SIM7600G-1.JPG}
\captionof{figure}{Intalaci?n de bibliotecas}
 \label{fig:SIM7600G-1.JPG} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.9]{imagenes/SIM7600G-2.JPG}
\captionof{figure}{Instalaci?n de comandos}
 \label{fig:SIM7600G-2.JPG} 
\end{center} 

Se coloca el DIP en ON y se ejecuta minicom con el comando AT para probar el SIM7600.

\begin{center}
  \includegraphics[scale=0.9]{imagenes/SIM7600G-3.JPG}
\captionof{figure}{ Prueba de SIM7600G }
 \label{fig:SIM7600G-3.JPG} 
\end{center} 

Ejemplo de GPS: Se conectó la antena GPS y se colocó el receptor en un lugar abierto. Se ejecutaron los siguientes comandos para probar el GPS.

\begin{center}
  \includegraphics[scale=0.9]{imagenes/SIM7600G-4.JPG}
\captionof{figure}{Comandos GPS para pruebas.}
 \label{fig:SIM7600G-4.JPG} 
\end{center} 

Comunicación por Minicom:

Para obtener los datos de posición GPS, fue necesario interactuar con el módulo SIM7600X a través del programa en Python:

\begin{center}
  \includegraphics[scale=0.62]{imagenes/GPSpy1.JPG}
\captionof{figure}{C?digo que permite obtener la posición GPS parte 1}
 \label{fig:GPSpy1} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.62]{imagenes/GPSpy2.JPG}
\captionof{figure}{Código que permite obtener la posición GPS parte 2}
 \label{fig:GPSpy2} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.62]{imagenes/GPSpy3.JPG}
\captionof{figure}{C?digo que permite oibtener la posici+on GPS parte 3}
 \label{fig:GPSpy3} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.7]{imagenes/GPSpy4.JPG}
\captionof{figure}{Código que permite obtener la posición GPS parte 4}
 \label{fig:GPSpy4} 
\end{center} 

\textbf{AWS Maps}\\

AWS Maps es un servicio de Amazon Web Services que proporciona capacidades de mapas y geolocalización en la nube. Permite crear, visualizar y analizar datos geoespaciales en aplicaciones y servicios.
\\
Se creó un mapa en AWS Maps donde se configuró la apariencia y funcionalidad del mismo, incluyendo los estilos de visualización, las capas de datos y las interacciones del usuario. El propósito de este mapa es mostrar información geográfica, como ubicaciones, rutas, geovallas, puntos de interés, entre otros. La configuración del mapa permitió personalizar su aspecto y adaptarlo a las necesidades del proyecto.\\

Para crear el mapa, se inició sesión en la Consola de administración de AWS. Luego, se accedió a la página de AWS Maps Service en la consola de administración. A continuación, se hizo clic en "Crear mapa" para comenzar a crearlo. En el proceso de creación, se seleccionó un nombre para el mapa y se especificó la región de AWS donde se deseaba crearlo. Seguidamente, se eligió el estilo de mapa y posteriormente se configuraron las capas del mapa, pudiendo agregar capas para mostrar datos como carreteras, edificios, ríos, y también se pudieron agregar datos geoespaciales personalizados como capas personalizadas. Finalmente, se creó el mapa.\\

Una vez creado el mapa en AWS Maps, se agregó y configuró un rastreador para realizar el seguimiento del dispositivo llamado "mydevice" en el mapa. Los rastreadores se encargaron de recopilar y actualizar la ubicación de los dispositivos, brindando información en tiempo real.\\

A continuación, se presenta un resumen de cómo se creó un rastreador en AWS Maps:\\

En la página del mapa en la consola de administración de AWS Maps, se hizo clic en "Crear rastreador". Se seleccionó un nombre para el rastreador y se especificó la región de AWS donde se deseaba crearlo. Se procedió a configurar los detalles del rastreador, como la frecuencia de actualización de la ubicación de los dispositivos, en este caso, cada 10 minutos se envían las coordenadas. Finalmente, se hizo clic en "Crear rastreador" para finalizar la configuración del mismo.


\begin{center}
  \includegraphics[scale=0.55]{imagenes/Mymapaws.png}
\captionof{figure}{Mapa creado en AWS - MyMap}
 \label{fig:Mymapa} 
\end{center} 


\textbf{Ubicación geográfica en la Aplicación web}\\

Para obtener el historial de posiciones de un dispositivo, se definió la función llamada "getDevicePosition". Posteriormente, se utilizó la función "client.getDevicePositionHistory" con el argumento "params" para solicitar el historial de posiciones del dispositivo. Después, se creó la variable "tempPosMarkers" para almacenar los resultados obtenidos al mapear los elementos de "data.DevicePositions". Para cada elemento "devPos" en "data.DevicePositions", se imprimió su posición en la consola y se generó un nuevo objeto con propiedades "index", "Long" y "lat", que representaban los valores de la posición del dispositivo. Este archivo se guardó con la extensión .jsx.

\begin{center}
  \includegraphics[scale=0.35]{imagenes/RealTimeMap}
\captionof{figure}{Código para obtener la ubicación geográfica en la aplicación web}
 \label{fig:RealTimeMap} 
\end{center} 

Obtención de coordenadas geográficas desde la Jetson Nano 

\begin{center}
  \includegraphics[scale=0.53]{imagenes/Mymapaws2.png}
\captionof{figure}{Coordenadas geográficas en la Jetson Nano}
 \label{fig:Mymapadet} 
\end{center} 


Mapa creado en AWS Maps 

\begin{center}
  \includegraphics[scale=0.53]{imagenes/Mymapaws2.png}
\captionof{figure}{Detalles del mapa creado en AWS}
 \label{fig:Mymapadet} 
\end{center} 


coordenadas geográficas que recibe la página web 

\begin{center}
  \includegraphics[scale=1]{imagenes/RealTimeMap2}
\captionof{figure}{Coordenadas geográficas que recibe la página web }
 \label{fig:CorGeo} 
\end{center} 


\subsubsection{Conexión de la aplicación web con el Módulo Central de Procesamiento}
La primer configuración que se realiza, fue la habilitación y activación de la red 4G Lte en la Jetson Nano por medio de la interfaz wwan0 \cite{Waveshare} , que nos permite conectarnos a internet por medio de la red celular, se utiliza una SIM Telcel para adquirir GB y poder acceder a internet.\\

Se abre una terminal y se ejecutaron los siguinete comandos para abrir minicom por comando:

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte1.JPG}
\captionof{figure}{Abrir minicom por comando.}
 \label{fig:4glte1} 
\end{center} 


El siguiente comando se utiliza para verificar la conexión.

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte2.JPG}
\captionof{figure}{Verificar conexión.}
 \label{fig:4glte2} 
\end{center} 

Posteriormente se descarga el controlador con los siguinetes comandos:

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte3.JPG}
\captionof{figure}{Descarga del driver.}
 \label{fig:4glte3} 
\end{center} 

Se usa el permiso de root para instalar el controlador:

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte4.JPG}
\captionof{figure}{Instalar driver.}
 \label{fig:4glte4} 
\end{center} 

Se comprobueba si se reconoce la interfaz wwan0.

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte5.JPG}
\captionof{figure}{Comando para comprobar interfaz wwan0.}
 \label{fig:4glte5} 
\end{center} 

Se habilita la interfaz wwan0.

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte6.JPG}
\captionof{figure}{Habilitar la interfaz wwan0.}
 \label{fig:4glte6} 
\end{center} 

Se realiza la comunicación por Minicom:

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte7.JPG}
\captionof{figure}{Comunicar por Minicom.}
 \label{fig:4glte7} 
\end{center} 

Se asigna la IP:

\begin{center}
  \includegraphics[scale=0.9]{imagenes/4glte8.JPG}
\captionof{figure}{Asignar IP.}
 \label{fig:4glte8} 
\end{center} 


Posteriormente se realiza la conexión del Módulo Central de Procesamiento y la aplicaciónn web, se utiliza la librería \textbf{Boto3}\\

Boto3 es una biblioteca de Python desarrollada por Amazon Web Services (AWS) que permite interactuar con los servicios de AWS. Proporciona una interfaz de programación de aplicaciones (API) fácil de usar para acceder y administrar recursos en la nube de AWS \cite{Boto3}.\\

Para crear una conexión a AWS Amplify utilizando Boto3, se siguieron los siguientes pasos :\\

En primer lugar, se instalá Boto3 utilizando el comando: \emph{pip install boto3}. A continuación, se configuraron las credenciales de AWS, proporcionando las claves de acceso de IAM que otorgan acceso a los servicios de AWS. Estas credenciales se configuraron manualmente en el archivo de configuración. Luego, se importa el módulo Boto3 en el script de Python y se crea una conexión al servicio de AWS Amplify utilizando las credenciales configuradas anteriormente. A partir de la conexión establecida, se pudieron utilizar los métodos proporcionados por el cliente de Boto3 para interactuar con AWS Amplify.

ed 4G LTE activa en la Jetson Nano

\begin{center}
  \includegraphics[scale=0.6]{imagenes/4glte.jpeg}
\captionof{figure}{Red 4G LTE activa por medio de la interfaz wwan0}
 \label{fig:4GLTE} 
\end{center} 

Conexión a AWS Amplify utilizando Boto3

\begin{center}
  \includegraphics[scale=0.87]{imagenes/ConexionPw.JPG}
\captionof{figure}{Conexión con boto3 hacía AWS}
 \label{fig:addstorage} 
\end{center} 


\newpage

\subsection{Módulo de Estación Base}

\subsubsection{Definición de rutas del frontend}

\textbf{Rutas públicas vs rutas protegidas}

Cuando se habla de una ruta protegida en React, se referiere a programar un bloqueo en ciertas rutas a la cual se le restringe el acceso al usuario. Esto comunmente se realiza para la validación de inicio de sesión de usuarios. Sí el usuario no tiene una sesión iniciada, no podrá acceder a las rutas protegidas de la aplicación. Por otro lado, las rutas públicas son todas aquellas las cuales no requieren contar con una sesión iniciada, y pueden ser accesadas por cualquier tipo de usuario\cite{dom}.


Como primer paso, se creo un proyecto de React utilizando el siguiente comando:


\begin{center}
  \includegraphics[scale=0.5]{imagenes/create}
\captionof{figure}{Creación proyecto de react}
 \label{fig:MongoA} 
\end{center} 


Posteriomente, se realizó la instalación del modelo \emph{React Router Dom} utilizando el siguiente comando:

\begin{center}
  \includegraphics[scale=0.5]{imagenes/router}
\captionof{figure}{Instalación React Router DOM}
 \label{fig:MongoA} 
\end{center} 

Utilizando la librería \emph{useAuthenticator} ofrecida por el paquete de React Dom se creó un archivo de nombre \emph{RequireAuth.js} el cuál contiene una función la cual se encargará de validar si existe una sesión iniciada previamente.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/auth}
\captionof{figure}{Función RequireAuth}
 \label{fig:auth} 
\end{center} 

Posteriormente, se necesita contar con una página de Login, la cuál permite validar que se encuentre una sesión inciada por parte del usuario, para así poder acceder a las rutas protegidas.

\begin{center}
  \includegraphics[scale=0.6]{imagenes/loginjs}
\captionof{figure}{Componente Login}
 \label{fig:loginjs} 
\end{center} 


Para indicar a React, que se desea implementar una ruta protegida, se necesita ir al componente de dicha ruta e ingresar el siguiente código:


\begin{center}
  \includegraphics[scale=0.5]{imagenes/homejs}
\captionof{figure}{Ruta protegida del componente Home}
 \label{fig:homejs} 
\end{center} 

En dicho componente, se hace uso de las librerías \emph{useAuthenticator} y \emph{Authenticator} las cuales son ofrecidas por los servicios de Amazon Amplify. Se realizó esto para todos los componentes que se requirieron mantener como rutas protegidas.


Finalmente, dentro de nuestro componente \textbf{App.js}, se creó una función que contiene el directorio de rutas tanto públicas como protegidas:

\begin{center}
  \includegraphics[scale=0.5]{imagenes/routesjs}
\captionof{figure}{Directorio de rutas}
 \label{fig:routesjs} 
\end{center} 

Las rutas protedigas, están dentro de las etiquetas \textbf{<RequireAuth></RequireAuth>}, mientras que las públicas, se encuentran dentro de las etiquetas \textbf{<Route></Route>}.


Como resultado de todo lo anterior, se obtuvo una página de Login que utilizando los servicios de AWS Amplify y Cognito, permitirá iniciar sesión así como registrar a nuevos usuarios.

\begin{center}
  \includegraphics[scale=0.4]{imagenes/loginpage}
\captionof{figure}{Página de Login}
 \label{fig:loginpage} 
\end{center} 

Si intentamos ingresar a las paginas de Conductores, Incidencias o Ubicacion, nos redigirá a la página de Login, debido a que estas páginas fueron definidas como rutas protegidas. Por lo tanto el usuario debe haber inciado sesión para poder acceder a las mismas.


\begin{itemize}
\item \textbf{Path:} "/\\ \textbf{Descripción:} En esta dirección se encontrará la el formulario para poder iniciar sesión o registrarse

\item \textbf{Path:} "/home \\  \textbf{Descripción:} Esta dirección será la página principal de la aplicación dónde se mostrarán las incidencias más recientes así como una lista de todos los conductores

\item \textbf{Path:} "/conductor/\\ \textbf{Descripción:} Esta dirección mostrará el perfil del conductor de id correspondiente

\item \textbf{Path:} "/detalle\textunderscore incidencia \\ \textbf{Descripción:} Esta dirección mostrará cada incidencia mostrando detalles como hora, fecha, coordenadas

\item \textbf{Path:}  "/conductor/id/ubicacion \\ \textbf{Descripción:} En esta vista se mostrará la ubicación en tiempo real de cada conductor


\item \textbf{Path:} "/conductor/id/incidencias \\ \textbf{Descripción:} En esta vista se mostrará todas las incidencias registradas por cada conductor

\end{itemize}


\newpage

\subsubsection{Definición de rutas del backend}

La creación de rutas mediante las que el cliente realizará las peticiones y tendrá acceso a las operaciones, así como su funcionamiento en cuanto a obtención de datos y comunicación con el resto de la aplicación.

Para poder utilizar los servicios de Amazon Amplify, es necesario ir al directorio root del proyecto y ejectutar el siguiente comando:

\begin{center}
  \includegraphics[scale=0.6]{imagenes/cli}
\captionof{figure}{Instalación Amplify CLI}
 \label{fig:MongoA} 
\end{center} 

Posteriormente, se necesita especificar la región en la cual queremos alojar nuestra aplicación web:

\begin{center}
  \includegraphics[scale=0.6]{imagenes/region}
\captionof{figure}{Configuración del proyecto}
 \label{fig:MongoA} 
\end{center} 


Utilizando un editor de código, se necesita especificar que estará utilizando el \emph{SDK} de Amazon Amplify:

\begin{center}
  \includegraphics[scale=0.55]{imagenes/sdk}
\captionof{figure}{Implementación del SDK de Amplify}
 \label{fig:MongoA} 
\end{center} 

Posteriormente, declaramos una aplicación de ExpressJs la cuál nos permitirá ejecutar entre otras cosas, peticiones HTTP para la comunicación con la base de datos.

\begin{center}
  \includegraphics[scale=0.55]{imagenes/expressjs}
\captionof{figure}{Creación de aplicación de Express}
 \label{fig:MongoA} 
\end{center} 

Finalmente, se necesitan definir las rutas de las APIs que se estarán utilizando en el proyecto, las cuales serán dos, la primera se encargará de la aplicación web, y la segunda de realizar la comunicación con el Módulo Central de Procesamiento.

Para agregar una api, se necesita ejecutar el siguiente comando desde el directorio raíz del proyecto.


\begin{center}
  \includegraphics[scale=0.55]{imagenes/addapi}
\captionof{figure}{Amplify add api}
 \label{fig:MongoA} 
\end{center} 

La consola de AWS Amplify requiere introducir parámetros con los cuales serán construida nuestra API, para el presente proyecto se estará utilizando una arquitectura mediante GraphQL, por lo cual seleccionaremos dicha opción.

\begin{center}
  \includegraphics[scale=0.4]{imagenes/graphql}
\captionof{figure}{Configuración de parámetros de GraphQL}
 \label{fig:MongoA} 
\end{center} 

Antes de poder publicar nuestra API en AWS Amplify, se necesita definir el Schema con el cuál se hará el manejo de datos. A contiuación se muestran dichos schemas:

\begin{center}
  \includegraphics[scale=0.55]{imagenes/schema}
\captionof{figure}{Definición de Schemas para el manejo de datos}
 \label{fig:MongoA} 
\end{center} 

Finalmente, ejecutaremos el comando \emph{amplify push}, el cuál publicará la API hacáa AWS amplify, generando el endpoint correspondiente a dicha API

Como resultado, tenemos el endpoint de nuestro modelo de GraphQL y nuestra API Key generada por Amplify

\begin{center}
  \includegraphics[scale=0.55]{imagenes/endpoints}
\captionof{figure}{Generación de Endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center} 

\subsubsection{Creación de la base de datos no relacional}

Debido a problemas de integración junto con los servicios de autenticación y de despliegue de Amplify, se decidió utilizar el sistema de gestión de bases de datos DynamoDB.

DynamoDB es un servicio de base de datos NoSQL Ofrecido por Amazon Web Services. DynamoDB trabaja con tablas. Estas a su vez, contienen parámetros importantes que se mencionarón a continuación.



\begin{itemize}
\item \textbf{\emph{Primary Key}}: Se trada de una clave primaria simple, compuesta por un solo atributo denominado clave de partición. Una clave primaria puede ser una clave de partición o una combinación de clave de partición y clave de ordenación. La clave primaria debe ser única en toda la tabla.
\begin{itemize}
\item \textbf{\emph{Parition Key}}: Es la llave principal por la cual se agruparán los datos, y determina cómo se particiona la información.

\item \textbf{\emph{Sort Key}}: Es llave de ordenamiento de los datos.

\end{itemize}

\end{itemize}

\begin{center}
  \includegraphics[scale=0.5]{imagenes/dynamo}
\captionof{figure}{Tablas en DynamoDB}
 \label{fig:cognito} 
\end{center} 


DynamoDB almacena los datos como grupos de atributos, conocidos como elementos. Los elementos son similares a las filas o registros de otros sistemas de bases de datos. DynamoDB almacena y recupera cada elemento en función del valor de la clave principal, que debe ser único.

DynamoDB utiliza el valor de la clave de partición como parámetro de entrada para una función hash interna. El resultado de la función hash determina la partición en la que se almacena el elemento. La ubicación de cada elemento viene determinada por el valor hash de su clave de partición

Todos los elementos con la misma clave de partición se almacenan juntos y, para las claves de partición compuestas, se ordenan por el valor de la clave de ordenación. DynamoDB divide las particiones por clave de ordenación si el tamaño de la colección crece más de 10 GB\cite{dynamo}.


Crear la base de datos en MongoDB.


Para crear nuestras tablas de DynamoDB, se debe ingresar a la consola de AWS.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/aws}
\captionof{figure}{Consola de AWS}
 \label{fig:cognito} 
\end{center} 


Una vez dentro, ingresamos a la sección del servicio de DynamoDB


\begin{center}
  \includegraphics[scale=0.5]{imagenes/tables}
\captionof{figure}{Tablas generadas mediante los schemas definidos}
 \label{fig:cognito} 
\end{center} 

Como se puede observar, gracias a los pasos realizados en la sección \ref{Backend}, DynamoDB crea automáticamente las tablas creadas en base a los schemas definidos previamente.

\subsubsection{Conexión backend con la base de datos}

Realizar la conexión de NodeJs con la base de datos MongoDb.


Para realizar la conexión y la integración de los servicios de DynamoDB hacáa nuestra API, se hará uso de AppSync. Las API de GraphQL creadas con AWS AppSync brindan a los desarrolladores frontend la capacidad de consultar varias bases de datos, microservicios y API desde un único punto de conexión de GraphQL. 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/appsync}
\captionof{figure}{Funcionamiento de Appsync}
 \label{fig:MongoA} 
\end{center} 

AWS AppSync crea las API sin servidor de GraphQL y de publicación o suscripción que simplifican el desarrollo de aplicaciones a través de un único punto de conexión para consultar, actualizar o publicar datos.



Despues de haber realizado los pasos de la sección \ref{Backend}, si ejecutamos el comando \emph{amplify status}, la consola de Amplify nos retornara el endpoint de GraphQL junto con AppSync correspondiente, el cuál se utilizará para realizar todas las operaciones con respecto al almacenamiento de datos

\begin{center}
  \includegraphics[scale=0.55]{imagenes/appsyncendpoint}
\captionof{figure}{Generación de endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center} 



\subsubsection{Sistema de acceso con credenciales}

\textbf{Definición del Esquema}

\begin{center}
  \includegraphics[scale=.2]{imagenes/as}
\captionof{figure}{Arquitectura Amazon Cognito}
 \label{fig:DocumentoIncidencias}
\end{center}

\emph{Implementación del sistema de acceso con credennciales}

Para el sistema de autenticación, se utilizará Amazon Cognito.


Para poder hacer uso de Amazon Cognito en nuestra aplicación debemos de introducir el siguiente comando:

\begin{center}
  \includegraphics[scale=0.7]{imagenes/add}
\captionof{figure}{Implementación de Amazon Cognito en el proyecto}
 \label{fig:cognito} 
\end{center} 

Obteniendo el siguiente menú:

\begin{center}
  \includegraphics[scale=0.5]{imagenes/menu}
\captionof{figure}{Menu de configuración de Amazon Cognito}
 \label{fig:cognito} 
\end{center} 


\begin{center}
  \includegraphics[scale=0.5]{imagenes/console}
\captionof{figure}{Implementación completada}
 \label{fig:cognito} 
\end{center} 

Entrando a nuestra consola de AWS, en la sección de Amazon Cognito, se puede observar dos grupos de usuarios, uno de tipo Administrador, el cual puede realizar cambios a la configuración de la aplicación, y otro de tipo de Usuario, el cual sólo puede hacer uso del sistema de inició de sesión y registro ofrecido por Cognito.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/pools}
\captionof{figure}{Grupos de usuario}
 \label{fig:cognito} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/admin}
\captionof{figure}{Grupos de usuario}
 \label{fig:cognito} 
\end{center} 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/users}
\captionof{figure}{Grupos de usuario}
 \label{fig:cognito} 
\end{center} 

\subsubsection{Creación de los servicios backend}

Para comenzar con el archivo de \emph{Queries}se tienen las siguientes funciones:

\begin{center}
  \includegraphics[scale=0.5]{imagenes/getconductor}
\captionof{figure}{Función getConductor}
 \label{fig:getConductor} 
\end{center}

La función de la figura \ref{getConductor}, obtiene los datos de un solo Conductor.


\begin{center}
  \includegraphics[scale=0.5]{imagenes/listconductors}
\captionof{figure}{Función listConductors}
 \label{fig:listConductors} 
\end{center}

La función de la figura \ref{fig:listConductors} obtiene todos los datos de todos los conductores almacenados en la base de datos.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/getincidencia}
\captionof{figure}{Función getIncidencia}
 \label{fig:getIncidencia} 
\end{center}

La función de la figura \ref{fig:getIncidencia} obtiene los datos de una sola Incidencia.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/listIncidencias}
\captionof{figure}{Función listIncidencias}
 \label{fig:listIncidencias} 
\end{center}

La función de la figura \ref{fig:listIncidencias} obtiene los datos de todas las incidencias de almacenadas en la base de datos.

En cuanto al archivo de \emph{Mutations} se tienen las siguientes funciones:

\begin{center}
  \includegraphics[scale=0.5]{imagenes/createconductor}
\captionof{figure}{Función createConductor}
 \label{fig:createConductor} 
\end{center}

La función de la figura \ref{fig:createConductor} se encarga de crear el registro de un conductor en la base de datos.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/updateConductor}
\captionof{figure}{Función updateConductor}
 \label{fig:updateConductor} 
\end{center}

La función de la figura \ref{fig:updateConductor} se encarga de modificar datos del registro de un conductor.


\begin{center}
  \includegraphics[scale=0.5]{imagenes/deleteconductor}
\captionof{figure}{Función deleteConductor}
 \label{fig:deleteConductor} 
\end{center}

La función de la figura \ref{fig:deleteConductor} se encarga de eliminar un conductor de la base de datos.


\begin{center}
  \includegraphics[scale=0.5]{imagenes/createIncidencia}
\captionof{figure}{Función createIncidencia}
 \label{fig:createIncidencia} 
\end{center}

La función de la figura \ref{fig:createIncidencia} se encarga de crear una Incidencia en la base de datos.

Para el archivo de \emph{subscriptions} se tienen la siguiente función:

\begin{center}
  \includegraphics[scale=0.5]{imagenes/oncreateIncidencia}
\captionof{figure}{Función oncreateIncidencia}
 \label{fig:oncreateIncidencia} 
\end{center}	

La función de la figura \ref{fig:oncreateIncidencia} se encarga de realizar una consulta cada vez que una Incidencia nueva es dada de alta en la base de datos.



Al estar trabajando con GraphQL dentro del proyecto, la manera en que se podrán realizar las operaciones \emph{CRUD - (Create, Read, Update, Delete)}, será mediante funciones JSON.

Para comprobar que la API permite dichas operaciones, se debe ingresar a la consola de AWS y dirigirse a la sección de AWS AppSync. 

\begin{center}
  \includegraphics[scale=0.4]{imagenes/consola}
\captionof{figure}{Consola de AWS}
 \label{fig:awsconsole} 
\end{center} 

Posteriormente se necesita ingresar a la sección de consultas.


\begin{center}
  \includegraphics[scale=0.4]{imagenes/funciones}
\captionof{figure}{Funcionamiento de Appsync}
 \label{fig:MongoA} 
\end{center} 


AWS permite elegir si realizar un \emph{query}, \emph{mutation}, o \emph{subscription} mediante código JSON

\begin{center}
  \includegraphics[scale=0.4]{imagenes/crear}
\captionof{figure}{Crear Conductor}
 \label{fig:crearConductor} 
\end{center} 

En la figura \ref{fig:crearConductor} se puede apreciar una sentencia JSON que permite utilizar las funciones previamente creadas para dar de alta un conductor.

\clearpage
\subsubsection{Maquetación web}
\textbf{ReactJs}

Para el desarrollo del front-end del presente proyecto, se hará uso de la librería de diseño de ReactJs. ReactJs facilia la creación de componentes reutilizables e interactivos para las interfaces de usuario.

Los componentes que darán lugar a las vistas del presente proyecto son los siguientes:

\begin{itemize}

\item Layout.jsx: Este componente será la vista principal de la Aplicación Web. Se trata de un diseño tipo \emph{dashboard} que contendrá una sección principal que contendrá etiquetas para poder ingresar a las diferentes vistas de la aplicación. Además estará compuesta también de una sección secundaría que mostrará el contenido de dichas vistas.

\item Incidencias.jsx: Este componente se encargará de mostrar todas las incidencias registradas en la base de datos. Las incidencias serán desplegadas en forma de lista.


\item Incidencias.jsx: Este componente de mostrar un reporte de incidencia a detalle. Contendrá una ventana que permitirá ver el video del momento de la incidencia registrada. Así como los datos de la fecha y hora. Además de botones para poder confirmar o rechazar la incidencia. Finalmente contendrá el nombre del conductor además de una opción para poder consultar la ubicación en tiempo real del conductor.

\item Ubicación.jsx: Este componente mostrará la ubicación en tiempo real del conductor con ayuda del servicio de diseño de mapas Leaflet.

\item Conductores.jsx: Este componente mostrará todos los conductores registrados en la base de datos en forma de lista. 

\end{itemize}

De acuerdo con los componentes explicados anteriormente, las vistas que contendrá la aplicación web son las siguientes:

\begin{itemize}

\item Página Principal
\begin{center}
  \includegraphics[scale=0.3]{imagenes/principal}
\captionof{figure}{Página Principal - Layout.jsx}
 \label{fig:vista_principal} 
\end{center} 

\item Reporte de Incidencia
	
\begin{center}
  \includegraphics[scale=0.5]{imagenes/incidencia}
\captionof{figure}{Vista Reporte Incidencia Incidencia - Incidencia.jsx}
 \label{fig:vista_incidencia} 
\end{center} 

\item Ubicación

\begin{center}
  \includegraphics[scale=0.4]{imagenes/ubicacion}
\captionof{figure}{Vista Ubicacion}
 \label{fig:vista_ubicacion} 
\end{center} 

\item Conductores

\begin{center}
  \includegraphics[scale=0.3]{imagenes/conductores}
\captionof{figure}{Vista Conductores - Conductores.jsx}
 \label{fig:vista_conductores} 
\end{center} 



\end{itemize}
\clearpage
\subsubsection{Enlace de Amazon S3 con el sistema backend}

Utilizando un editor de código, y desde el directorio raíz de la aplicación, se deberá introducir el siguiente comando:

\begin{center}
  \includegraphics[scale=0.55]{imagenes/addstorage}
\captionof{figure}{Configuración de servicio de almacenamiento S3}
 \label{fig:addstorage} 
\end{center} 

Posteriormente, se requiere especificar que tipo de servicio de almacenamiento se integrará a la aplicación (multimedia o base de datos NoSQL). Para el presente proyecto, se utilizará el almacenamiento de contenido multimedia, por lo tanto, se seleccionará dicha opción.

\begin{center}
  \includegraphics[scale=0.55]{imagenes/content}
\captionof{figure}{Generación de Endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center} 

Ingresamos el nombre de nuestro espacio de almacenamiento:

\begin{center}
  \includegraphics[scale=0.55]{imagenes/name}
\captionof{figure}{Generación de Endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center}

Después, se necesita establecer cuantos usuarios, así como cuales podrán acceder a dicho servicio:

\begin{center}
  \includegraphics[scale=0.55]{imagenes/rules}
\captionof{figure}{Generación de Endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center}


\begin{center}
  \includegraphics[scale=0.55]{imagenes/rulesauth}
\captionof{figure}{Generación de Endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center}

\begin{center}
  \includegraphics[scale=0.55]{imagenes/guestrules}
\captionof{figure}{Generación de Endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center}

\begin{center}
  \includegraphics[scale=0.55]{imagenes/push}
\captionof{figure}{Generación de Endpoint de GraphQL}
 \label{fig:MongoA} 
\end{center}

Al ingresar a la consola de servicios de AWS, en la sección de buckets de S3, se puede observar que se encuentra el bucket recién creado llamado \emph{videos175126-dev}.


\begin{center}
  \includegraphics[scale=0.5]{imagenes/buckets}
\captionof{figure}{Tablas generadas mediante los schemas definidos}
 \label{fig:cognito} 
\end{center} 

\clearpage

\subsubsection{Despliegue de la aplicación web}

Para poder alojar y desplegar la aplicación web en un servicio de \emph{hosting}, se utilizará Amplify Hosting \cite{AwsAmplify}.	

Se necesita ingresar a la consola de AWS y seleccionar el servicio de Amplify Hosting

\begin{center}
  \includegraphics[scale=0.5]{imagenes/hosting}
\captionof{figure}{Amplify Hosting
}
 \label{fig:hat} 
\end{center} 


Hosting requiere alguna fuente de alojamiento de código para poder desplegar la apliación web. En este caso, la aplicación web fue alojada utilizando \emph{Github}, por lo tanto, se selecciona esta opción.

Posteriormente, se requiere seleccionar el repositorio el cual será alojado, en este caso, el nombre de dicho repositorio es \emph{eb}. A su vez, se selecciona la ramificación \emph{main} para ser desplegada.

\begin{center}
  \includegraphics[scale=0.5]{imagenes/repo}
\captionof{figure}{ramificación de repositorio de Github}
 \label{fig:libraries} 
\end{center} 

\textbf{Resultados}
Acceso a la pagina web desde el buscador con la siguiente URL: \\
https://main.dcst1c83llut3.amplifyapp.com/login

\begin{center}
  \includegraphics[scale=.45]{imagenes/paginaweb.JPG}
\captionof{figure}{Acceso a la página web desde el navegador}
 \label{fig:libraries} 
\end{center} 


\newpage



\newpage





\newpage

\section{Pruebas}

\newpage

\section{Validación}



\subsubsection{Resultados}



\newpage


\section{Conclusion y aportaciones}

Con base en los objetivos planteados, se llevó a cabo el diseño y análisis del sistema utilizando la metodología en espiral, que implica un enfoque iterativo y progresivo en el desarrollo. El sistema se dividió en módulos y submódulos, permitiendo un enfoque más detallado en cada uno de ellos. Esta aproximación ayudó a definir los elementos y algoritmos necesarios para la implementación del sistema. En este trabajo, se presentan los resultados de las investigaciones que para la elección de los elementos principales del sistema y, posteriormente, los resultados del diseño de cada módulo propuesto.\\

En el Submódulo de Visión Artificial, se logró la detección del rostro, los ojos y la boca, seguida de la clasificación de la somnolencia. Este proceso consideró la apertura de los ojos y la boca, así como la duración de dichos estados. La utilización de dlib para la detección facial y la relación MOR y EOR a través de puntos de referencia faciales contribuyeron a la implementación para el reconocimiento de signos de somnolencia.\\

En cuanto a la comunicación y transferencia de archivos, se optó por el módulo SIM7600G para Jetson Nano, que integra GNSS para el posicionamiento GPS. La conectividad LTE fue seleccionada, y se configuró un intervalo de tiempo de 10 segundos para el envío de información de posicionamiento GPS.\\

En el proceso de desarrollo de la Estación Base, se tomó la decisión estratégica de implementar la suite de herramientas proporcionada por Amazon Amplify. Esta elección se fundamentó en la eficacia y versatilidad que ofrece Amplify Hosting, al mismo tiempo que permite una integración fluida con GitHub. De esta manera, los cambios realizados en el repositorio se reflejan de manera automática en la aplicación web, agilizando el ciclo de desarrollo y asegurando una sincronización eficiente entre el código fuente y la implementación en producción.\\

Para abordar la gestión de contenido multimedia, se optó por el servicio de almacenamiento en la nube S3 de Amazon Web Services (AWS). Esta solución proporciona una infraestructura escalable y segura para el almacenamiento de archivos, garantizando un acceso rápido y confiable a los recursos multimedia necesarios para la aplicación.\\

En cuanto a la seguridad y gestión de credenciales, la responsabilidad recayó en Amazon Cognito. Este servicio facilita la autenticación de usuarios y la gestión de identidades de manera segura, ofreciendo un entorno robusto para la administración de permisos y credenciales de acceso. La elección de Amazon Cognito contribuye a garantizar la integridad y confidencialidad de la información sensible manejada por la Estación Base.\\

Para el manejo eficiente de la base de datos, se eligió DynamoDB como el sistema de gestión de bases de datos. La elección se basó en su sólida compatibilidad con las herramientas de AWS y su capacidad para integrarse sin problemas en el ecosistema de servicios en la nube.\\

En lo que respecta a la aplicación web, se implementaron tecnologías líderes en el desarrollo web moderno. Node.js fue seleccionado para el desarrollo del backend, proporcionando un entorno de ejecución eficiente y orientado a eventos. Por otro lado, React se utilizó en el frontend, permitiendo la construcción de interfaces de usuario dinámicas y reactivas. Esta combinación de tecnologías garantiza un rendimiento óptimo, así como una experiencia de usuario fluida y atractiva.\\

La implementación del sistema se llevó a cabo de manera iterativa, siguiendo los principios de la metodología en espiral. En cada fase del desarrollo, se llevaron a cabo pruebas y validaciones para asegurar la funcionalidad del sistema. Los resultados obtenidos de estas pruebas fueron evaluados y utilizados como base para realizar ajustes en el diseño como en la implementación.\\

El sistema final permitió detectar síntomas de somnolencia y emitir alertas al conductor. Además, proporciona la ubicación del conductor en tiempo real, permitiendo el monitoreo desde la aplicación web asociada. Esta aplicación desempeña un papel integral al gestionar la información de los conductores y supervisar los reportes de incidencias enviados desde el módulo central de procesamiento. La interacción entre la infraestructura de AWS y las tecnologías Node.js y React en el frontend y backend, respectivamente, contribuyó significativamente a la implementación y resiliencia del sistema en conjunto.


\clearpage
\section{Referencias}

\bibliographystyle{ieeetran}

\bibliography{Referencias}


\end{document}



